<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Netty实战读书笔记]]></title>
    <url>%2Fposts%2Fbc6b2f71%2F</url>
    <content type="text"><![CDATA[第三章Channel、EventLoop和ChannelFuture是Netty网络抽象的代表。Channel—-对Java中的Socket的封装。Netty拥有许多预定义的、专门化实现的广泛类层次结构的根（EmbeddedChannel、LocalServerChannel、NioDatagramChannel，NioSctpChannel和NioSocketChannel）EventLoop—-控制流、多线程处理、并发。EventLoopGroup是一个EventLoop的容器，可以包含一个或多个EventLoop。每个EventLoop在其生命周期内只和一个Thread绑定，；EventLoop处理的IO事件都在它专有的Thread上被处理。一个Channel在其生命周期内只注册于一个EventLoop，一个EventLoop可能会被分配给一个或多个Channel。（在这种设计中，一个给定的Channel的I/O操作都是由同一个Thread执行的，实际上消除了对于同步的需要）ChannelFuture—-异步通知，可以通过该接口的addListener()方法注册一个ChannelFutureListener监听类，以便在某个操作完成时得到通知。在Netty中，有两种发送消息的方式。可以直接写到Channel中，会导致消息从ChannelPipeline的尾端开始流动；也可以写到和ChannelHandler相关联的ChannelHandlerContext对象中，会导致消息从ChannelPipeline中的下一个ChannelHandler流动。第四章ChannelPipeline的典型用途包括：将数据从一个格式转换为另一种格式提供异常的通知提供Channel变为活动的或者非活动的通知提供当Channel注册到EventLoop或者从EventLoop注销时的通知提供有关用户自定义事件的通知Netty的Channel实现是线程安全的，因此可以存储一个指向Channel的引用，每当需要向远程节点写数据时，都可以使用存储的引用，可以保证消息按顺序发送。Netty内置的传输：| 名称 | 包 | 描述 || ——– | ————————— | ———————————————————— || NIO | io.netty.channel.socket.nio | 使用java.nio.channelds包作为基础–给予选择器的方式 || Epoll | io.netty.channel.epoll | 有JNI驱动的epoll()和非阻塞IO。这个传输支持只有在LInux上可用的多种特性，如SO_REUSEPORT，比NIO传输更快，而且是完全非阻塞的 || OIO | io.netty.channel.socket.io | 使用java.net包作为基础–使用阻塞流 || Local | io.netty.channel.local | 可以在JVM内部通过管道进行通信的本地传输 || Embedded | io.netty.channel.embedded | Embedded传输，允许是用ChannelHandler而又不需要一个真正的基于网络的传输，可以用来作为测试使用。 |第五章ByteBuf对比原生ByteBuffer的有点可以被用户自定义的缓冲区类型拓展通过内置的复合缓冲区类型实现透明的零拷贝容量可以按需增长，(可以指定最大容量，试图移动写索引超过这个值会触发异常)在读和写两种模式之间不需要调用ByteBuffer的flip()方法，读和写使用了不同的索引支持方法的链式调用支持引用计数支持池化名称以read或者write开头的ByteBuf方法，将会推进其对应的索引，而名称以set或get开头的操作不会修改索引。ByteBuf的三种模式堆缓冲区，将数据存储在JVM的堆空间中，又称为支撑数据模式。可以在没有使用池化的情况下提供快速的分配和释放直接缓冲区，该数据不会被JVM的垃圾回收机制回收，也避免了每次调用本地I/O操作之前（或之后）将缓冲区的内容复制到一个中间缓冲区（或从中间缓冲区把内容复制到缓冲区）；其分配和释放都比较昂贵复合缓冲区，为多个ByteBuf提供了一个聚合视图。ByteBuf字节级操作如图所示，标记为可丢弃字节的分段包含了已经被读过的字节。通过调用discardReadBytes()方法可以丢弃他们以回收空间。因为可读字段必须被移动到缓冲区的开始位置，调用该方法后会导致内存复制，不建议频繁调用该方法。可读字节分段存储了实际数据，任何名称以read或skip开头的操作都将检索或者跳过位于当前readIndex的数据，并且将它增加已读字节数。可读字节分段是指一个拥有未定义内容的、写入就绪的内存区域，任何名称以write开头的操作都将从当前的writeIndex处开始写数据，并将它增加已经写入的字节数。ByteBuf可以通过调用markReaderIndex()、markWriterIndex()、resetWriterIndex()和resetReaderIndex()来标记和重置ByteBuf的readIndex和writeIndex。也可以通过调用readerIndex(int)或者writerIndex(int)来将索引移动到指定位置。通过调用clear()方法来将readerIndex和writerIndex都置为0，但不会清除内存中的内容，因为只是重置索引所以比discardReadBytes()轻量的多。派生缓冲区为ByteBuf提供了以专门的方式来呈现其内容的视图，可以通过duplicate()、slice()、slice(int, int)、Unpooled.unmodifiableBuffer(...)、order(ByteOrder)、readSlice(int)等方法创建。这些方法都将返回一个新的ByteBuf实例，它具有自己的读写索引和标记索引，其共享源ByteBuf内存。意味着修改了它的内容也会同时修改其对应源的实例。第六章Channel的4具有4中状态状态描述ChannelUnregisteredChannel已经被创建，但还未注册到EventLoopChannelResisteredChannel已经被注册到EventLoopChannelActiveChannel处于活动状态(已经连接到它的远程节点)。他现在可以接受和发送数据了ChannelInactiveChannel没有连接到远程节点当状态发生变化时，将会生成对应的事件。这些事件将会被转发给ChannelPipeline中的ChannelHandler，其可以随后对它们做出相应。ChannelHandler定义了3中生命周期操作，每个方法都能接受一个ChannelHandlerContext参数。类型描述handlerAddedChannelHandler添加到ChannelPipeline中时被调用handlerRemoved从ChannelPipeline中移除ChannelHandler时被调用exceptionCaught当处理过程中在ChannelPipeline中有错误产生时被调用ChannelInboundHandler接口负责处理入站数据以及各种状态的变化，其实现类在重写channelRead()方法时，需要显式的释放和池化ByteBuf实例相关的内存。继承自SimpleChannelInboundHandler的类在重写channelRead0()方法时，该抽象类会自动释放ByteBuf资源，所以我们不应该存储指向任何消息的引用。ChannelOutboundHandler用来处理出站操作和数据如果再该Handler中消息被消费或者丢弃了，并且没有传递给ChannelPipeline中的下一个ChannelOutboundHandler，就需要调用realease方法释放内存。如果消息到达了实际的传输层，当它被写入时或者Channel关闭时，就将会被自动释放。该接口中的大部分方法都需要一个ChannelPromise参数，以便在操作完成时得到通知。ChannelPromise是ChannelFuture的一个子类，其定义了一些可写的方法，如setSuccess()和setFailure()。ChannelPipline中的每一个ChannelHandler都是通过它的EventLoop(I/O线程)来处理传递给他的事件的，所以一定不要阻塞这个线程，否则的话会对整体的I/O处理产生负面的影响。ChannelHandleContext有很多方法，其中一些方法也存在与Channel和ChannelPipeline中。如果调用Channel或者ChannelPipeline上的这些方法，他们将沿着整个ChannelPipeline进行传播；而调用位于ChannelHandlerContext上的相同方法，则将从当前所关联的ChannelHandler开始，并且只会传播给位于该ChannelPipeline中的下一个能够处理改事件的ChannelHandler。ChannelHandler的数据入站异常处理逻辑ChannelHandler.exceptionCaught()的默认实现是简单得将当前一场转发给ChannelPipeline中的下一个ChannelHandler如果异常到达了ChannelPipeline的尾端，他将会通过Warning级别的日志被记录为未被处理可以重写exceptionCaught()方法来自定义异常处理逻辑ChannelHandler处理出站异常每个出站操作都将返回一个ChannelFuture。注册到ChannelFuture的ChannelFutureListener都将在操作完成时被通知该操作是否成功。几乎所有的ChannelOutboundHandler上的方法都会传入一个ChannelPromise的实例，其提供了立即通知的可写方法。第七章 &amp; 第八章EventLoop继承了ScheduledExcutorService的同时，只定义了一个方法parent()，用于返回所属的EventLoopGroup。故其提供了ScheduledExecutorService的所有方法，并提供了更好的性能。EventLoop线程分配时，每个EventLoop都将分配给一个Thread，Channel和EventLoop的分配方式根据所选IO类型有所不同。使用异步传输时，一个EventLoop可以被多个Channel共享。在使用ThreadLocal时，共享同一EventLoop的Channel获取到的ThreadLocal都是一样的使用同步传输时，每个EventLoop只能分配给一个Channel，保证了阻塞发生时编程的灵活性。AbstractBootstrap类的完整声明如下：1public abstract class AbstracBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt;在这个签名中，子类型B是其符类型的一个类型参数，因此可以返回到运行实例的引用以支持方法的链式调用。Bootstrap在调用bind或者connect方法之前，必须调用如下方法来设置所需的组件：group()、channel()或channelFactory()、handler()，否则会抛出IllegalStateException异常。第十章Netty内置了三种解码器：ByteToMessageDecoder将字节解码为消息，由于远程节点不一定能一次性发送一个完整的消息，所以这个类会对入站数据进行缓冲，知道他准备好处理。| 方法 | 描述 || ———————————————————— | ———————————————————— || decode(ChannelHandlerContext ctx, ByteBuf in, Listout) | 该方法必须在子类中实现。decode()方法被调用时将会传入一个包含了传入数据的ByteBuf，以及一个用来添加解码消息的List。对这个方法的调用将会重复进行，直到确定没有新的元素被添加到List，或者该ByteBuf中没有更多可读取的字节时为止。如果该List不为空，那么它的内容将会被传递给ChannelPipeline中的下一个ChannelInboundHandler || decodeLast(ChannelHandlerContext ctx, ByteBuf in, Listout) | Netty提供的默认实现只是简单地调用decode()方法。当Channel的状态变为非活动时，这个方法将会被调用一次。 |123456public class ToIntegerDecoder extends ByteToMessageDecoder&#123; @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception&#123; if(in.readableBytes() &gt;= 4) out.add(in.readInt()); &#125;&#125;对于编码器和解码器来说，一旦消息被编码或者解码，他就会被ReferenceCountUtil.release(msg)调用自动释放，如果需要保留引用以便稍后使用，可以调用ReferenceCountUtil.retain(msg)方法，这将增加该引用计数，防止该消息被释放。ReplayingDecoder是对ByteToMessageDecoder的封装，使得我们不需要调用readableBytes()方法来检查ByteBuf中是否有足够的字节数。如果没有足够的字节可用，ByteBuf的read方法将会抛出一个Error，其将在积累中被捕获并处理。当有更多的数据可供读取时，该decode()方法将会被再次调用。并不是所有的ByteBuf操作都被支持，如果调用了一个不被支持的方法，将会抛出一个异常ReplayingDecoder稍慢于ByteToMessageDecoder如果使用ByteToMessageDecoder不会引入太多的复杂性，就是用它；否则使用ReplayingDecoderMessageToMessageDecoder用于两个消息格式之间进行转换12public abstract class MessageToMessageDecoder&lt;I&gt; extends ChannelInboundAdapter// 参数类型I指定了decode()方法的输入参数msg的类型该类将调用I类的方法进行编码，调用O类的方法进行解码。综合考虑了实现的灵活性和简洁性。由于需要在解码之前在内存中缓存接收到的数据，但数据量太大有可能耗尽可用内存。Netty提供了一个TooLongFrameException异常类，其可由解码器在帧超出指定大小限制时抛出。Netty提供了两种编码器MessageToByteEncoder和MessageToMessage，其使用方法和解码器类似。如果要想把编码和解码集成到一个类中，Netty提供了抽象的编解码器类：ByteToMessageCodec和MessageToMessageCodec，但是这样对编解码组件的可重用性造成了影响。CombinedChannelDuplexHandler类可以整合一个已经实现好的编码器和解码器，其方法签名如下1public class CombinedChannelDuplexHandler &lt;I extends ChannelInboundHandler, O extends ChannelOutboundHandler&gt;第十一章Netty内置的Http协议编解码器名称描述HttpRequestEncoder将HttpRequest，HttpContent和LastHttpContent消息编码为字节HttpResponseEncoder将HttpResponse，HttpContent和LastHttpContent消息解码为字节HttpRequestDecoder将字节解码为HttpRequest，HttpContent和LastHttpContent消息HttpResponseDecoder将字节解码为HttpResponse，HttpContent和LastHttpContent消息HttpObjectAggregator将多个消息部分合并为FullHttpRequest或者FullHttpResponse消息HttpContentCompressor用来压缩Http的request或response用于空闲连接及超时的ChannelHandler名称描述IdleStateHandler当连接空闲时间太长时，将会触发一个IdleStateEvent事件。可以通过在自定义的ChannelInboundHandler中重写userEventTriggered()方法来处理该IdleStateEvent事件ReadTimeoutHandler如果在指定的时间间隔没有收到任何的入站数据，则抛出一个ReadTimeoutException并关闭对应的Channel。可以通过重写ChannelHandler中的exceptionCaught()方法来检测该ReadTimeoutExceptionWriteTimeoutHandler如果在指定的时间间隔没有任何入站数据写入，则抛出一个WriteTimeoutException并关闭对应的Channel。可以通过重写ChannelHandler中的exceptionCaugh()方法检测该WriteTimeoutException基于分隔符的解码器名称描述LineBasedFrameDecoder提取由行尾符（\n或者\r\n）分隔的帧的解码器DelimiterBasedFrameDecoder使用任何由用户提供的分割符来提取帧的通用解码器基于长度的解码器名称描述FixedLengthFrameDecoder提取在调用构造函数时指定的定长帧LengthFieldBasedFrameDecoder根据编码进帧头部中的长度值提取帧，该类接收三个参数，分别用于指定maxFrameLength(帧最大长度)、lengthFieldOffset(长度字段偏移量)、lengthFieldLength(长度字段的长度)Protocol Buffers编解码器名称描述ProtobufDecoder使用protobuf对消息进行解码ProtobufEncoder使用protobuf对消息进行编码ProtobufVarint32FrameDecoder根据消息中的Google Protocol Buffers的“Base 128 Varints”整形长度字段值动态的分割所接收到的ByteBufProtobufVarint32LengthFieldPrepender向Bytebuf前追加一个Google Protocol Buffers的“Base 128Varints”整形的长度字段]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop NameNode 高可用 (High Availability) 实现解析.md]]></title>
    <url>%2Fposts%2F523baf91%2F</url>
    <content type="text"><![CDATA[NameNode 高可用整体架构概述在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。HDFS NameNode 和 YARN ResourceManger 的高可用 (High Availability，HA) 方案基本类似，两者也复用了部分代码，但是由于 HDFS NameNode 对于数据存储和数据一致性的要求比 YARN ResourceManger 高得多，所以 HDFS NameNode 的高可用实现更为复杂一些，本文从内部实现的角度对 HDFS NameNode 的高可用机制进行详细的分析。HDFS NameNode 的高可用整体架构如图 1 所示 (图片来源于参考文献 [1])：图 1.HDFS NameNode 高可用整体架构从上图中，我们可以看出 NameNode 的高可用架构主要分为下面几个部分：Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。Zookeeper 集群：为主备切换控制器提供主备选举支持。共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。下面开始分别介绍 NameNode 的主备切换实现和共享存储系统的实现，在文章的最后会结合笔者的实践介绍一下在 NameNode 的高可用运维中的一些注意事项。NameNode 的主备切换实现NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现：ZKFailoverController 作为 NameNode 机器上一个独立的进程启动 (在 hdfs 启动脚本之中的进程名为 zkfc)，启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举。ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。NameNode 实现主备切换的流程如图 2 所示，有以下几步：HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调 ZKFailoverController 注册的相应方法进行处理。如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。图 2.NameNode 的主备切换流程下面分别对 HealthMonitor、ActiveStandbyElector 和 ZKFailoverController 的实现细节进行分析：HealthMonitor 实现分析ZKFailoverController 在初始化的时候会创建 HealthMonitor，HealthMonitor 在内部会启动一个线程来循环调用 NameNode 的 HAServiceProtocol RPC 接口的方法来检测 NameNode 的状态，并将状态的变化通过回调的方式来通知 ZKFailoverController。HealthMonitor 主要检测 NameNode 的两类状态，分别是 HealthMonitor.State 和 HAServiceStatus。HealthMonitor.State 是通过 HAServiceProtocol RPC 接口的 monitorHealth 方法来获取的，反映了 NameNode 节点的健康状况，主要是磁盘存储资源是否充足。HealthMonitor.State 包括下面几种状态：INITIALIZING：HealthMonitor 在初始化过程中，还没有开始进行健康状况检测；SERVICE_HEALTHY：NameNode 状态正常；SERVICE_NOT_RESPONDING：调用 NameNode 的 monitorHealth 方法调用无响应或响应超时；SERVICE_UNHEALTHY：NameNode 还在运行，但是 monitorHealth 方法返回状态不正常，磁盘存储资源不足；HEALTH_MONITOR_FAILED：HealthMonitor 自己在运行过程中发生了异常，不能继续检测 NameNode 的健康状况，会导致 ZKFailoverController 进程退出；HealthMonitor.State 在状态检测之中起主要的作用，在 HealthMonitor.State 发生变化的时候，HealthMonitor 会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。而 HAServiceStatus 则是通过 HAServiceProtocol RPC 接口的 getServiceStatus 方法来获取的，主要反映的是 NameNode 的 HA 状态，包括：INITIALIZING：NameNode 在初始化过程中；ACTIVE：当前 NameNode 为主 NameNode；STANDBY：当前 NameNode 为备 NameNode；STOPPING：当前 NameNode 已停止；HAServiceStatus 在状态检测之中只是起辅助的作用，在 HAServiceStatus 发生变化时，HealthMonitor 也会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。ActiveStandbyElector 实现分析Namenode(包括 YARN ResourceManager) 的主备选举是通过 ActiveStandbyElector 来完成的，ActiveStandbyElector 主要是利用了 Zookeeper 的写一致性和临时节点机制，具体的主备选举实现如下：创建锁节点如果 HealthMonitor 检测到对应的 NameNode 的状态正常，那么表示这个 NameNode 有资格参加 Zookeeper 的主备选举。如果目前还没有进行过主备选举的话，那么相应的 ActiveStandbyElector 就会发起一次主备选举，尝试在 Zookeeper 上创建一个路径为/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 的临时节点 (${dfs.nameservices} 为 Hadoop 的配置参数 dfs.nameservices 的值，下同)，Zookeeper 的写一致性会保证最终只会有一个 ActiveStandbyElector 创建成功，那么创建成功的 ActiveStandbyElector 对应的 NameNode 就会成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Active 状态。而创建失败的 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Standby 状态。注册 Watcher 监听不管创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点是否成功，ActiveStandbyElector 随后都会向 Zookeeper 注册一个 Watcher 来监听这个节点的状态变化事件，ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件。自动触发主备选举如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock，这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。防止脑裂Zookeeper 在工程实践的过程中经常会发生的一个现象就是 Zookeeper 客户端“假死”，所谓的“假死”是指如果 Zookeeper 客户端机器负载过高或者正在进行 JVM Full GC，那么可能会导致 Zookeeper 客户端到 Zookeeper 服务端的心跳不能正常发出，一旦这个时间持续较长，超过了配置的 Zookeeper Session Timeout 参数的话，Zookeeper 服务端就会认为客户端的 session 已经过期从而将客户端的 Session 关闭。“假死”有可能引起分布式系统常说的双主或脑裂 (brain-split) 现象。具体到本文所述的 NameNode，假设 NameNode1 当前为 Active 状态，NameNode2 当前为 Standby 状态。如果某一时刻 NameNode1 对应的 ZKFailoverController 进程发生了“假死”现象，那么 Zookeeper 服务端会认为 NameNode1 挂掉了，根据前面的主备切换逻辑，NameNode2 会替代 NameNode1 进入 Active 状态。但是此时 NameNode1 可能仍然处于 Active 状态正常运行，即使随后 NameNode1 对应的 ZKFailoverController 因为负载下降或者 Full GC 结束而恢复了正常，感知到自己和 Zookeeper 的 Session 已经关闭，但是由于网络的延迟以及 CPU 线程调度的不确定性，仍然有可能会在接下来的一段时间窗口内 NameNode1 认为自己还是处于 Active 状态。这样 NameNode1 和 NameNode2 都处于 Active 状态，都可以对外提供服务。这种情况对于 NameNode 这类对数据一致性要求非常高的系统来说是灾难性的，数据会发生错乱且无法恢复。Zookeeper 社区对这种问题的解决方法叫做 fencing，中文翻译为隔离，也就是想办法把旧的 Active NameNode 隔离起来，使它不能正常对外提供服务。ActiveStandbyElector 为了实现 fencing，会在成功创建 Zookeeper 节点 hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 从而成为 Active NameNode 之后，创建另外一个路径为/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 的持久节点，这个节点里面保存了这个 Active NameNode 的地址信息。Active NameNode 的 ActiveStandbyElector 在正常的状态下关闭 Zookeeper Session 的时候 (注意由于/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 是临时节点，也会随之删除)，会一起删除节点/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb。但是如果 ActiveStandbyElector 在异常的状态下 Zookeeper Session 关闭 (比如前述的 Zookeeper 假死)，那么由于/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 是持久节点，会一直保留下来。后面当另一个 NameNode 选主成功之后，会注意到上一个 Active NameNode 遗留下来的这个节点，从而会回调 ZKFailoverController 的方法对旧的 Active NameNode 进行 fencing，具体处理见后文 ZKFailoverController 部分所述。ZKFailoverController 实现分析ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调函数，ZKFailoverController 的处理逻辑主要靠 HealthMonitor 和 ActiveStandbyElector 的回调函数来驱动。对 HealthMonitor 状态变化的处理如前所述，HealthMonitor 会检测 NameNode 的两类状态，HealthMonitor.State 在状态检测之中起主要的作用，ZKFailoverController 注册到 HealthMonitor 上的处理 HealthMonitor.State 状态变化的回调函数主要关注 SERVICE_HEALTHY、SERVICE_NOT_RESPONDING 和 SERVICE_UNHEALTHY 这 3 种状态：如果检测到状态为 SERVICE_HEALTHY，表示当前的 NameNode 有资格参加 Zookeeper 的主备选举，如果目前还没有进行过主备选举的话，ZKFailoverController 会调用 ActiveStandbyElector 的 joinElection 方法发起一次主备选举。如果检测到状态为 SERVICE_NOT_RESPONDING 或者是 SERVICE_UNHEALTHY，就表示当前的 NameNode 出现问题了，ZKFailoverController 会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举，这样其它的 NameNode 就有机会成为主 NameNode。而 HAServiceStatus 在状态检测之中仅起辅助的作用，在 HAServiceStatus 发生变化时，ZKFailoverController 注册到 HealthMonitor 上的处理 HAServiceStatus 状态变化的回调函数会判断 NameNode 返回的 HAServiceStatus 和 ZKFailoverController 所期望的是否一致，如果不一致的话，ZKFailoverController 也会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举。对 ActiveStandbyElector 主备选举状态变化的处理在 ActiveStandbyElector 的主备选举状态发生变化时，会回调 ZKFailoverController 注册的回调函数来进行相应的处理：如果 ActiveStandbyElector 选主成功，那么 ActiveStandbyElector 对应的 NameNode 成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeActive 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToActive 方法，将 NameNode 转换为 Active 状态。如果 ActiveStandbyElector 选主失败，那么 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeStandby 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，将 NameNode 转换为 Standby 状态。如果 ActiveStandbyElector 选主成功之后，发现了上一个 Active NameNode 遗留下来的/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 节点 (见“ActiveStandbyElector 实现分析”一节“防止脑裂”部分所述)，那么 ActiveStandbyElector 会首先回调 ZKFailoverController 注册的 fenceOldActive 方法，尝试对旧的 Active NameNode 进行 fencing，在进行 fencing 的时候，会执行以下的操作：首先尝试调用这个旧 Active NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，看能不能把它转换为 Standby 状态。如果 transitionToStandby 方法调用失败，那么就执行 Hadoop 配置文件之中预定义的隔离措施，Hadoop 目前主要提供两种隔离措施，通常会选择 sshfence：sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死；shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离；只有在成功地执行完成 fencing 之后，选主成功的 ActiveStandbyElector 才会回调 ZKFailoverController 的 becomeActive 方法将对应的 NameNode 转换为 Active 状态，开始对外提供服务。NameNode 的共享存储实现过去几年中 Hadoop 社区涌现过很多的 NameNode 共享存储方案，比如 shared NAS+NFS、BookKeeper、BackupNode 和 QJM(Quorum Journal Manager) 等等。目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现，本部分只针对基于 QJM 的共享存储方案的内部实现原理进行分析。为了理解 QJM 的设计和实现，首先要对 NameNode 的元数据存储结构有所了解。NameNode 的元数据存储概述一个典型的 NameNode 的元数据存储目录结构如图 3 所示 (图片来源于参考文献 [4])，这里主要关注其中的 EditLog 文件和 FSImage 文件：图 3 .NameNode 的元数据存储目录结构NameNode 在执行 HDFS 客户端提交的创建文件或者移动文件这样的写操作的时候，会首先把这些操作记录在 EditLog 文件之中，然后再更新内存中的文件系统镜像。内存中的文件系统镜像用于 NameNode 向客户端提供读服务，而 EditLog 仅仅只是在数据恢复的时候起作用。记录在 EditLog 之中的每一个操作又称为一个事务，每个事务有一个整数形式的事务 id 作为编号。EditLog 会被切割为很多段，每一段称为一个 Segment。正在写入的 EditLog Segment 处于 in-progress 状态，其文件名形如 edits_inprogress_${start_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，例如上图中的 edits_inprogress_0000000000000000020。而已经写入完成的 EditLog Segment 处于 finalized 状态，其文件名形如 edits_${start_txid}-${end_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，${end_txid} 表示这个 segment 的结束事务 id，例如上图中的 edits_0000000000000000001-0000000000000000019。NameNode 会定期对内存中的文件系统镜像进行 checkpoint 操作，在磁盘上生成 FSImage 文件，FSImage 文件的文件名形如 fsimage_${end_txid}，其中${end_txid} 表示这个 fsimage 文件的结束事务 id，例如上图中的 fsimage_0000000000000000020。在 NameNode 启动的时候会进行数据恢复，首先把 FSImage 文件加载到内存中形成文件系统镜像，然后再把 EditLog 之中 FsImage 的结束事务 id 之后的 EditLog 回放到这个文件系统镜像上。基于 QJM 的共享存储系统的总体架构基于 QJM 的共享存储系统主要用于保存 EditLog，并不保存 FSImage 文件。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法 (参见参考文献 [3])，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。基于 QJM 的共享存储系统的内部实现架构图如图 4 所示，主要包含下面几个主要的组件：图 4 . 基于 QJM 的共享存储系统的内部实现架构图FSEditLog：这个类封装了对 EditLog 的所有操作，是 NameNode 对 EditLog 的所有操作的入口。JournalSet： 这个类封装了对本地磁盘和 JournalNode 集群上的 EditLog 的操作，内部包含了两类 JournalManager，一类为 FileJournalManager，用于实现对本地磁盘上 EditLog 的操作。一类为 QuorumJournalManager，用于实现对 JournalNode 集群上共享目录的 EditLog 的操作。FSEditLog 只会调用 JournalSet 的相关方法，而不会直接使用 FileJournalManager 和 QuorumJournalManager。FileJournalManager：封装了对本地磁盘上的 EditLog 文件的操作，不仅 NameNode 在向本地磁盘上写入 EditLog 的时候使用 FileJournalManager，JournalNode 在向本地磁盘写入 EditLog 的时候也复用了 FileJournalManager 的代码和逻辑。QuorumJournalManager：封装了对 JournalNode 集群上的 EditLog 的操作，它会根据 JournalNode 集群的 URI 创建负责与 JournalNode 集群通信的类 AsyncLoggerSet， QuorumJournalManager 通过 AsyncLoggerSet 来实现对 JournalNode 集群上的 EditLog 的写操作，对于读操作，QuorumJournalManager 则是通过 Http 接口从 JournalNode 上的 JournalNodeHttpServer 读取 EditLog 的数据。AsyncLoggerSet：内部包含了与 JournalNode 集群进行通信的 AsyncLogger 列表，每一个 AsyncLogger 对应于一个 JournalNode 节点，另外 AsyncLoggerSet 也包含了用于等待大多数 JournalNode 返回结果的工具类方法给 QuorumJournalManager 使用。AsyncLogger：具体的实现类是 IPCLoggerChannel，IPCLoggerChannel 在执行方法调用的时候，会把调用提交到一个单线程的线程池之中，由线程池线程来负责向对应的 JournalNode 的 JournalNodeRpcServer 发送 RPC 请求。JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。下面对基于 QJM 的共享存储系统的两个关键性问题同步数据和恢复数据进行详细分析。基于 QJM 的共享存储系统的数据同步机制分析Active NameNode 和 StandbyNameNode 使用 JouranlNode 集群来进行数据同步的过程如图 5 所示，Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog：图 5 . 基于 QJM 的共享存储的数据同步机制Active NameNode 提交 EditLog 到 JournalNode 集群当处于 Active 状态的 NameNode 调用 FSEditLog 类的 logSync 方法来提交 EditLog 的时候，会通过 JouranlSet 同时向本地磁盘目录和 JournalNode 集群上的共享存储目录写入 EditLog。写入 JournalNode 集群是通过并行调用每一个 JournalNode 的 QJournalProtocol RPC 接口的 journal 方法实现的，如果对大多数 JournalNode 的 journal 方法调用成功，那么就认为提交 EditLog 成功，否则 NameNode 就会认为这次提交 EditLog 失败。提交 EditLog 失败会导致 Active NameNode 关闭 JournalSet 之后退出进程，留待处于 Standby 状态的 NameNode 接管之后进行数据恢复。从上面的叙述可以看出，Active NameNode 提交 EditLog 到 JournalNode 集群的过程实际上是同步阻塞的，但是并不需要所有的 JournalNode 都调用成功，只要大多数 JournalNode 调用成功就可以了。如果无法形成大多数，那么就认为提交 EditLog 失败，NameNode 停止服务退出进程。如果对应到分布式系统的 CAP 理论的话，虽然采用了 Paxos 的“大多数”思想对 C(consistency，一致性) 和 A(availability，可用性) 进行了折衷，但还是可以认为 NameNode 选择了 C 而放弃了 A，这也符合 NameNode 对数据一致性的要求。Standby NameNode 从 JournalNode 集群同步 EditLog当 NameNode 进入 Standby 状态之后，会启动一个 EditLogTailer 线程。这个线程会定期调用 EditLogTailer 类的 doTailEdits 方法从 JournalNode 集群上同步 EditLog，然后把同步的 EditLog 回放到内存之中的文件系统镜像上 (并不会同时把 EditLog 写入到本地磁盘上)。这里需要关注的是：从 JournalNode 集群上同步的 EditLog 都是处于 finalized 状态的 EditLog Segment。“NameNode 的元数据存储概述”一节说过 EditLog Segment 实际上有两种状态，处于 in-progress 状态的 Edit Log 当前正在被写入，被认为是处于不稳定的中间态，有可能会在后续的过程之中发生修改，比如被截断。Active NameNode 在完成一个 EditLog Segment 的写入之后，就会向 JournalNode 集群发送 finalizeLogSegment RPC 请求，将完成写入的 EditLog Segment finalized，然后开始下一个新的 EditLog Segment。一旦 finalizeLogSegment 方法在大多数的 JournalNode 上调用成功，表明这个 EditLog Segment 已经在大多数的 JournalNode 上达成一致。一个 EditLog Segment 处于 finalized 状态之后，可以保证它再也不会变化。从上面描述的过程可以看出，虽然 Active NameNode 向 JournalNode 集群提交 EditLog 是同步的，但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。基于 QJM 的共享存储系统的数据恢复机制分析处于 Standby 状态的 NameNode 转换为 Active 状态的时候，有可能上一个 Active NameNode 发生了异常退出，那么 JournalNode 集群中各个 JournalNode 上的 EditLog 就可能会处于不一致的状态，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 EditLog 恢复为一致。另外如前所述，当前处于 Standby 状态的 NameNode 的内存中的文件系统镜像有很大的可能是落后于旧的 Active NameNode 的，所以在 JournalNode 集群中各个节点上的 EditLog 达成一致之后，接下来要做的事情就是从 JournalNode 集群上补齐落后的 EditLog。只有在这两步完成之后，当前新的 Active NameNode 才能安全地对外提供服务。补齐落后的 EditLog 的过程复用了前面描述的 Standby NameNode 从 JournalNode 集群同步 EditLog 的逻辑和代码，最终调用 EditLogTailer 类的 doTailEdits 方法来完成 EditLog 的补齐。使 JournalNode 集群上的 EditLog 达成一致的过程是一致性算法 Paxos 的典型应用场景，QJM 对这部分的处理可以看做是 Single Instance Paxos(参见参考文献 [3]) 算法的一个实现，在达成一致的过程中，Active NameNode 和 JournalNode 集群之间的交互流程如图 6 所示，具体描述如下：图 6.Active NameNode 和 JournalNode 集群的交互流程图生成一个新的 EpochEpoch 是一个单调递增的整数，用来标识每一次 Active NameNode 的生命周期，每发生一次 NameNode 的主备切换，Epoch 就会加 1。这实际上是一种 fencing 机制，为什么需要 fencing 已经在前面“ActiveStandbyElector 实现分析”一节的“防止脑裂”部分进行了说明。产生新 Epoch 的流程与 Zookeeper 的 ZAB(Zookeeper Atomic Broadcast) 协议在进行数据恢复之前产生新 Epoch 的过程完全类似：Active NameNode 首先向 JournalNode 集群发送 getJournalState RPC 请求，每个 JournalNode 会返回自己保存的最近的那个 Epoch(代码中叫 lastPromisedEpoch)。NameNode 收到大多数的 JournalNode 返回的 Epoch 之后，在其中选择最大的一个加 1 作为当前的新 Epoch，然后向各个 JournalNode 发送 newEpoch RPC 请求，把这个新的 Epoch 发给各个 JournalNode。每一个 JournalNode 在收到新的 Epoch 之后，首先检查这个新的 Epoch 是否比它本地保存的 lastPromisedEpoch 大，如果大的话就把 lastPromisedEpoch 更新为这个新的 Epoch，并且向 NameNode 返回它自己的本地磁盘上最新的一个 EditLogSegment 的起始事务 id，为后面的数据恢复过程做好准备。如果小于或等于的话就向 NameNode 返回错误。NameNode 收到大多数 JournalNode 对 newEpoch 的成功响应之后，就会认为生成新的 Epoch 成功。在生成新的 Epoch 之后，每次 NameNode 在向 JournalNode 集群提交 EditLog 的时候，都会把这个 Epoch 作为参数传递过去。每个 JournalNode 会比较传过来的 Epoch 和它自己保存的 lastPromisedEpoch 的大小，如果传过来的 epoch 的值比它自己保存的 lastPromisedEpoch 小的话，那么这次写相关操作会被拒绝。一旦大多数 JournalNode 都拒绝了这次写操作，那么这次写操作就失败了。如果原来的 Active NameNode 恢复正常之后再向 JournalNode 写 EditLog，那么因为它的 Epoch 肯定比新生成的 Epoch 小，并且大多数的 JournalNode 都接受了这个新生成的 Epoch，所以拒绝写入的 JournalNode 数目至少是大多数，这样原来的 Active NameNode 写 EditLog 就肯定会失败，失败之后这个 NameNode 进程会直接退出，这样就实现了对原来的 Active NameNode 的隔离了。选择需要数据恢复的 EditLog Segment 的 id需要恢复的 Edit Log 只可能是各个 JournalNode 上的最后一个 Edit Log Segment，如前所述，JournalNode 在处理完 newEpoch RPC 请求之后，会向 NameNode 返回它自己的本地磁盘上最新的一个 EditLog Segment 的起始事务 id，这个起始事务 id 实际上也作为这个 EditLog Segment 的 id。NameNode 会在所有这些 id 之中选择一个最大的 id 作为要进行数据恢复的 EditLog Segment 的 id。向 JournalNode 集群发送 prepareRecovery RPC 请求NameNode 接下来向 JournalNode 集群发送 prepareRecovery RPC 请求，请求的参数就是选出的 EditLog Segment 的 id。JournalNode 收到请求后返回本地磁盘上这个 Segment 的起始事务 id、结束事务 id 和状态 (in-progress 或 finalized)。这一步对应于 Paxos 算法的 Phase 1a 和 Phase 1b(参见参考文献 [3]) 两步。Paxos 算法的 Phase1 是 prepare 阶段，这也与方法名 prepareRecovery 相对应。并且这里以前面产生的新的 Epoch 作为 Paxos 算法中的提案编号 (proposal number)。只要大多数的 JournalNode 的 prepareRecovery RPC 调用成功返回，NameNode 就认为成功。选择进行同步的基准数据源，向 JournalNode 集群发送 acceptRecovery RPC 请求 NameNode 根据 prepareRecovery 的返回结果，选择一个 JournalNode 上的 EditLog Segment 作为同步的基准数据源。选择基准数据源的原则大致是：在 in-progress 状态和 finalized 状态的 Segment 之间优先选择 finalized 状态的 Segment。如果都是 in-progress 状态的话，那么优先选择 Epoch 比较高的 Segment(也就是优先选择更新的)，如果 Epoch 也一样，那么优先选择包含的事务数更多的 Segment。在选定了同步的基准数据源之后，NameNode 向 JournalNode 集群发送 acceptRecovery RPC 请求，将选定的基准数据源作为参数。JournalNode 接收到 acceptRecovery RPC 请求之后，从基准数据源 JournalNode 的 JournalNodeHttpServer 上下载 EditLog Segment，将本地的 EditLog Segment 替换为下载的 EditLog Segment。这一步对应于 Paxos 算法的 Phase 2a 和 Phase 2b(参见参考文献 [3]) 两步。Paxos 算法的 Phase2 是 accept 阶段，这也与方法名 acceptRecovery 相对应。只要大多数 JournalNode 的 acceptRecovery RPC 调用成功返回，NameNode 就认为成功。向 JournalNode 集群发送 finalizeLogSegment RPC 请求，数据恢复完成上一步执行完成之后，NameNode 确认大多数 JournalNode 上的 EditLog Segment 已经从基准数据源进行了同步。接下来，NameNode 向 JournalNode 集群发送 finalizeLogSegment RPC 请求，JournalNode 接收到请求之后，将对应的 EditLog Segment 从 in-progress 状态转换为 finalized 状态，实际上就是将文件名从 edits_inprogress_${startTxid} 重命名为 edits_${startTxid}-${endTxid}，见“NameNode 的元数据存储概述”一节的描述。只要大多数 JournalNode 的 finalizeLogSegment RPC 调用成功返回，NameNode 就认为成功。此时可以保证 JournalNode 集群的大多数节点上的 EditLog 已经处于一致的状态，这样 NameNode 才能安全地从 JournalNode 集群上补齐落后的 EditLog 数据。需要注意的是，尽管基于 QJM 的共享存储方案看起来理论完备，设计精巧，但是仍然无法保证数据的绝对强一致，下面选取参考文献 [2] 中的一个例子来说明：假设有 3 个 JournalNode：JN1、JN2 和 JN3，Active NameNode 发送了事务 id 为 151、152 和 153 的 3 个事务到 JournalNode 集群，这 3 个事务成功地写入了 JN2，但是在还没能写入 JN1 和 JN3 之前，Active NameNode 就宕机了。同时，JN3 在整个写入的过程中延迟较大，落后于 JN1 和 JN2。最终成功写入 JN1 的事务 id 为 150，成功写入 JN2 的事务 id 为 153，而写入到 JN3 的事务 id 仅为 125，如图 7 所示 (图片来源于参考文献 [2])。按照前面描述的只有成功地写入了大多数的 JournalNode 才认为写入成功的原则，显然事务 id 为 151、152 和 153 的这 3 个事务只能算作写入失败。在进行数据恢复的过程中，会发生下面两种情况：图 7.JournalNode 集群写入的事务 id 情况如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段收到了 JN2 的回复，那么肯定会以 JN2 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 153。从恢复的结果来看，实际上可以认为前面宕机的 Active NameNode 对事务 id 为 151、152 和 153 的这 3 个事务的写入成功了。但是如果从 NameNode 自身的角度来看，这显然就发生了数据不一致的情况。如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段没有收到 JN2 的回复，那么肯定会以 JN1 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 150。在这种情况下，如果从 NameNode 自身的角度来看的话，数据就是一致的了。事实上不光本文描述的基于 QJM 的共享存储方案无法保证数据的绝对一致，大家通常认为的一致性程度非常高的 Zookeeper 也会发生类似的情况，这也从侧面说明了要实现一个数据绝对一致的分布式存储系统的确非常困难。NameNode 在进行状态转换时对共享存储的处理下面对 NameNode 在进行状态转换的过程中对共享存储的处理进行描述，使得大家对基于 QJM 的共享存储方案有一个完整的了解，同时也作为本部分的总结。NameNode 初始化启动，进入 Standby 状态在 NameNode 以 HA 模式启动的时候，NameNode 会认为自己处于 Standby 模式，在 NameNode 的构造函数中会加载 FSImage 文件和 EditLog Segment 文件来恢复自己的内存文件系统镜像。在加载 EditLog Segment 的时候，调用 FSEditLog 类的 initSharedJournalsForRead 方法来创建只包含了在 JournalNode 集群上的共享目录的 JournalSet，也就是说，这个时候只会从 JournalNode 集群之中加载 EditLog，而不会加载本地磁盘上的 EditLog。另外值得注意的是，加载的 EditLog Segment 只是处于 finalized 状态的 EditLog Segment，而处于 in-progress 状态的 Segment 需要后续在切换为 Active 状态的时候，进行一次数据恢复过程，将 in-progress 状态的 Segment 转换为 finalized 状态的 Segment 之后再进行读取。加载完 FSImage 文件和共享目录上的 EditLog Segment 文件之后，NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式。如前所述，EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog。而 StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点。NameNode 从 Standby 状态切换为 Active 状态当 NameNode 从 Standby 状态切换为 Active 状态的时候，首先需要做的就是停止它在 Standby 状态的时候启动的线程和相关的服务，包括上面提到的 EditLogTailer 线程和 StandbyCheckpointer 线程，然后关闭用于读取 JournalNode 集群的共享目录上的 EditLog 的 JournalSet，接下来会调用 FSEditLog 的 initJournalSetForWrite 方法重新打开 JournalSet。不同的是，这个 JournalSet 内部同时包含了本地磁盘目录和 JournalNode 集群上的共享目录。这些工作完成之后，就开始执行“基于 QJM 的共享存储系统的数据恢复机制分析”一节所描述的流程，调用 FSEditLog 类的 recoverUnclosedStreams 方法让 JournalNode 集群中各个节点上的 EditLog 达成一致。然后调用 EditLogTailer 类的 catchupDuringFailover 方法从 JournalNode 集群上补齐落后的 EditLog。最后打开一个新的 EditLog Segment 用于新写入数据，同时启动 Active NameNode 所需要的线程和服务。NameNode 从 Active 状态切换为 Standby 状态当 NameNode 从 Active 状态切换为 Standby 状态的时候，首先需要做的就是停止它在 Active 状态的时候启动的线程和服务，然后关闭用于读取本地磁盘目录和 JournalNode 集群上的共享目录的 EditLog 的 JournalSet。接下来会调用 FSEditLog 的 initSharedJournalsForRead 方法重新打开用于读取 JournalNode 集群上的共享目录的 JournalSet。这些工作完成之后，就会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，EditLogTailer 线程会定时从 JournalNode 集群上同步 Edit Log。NameNode 高可用运维中的注意事项本节结合笔者的实践，从初始化部署和日常运维两个方面介绍一些在 NameNode 高可用运维中的注意事项。初始化部署如果在开始部署 Hadoop 集群的时候就启用 NameNode 的高可用的话，那么相对会比较容易。但是如果在采用传统的单 NameNode 的架构运行了一段时间之后，升级为 NameNode 的高可用架构的话，就要特别注意在升级的时候需要按照以下的步骤进行操作：对 Zookeeper 进行初始化，创建 Zookeeper 上的/hadoop-ha/${dfs.nameservices} 节点。创建节点是为随后通过 Zookeeper 进行主备选举做好准备，在进行主备选举的时候会在这个节点下面创建子节点 (具体可参照“ActiveStandbyElector 实现分析”一节的叙述)。这一步通过在原有的 NameNode 上执行命令 hdfs zkfc -formatZK 来完成。启动所有的 JournalNode，这通过脚本命令 hadoop-daemon.sh start journalnode 来完成。对 JouranlNode 集群的共享存储目录进行格式化，并且将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件 (具体可参照“NameNode 的元数据存储概述”一节的叙述) 之后的 EditLog 拷贝到 JournalNode 集群上的共享目录之中，这通过在原有的 NameNode 上执行命令 hdfs namenode -initializeSharedEdits 来完成。启动原有的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。对新增的 NameNode 节点进行初始化，将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件拷贝到这个新增的 NameNode 的本地磁盘上，同时需要验证 JournalNode 集群的共享存储目录上已经具有了这个 FSImage 文件之后的 EditLog(已经在第 3 步完成了)。这一步通过在新增的 NameNode 上执行命令 hdfs namenode -bootstrapStandby 来完成。启动新增的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。在这两个 NameNode 上启动 zkfc(ZKFailoverController) 进程，谁通过 Zookeeper 选主成功，谁就是主 NameNode，另一个为备 NameNode。这通过脚本命令 hadoop-daemon.sh start zkfc 完成。日常维护笔者在日常的维护之中主要遇到过下面两种问题：Zookeeper 过于敏感：Hadoop 的配置项中 Zookeeper 的 session timeout 的配置参数 ha.zookeeper.session-timeout.ms 的默认值为 5000，也就是 5s，这个值比较小，会导致 Zookeeper 比较敏感，可以把这个值尽量设置得大一些，避免因为网络抖动等原因引起 NameNode 进行无谓的主备切换。单台 JouranlNode 故障时会导致主备无法切换：在理论上，如果有 3 台或者更多的 JournalNode，那么挂掉一台 JouranlNode 应该仍然可以进行正常的主备切换。但是笔者在某次 NameNode 重启的时候，正好赶上一台 JournalNode 挂掉宕机了，这个时候虽然某一台 NameNode 通过 Zookeeper 选主成功，但是这台被选为主的 NameNode 无法成功地从 Standby 状态切换为 Active 状态。事后追查原因发现，被选为主的 NameNode 卡在退出 Standby 状态的最后一步，这个时候它需要等待到 JournalNode 的请求全部完成之后才能退出。但是由于有一台 JouranlNode 宕机，到这台 JournalNode 的请求都积压在一起并且在不断地进行重试，同时在 Hadoop 的配置项中重试次数的默认值非常大，所以就会导致被选为主的 NameNode 无法及时退出 Standby 状态。这个问题主要是 Hadoop 内部的 RPC 通信框架的设计缺陷引起的，Hadoop HA 的源代码 IPCLoggerChannel 类中有关于这个问题的 TODO，但是截止到社区发布的 2.7.1 版本这个问题仍然存在。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Manjaro安装配置]]></title>
    <url>%2Fposts%2F33ff7b7%2F</url>
    <content type="text"><![CDATA[0. 安装启动时选择第二项boot（non-free),Manjaro自带的驱动精灵会帮你安装好所需驱动，笔记本双显卡则会帮你安装bumblebeedriver boot（non-free)如果是WIndows+Manjaro双系统安装，步骤可以参考：https://my.oschina.net/langxSpirit/blog/16333841.系统信息查看系统信息1inxi -Fx2.网络设置查看网络状态1ping 8.8.8.8-———–connect: Network is unreachable-———–如果网卡驱动是正常，请尝试手动设置IP地址、网关、DNS信息3.笔记本双显卡设置查看显卡NVIDIA状态1lspci| grep -i vga01:00.0 VGA compatible controller: NVIDIA Corporation GK107M [GeForce GTX 660M] (rev ff)Nvidia 卡信息的末尾是 rev ff，表示独显已经关闭。现在运行的是intel核显，这正是我们安装bumblebee目的。bumblebee的作用是禁用nvidia独立显卡，需要使用独显时，使用”optirun 程序名“手动开启nvidia来运行需要加速的程序，如optirun vmware。https://wiki.archlinux.org/index.php/Bumblebeehttps://wiki.archlinux.org/index.php/Bumblebee_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)要使用 Bumblebee，请确保添加你的用户到 bumblebee 组：$ gpasswd -a svenaugustus bumblebee #gpasswd -a 您的用户名 bumblebee启用服务：1systemctl enable bumblebeed.service重启测试 Bumblebee 是否工作：1optirun glxgears -info如果一个内有动画的窗口出现，那么 Optimus 和 Bumblebee 正在工作。-—————–NVIDIA(0): Failed to assign any connected display devices to X screen 0如果终端输出如下:[ERROR]Cannot access secondary GPU - error: [XORG] (EE) NVIDIA(0): Failed to assign any connected display devices to X screen 0[ERROR]Aborting because fallback start is disabled.你要修改 /etc/bumblebee/xorg.conf.nvidia 里的这行:Option “ConnectedMonitor” “DFP”为:Option “ConnectedMonitor” “CRT”-—————–打开N卡设置：1optirun nvidia-settings -c :8如果需要不依赖Bumblebee来使用CUDA, 为开启NVIDIA显卡，运行:1sudo tee /proc/acpi/bbswitch &lt;&lt;&lt; ON注意，重启完N卡又会回复关闭状态。4.时间和日期如果安装的是双系统，注意Manjaro Setting Manager &gt; Time and Date勾选以下选项–set time and date automatically–hardware clock in local time zoneIf you has Windows as well, please install NTP. http://www.satsignal.eu/ntp/setup.htmlTips: NTP server ,please select your nearest country or region from the drop-down list.Here are some links in chinese: http://blog.csdn.net/aaazz47/article/details/78696899#如果你装了双系统，那么Windows系统需要装NTP同步为UTC时间，或者委屈Manjaro使用本地时间localtime。5.源镜像与系统更新排列源1sudo pacman-mirrors -i -c China -m rank #只留下清华源能令带宽跑满同步并优化（类似磁盘整理，固态硬盘无需操作）$ sudo pacman-optimize &amp;&amp; sync增加archlinuxcn库和antergos库1echo -e &quot;\n[archlinuxcn]\nSigLevel = TrustAll\nServer = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/\$arch\n\n[antergos]\nSigLevel = TrustAll\nServer = https://mirrors.tuna.tsinghua.edu.cn/antergos/\$repo/\$arch\n&quot;|sudo tee -a /etc/pacman.conf升级系统：1sudo pacman -Syyu安装archlinuxcn签名钥匙&amp;antergos签名钥匙1sudo pacman -S --noconfirm archlinuxcn-keyring antergos-keyring6.中文输入法安装搜狗输入法#xfce桌面1sudo pacman -S --noconfirm fcitx-im fcitx-configtool fcitx-sogoupinyin安装搜狗输入法#kde桌面1sudo pacman -S --noconfirm fcitx-im kcm-fcitx fcitx-sogoupinyin#配置fcitx1sudo echo -e &quot;export GTK_IM_MODULE=fcitx\nexport QT_IM_MODULE=fcitx\nexport XMODIFIERS=@im=fcitx&quot;&gt;&gt;~/.xprofilethen restart.fcitx的激活输入法方式改为ctrl+逗号,避免jetbrains系列快捷键冲突额外的激活输入法快捷键禁用输入法切换取消,上一页下一页改为逗号句号在窗口间共享状态改为所有(所有的话就是windows的习惯)#对于jetbrians系列fcitx无法跟随的情况 fcitx输入法配置&gt;附加组件&gt;勾选高级&gt;xim前端&gt;勾选on the spot7.中文汉化#切换系统语言为中文，可以在登录界面右下角选择zh_CN.utf8然后重启login screen choose zh_CN.UTF8then restart.1sudo pacman -S --noconfirm firefox-i18n-zh-cn thunderbird-i18n-zh-cn gimp-help-zh_cn libreoffice-still-zh-CN man-pages-zh_cn7-1.火狐汉化https://support.mozilla.org/en-US/kb/use-firefox-interface-other-languages-language-pack安装火狐汉化$ sudo pacman -S firefox-i18n-zh-cn在add-ons检查language是否已包含。如果已包含，在火狐浏览器中敲about:config然后回车。搜索intl.locale.requested如果没有那么右键new一个 键是 intl.locale.requested 值 是 zh_CN。最后重启Firefox,解决。8.中文字体1sudo pacman -S --noconfirm wqy-microhei &amp;&amp; fc-cache -fv安装完可以 在”外观&gt;字体”中设置应用程序的默认字体。可以在”QT5设置&gt;字体”设置qt窗体的默认字体。还可以在各个应用程序中，如notepadqq中设置显示的字体。其他文泉驿家族：$ sudo pacman -S wqy-microhei-lite$ sudo pacman -S wqy-bitmapfont$ sudo pacman -S wqy-zenhei选用：$ sudo pacman -S adobe-source-han-sans-cn-fonts$ sudo pacman -S adobe-source-han-serif-cn-fonts$ sudo pacman -S noto-fonts-cjk9.AUR助手yaourtManjaro有自己的图形化包管理器,pamac，当然也可以命令行使用archlinux系的，还有AUR助手 yaourt 更方便。Yaourt可用于查找软件包(包括[core][extra] [community] AUR的软件包，pacman只能查找非AUR的软件包)。1sudo pacman -S --noconfirm yaourt10.桌面菜单或启动器应用程序配置项，即 .desktop 文件是原信息资源和应用程序快捷图标的集合。系统程序的配置项通常位于 /usr/share/applications 或 /usr/local/share/applications目录，单用户安装的程序位于 ~/.local/share/applications 目录，优先使用用户的配置项。1cd ~/.local/share/applications[Desktop Entry]Type=ApplicationVersion=1.0Name=IntelliJ IDEAExec=/opt/ide/idea/bin/idea.shIcon=/opt/ide/idea/bin/idea.pngTerminal=falseCategories=Development;Languages;Java;11.快速设置系统全面更新1sudo pacman -Syyu --noconfirm登录后开启数字锁1yaourt -S --noconfirm systemd-numlockontty&amp;&amp;sudo systemctl enable numLockOnTty.service安装常用软件1yaourt -Sy --noconfirm netease-cloud-music smplayer smplayer-skins smplayer-themes google-chrome sublime-text-dev-zh-cn masterpdfeditor remarkable uget filezilla shadowsocks-qt5 deepin-screenshot shutternetease-cloud-music 网易云音乐；smplayer 视频播放器；google-chrome 谷歌浏览器；notepadqq 像notepad++文本编辑；sublime-text-dev-zh-cn 强大的开发必备文本编辑器；(有能力采用付费许可证)masterpdfeditor 对linux用户免费的PDF浏览及编辑器，支持实时预览；remarkable 卓越且功能齐全的 Markdown 编辑器；uget 媲美迅雷的下载工具；filezilla 强大的FTP工具；shadowsocks-qt5 翻墙工具，配合浏览器插件SwitchyOmega使用；deepin-screenshot 深度截图工具；shutter 强大的截图工具，gnome-web-photo配合使用；variety 随即更换壁纸的应用；ccal 终端农历日历，终端启动ccal；1yaourt -Sy --noconfirm bleachbit redshiftbleachbit 快速释放磁盘空间并不知疲倦地守卫你的隐私。释放缓存，删除 cookie，清除互联网浏览历史，清理临时文件，删除日志，以及更多功能…i-nex 小而全的系统信息查看软件；redshift 根据你的周边调整你屏幕的色温。当你夜晚在屏幕前工作时，它也许能帮助你减少对眼睛的伤害；1yaourt -Sy --noconfirm keepassx-git screenfetch-git freefilesync #需要网络gitkeepassx-git 密码管理器；screenfetch-git 系统信息工具，终端使用screenfetch命令；freefilesync 文件夹比较和同步工具；生产力1yaourt -Sy --noconfirm wiznote meld goldendict easystroke catfish peekwiznote 为知笔记；meld 文本比较；goldendict 词典软件；easystroke 鼠标手势；catfish 基于GTK+的非常快速，轻量级的文件搜索工具；peek 屏幕录像工具，小巧玲珑，可保存录像为gif动图和兼容于html5的webm视频；1yaourt -Sy --noconfirm xmind #需要网络xmind 跨平台的思维导图工具，关键还是可以导入MindManage的文件；编程开发1yaourt -Sy --noconfirm eclipse-jee jetbrains-toolbox openjdk8-doc openjdk8-src dbeaver dbeaver-plugin-apache-poi dbeaver-plugin-batik dbeaver-plugin-officeeclipse-jee 企业Java 集成开发环境；jetbrains-toolbox 著名的jetbrains序列的IDE管理工具；openjdk8-doc openjdk8-src 针对OpenJDK8的文档和源码；dbeaver 通用数据库客户端，支持多个平台及多种数据库，社区版是免费的；1yaourt -Sy --noconfirm nginx tomcat8 zookeeperdbeaver 通用数据库客户端，支持多个平台及多种数据库，社区版是免费的；nginx 终端执行 sudo nginx 启动，sudo nginx -s stop/realod 停止或重启；tomcat8 开发必备，轻量的应用服务器；zookeeper 终端执行sudo zkServer.sh start 启动；虚拟机（全面更新系统重启后最后安装）1sudo pacman -Sy virtualbox linux414-virtualbox-host-modules virtualbox-ext-oraclevirtualbox 虚拟机工具，linux首选，比vmware还好用。linux414-virtualbox-host-modules 根据安装的内核版本选择，比如有 uname -r 如果是4.14内核，则安装 linux414-virtualbox-host-modules ；展示Linux系统信息(装逼)1screenfetch]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Tools</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装MySQL]]></title>
    <url>%2Fposts%2Fdf149a46%2F</url>
    <content type="text"><![CDATA[总所周知，MySQL 被 Oracle 收购后，CentOS 的镜像仓库中提供的默认的数据库也变为了 MariaDB，如果想了解 MariaDB 和 CentOS 的区别，可以参考官网介绍，想用 MariaDB 的同学可以参考 MariaDB 安装指南言归正传，在 CentOS 上安装 MySQL 差不多有四个步骤添加 MySQL YUM 源根据自己的操作系统选择合适的安装源，和其他公司一样，总会让大家注册账号获取更新，注意是 Oracle 的账号，如果不想注册，下方有直接下载的地址，下载之后通过 rpm -Uvh 安装。123456789101112131415161718192021$wget 'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm'$sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpm$yum repolist all | grep mysqlmysql-cluster-7.5-community/x86_64 MySQL Cluster 7.5 Community disabledmysql-cluster-7.5-community-source MySQL Cluster 7.5 Community - disabledmysql-cluster-7.6-community/x86_64 MySQL Cluster 7.6 Community disabledmysql-cluster-7.6-community-source MySQL Cluster 7.6 Community - disabledmysql-connectors-community/x86_64 MySQL Connectors Community enabled: 51mysql-connectors-community-source MySQL Connectors Community - disabledmysql-tools-community/x86_64 MySQL Tools Community enabled: 63mysql-tools-community-source MySQL Tools Community - Sourc disabledmysql-tools-preview/x86_64 MySQL Tools Preview disabledmysql-tools-preview-source MySQL Tools Preview - Source disabledmysql55-community/x86_64 MySQL 5.5 Community Server disabledmysql55-community-source MySQL 5.5 Community Server - disabledmysql56-community/x86_64 MySQL 5.6 Community Server disabledmysql56-community-source MySQL 5.6 Community Server - disabledmysql57-community/x86_64 MySQL 5.7 Community Server enabled: 267mysql57-community-source MySQL 5.7 Community Server - disabledmysql80-community/x86_64 MySQL 8.0 Community Server disabledmysql80-community-source MySQL 8.0 Community Server - disabled可以看出该安装源包含了MySQL5.5，5.6，5.7和8.0四个版本，默认安装的是MySQL5.7版本。选择安装版本如果想安装最新版本的，直接使用 yum 命令即可1$sudo yum install mysql-community-server如果想要安装 5.6 版本的，有2个方法。命令行支持 yum-config-manager 命令的话，可以使用如下命令：123456789101112131415161718192021$ sudo dnf config-manager --disable mysql57-community$ sudo dnf config-manager --enable mysql56-community$yum repolist all | grep mysqlmysql-cluster-7.5-community/x86_64 MySQL Cluster 7.5 Community disabledmysql-cluster-7.5-community-source MySQL Cluster 7.5 Community - disabledmysql-cluster-7.6-community/x86_64 MySQL Cluster 7.6 Community disabledmysql-cluster-7.6-community-source MySQL Cluster 7.6 Community - disabledmysql-connectors-community/x86_64 MySQL Connectors Community enabled: 51mysql-connectors-community-source MySQL Connectors Community - disabledmysql-tools-community/x86_64 MySQL Tools Community enabled: 63mysql-tools-community-source MySQL Tools Community - Sourc disabledmysql-tools-preview/x86_64 MySQL Tools Preview disabledmysql-tools-preview-source MySQL Tools Preview - Source disabledmysql55-community/x86_64 MySQL 5.5 Community Server disabledmysql55-community-source MySQL 5.5 Community Server - disabledmysql56-community/x86_64 MySQL 5.6 Community Server enabledmysql56-community-source MySQL 5.6 Community Server - disabledmysql57-community/x86_64 MySQL 5.7 Community Server disabled: 267mysql57-community-source MySQL 5.7 Community Server - disabledmysql80-community/x86_64 MySQL 8.0 Community Server disabledmysql80-community-source MySQL 8.0 Community Server - disabled或者直接修改 /etc/yum.repos.d/mysql-community.repo 这个文件1234567891011121314# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/7/$basearch/enabled=1 #表示当前版本是安装gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/enabled=0 #默认这个是 1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql通过设置 enabled 来决定安装哪个版本。设置好之后使用 yum 安装即可。启动 MySQL 服务启动命令很简单12345678910111213$sudo service mysqld start $sudo systemctl start mysqld #CentOS 7$sudo systemctl status mysqld #检查MySQL运行状态● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sun 2018-06-24 21:23:53 EDT; 20min ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 2776 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 2758 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 2779 (mysqld) CGroup: /system.slice/mysqld.service └─2779 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid说明已经正在运行中了。为了加强安全性，MySQL5.7为root用户随机生成了一个密码，在error log中，关于error log的位置，如果安装的是RPM包，则默认是/var/log/mysqld.log，使用sudo grep ‘temporary password’ / /var/log/mysqld.log查看。使用该密码登录数据库，然后修改密码：12$ mysql -uroot -p #输入查看到的密码mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;MyNewPass4!&apos;;若设置的密码太简单，会报ERROR 1819 (HY000): Your password does not satisfy the current policy requirements错误。如果一定要设置简单密码，需要修改两个全局参数：修改validate_password_policy参数的值mysql&gt; set global validate_password_policy=0;修改密码的长度mysql&gt; set global validate_password_length=1;再次修改密码就可以了。MySQL 5.6 的安全设置由于 5.7 版本在安装的时候就设置好了，不需要额外设置，但是 5.6 版本建议从安全角度完善下，运行官方脚本即可1$ mysql_secure_installation会提示设置5个关键位置设置 root 密码禁止 root 账号远程登录禁止匿名账号（anonymous）登录删除测试库是否确认修改安装第三方组件查看 yum 源中有哪些默认的组件：1$ yum --disablerepo=\* --enablerepo=&apos;mysql*-community*&apos; list available需要安装直接通过 yum 命令安装即可。修改编码在 /etc/my.cnf 中设置默认的编码123456789[client]default-character-set = utf8[mysqld]default-storage-engine = INNODBcharacter-set-server = utf8collation-server = utf8_general_ci #不区分大小写collation-server = utf8_bin #区分大小写collation-server = utf8_unicode_ci #比 utf8_general_ci 更准确创建数据库和用户创建数据库123456CREATE DATABASE &lt;datebasename&gt; CHARACTER SET utf8;CREATE USER &apos;username&apos;@&apos;host&apos; IDENTIFIED BY &apos;password&apos;;GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos;;SHOW GRANTS FOR &apos;username&apos;@&apos;host&apos;;REVOKE privilege ON databasename.tablename FROM &apos;username&apos;@&apos;host&apos;;DROP USER &apos;username&apos;@&apos;host&apos;;其中username：你将创建的用户名host：指定该用户在哪个主机上可以登陆，如果是本地用户可用 localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符 %password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器privileges：用户的操作权限，如 SELECT，INSERT，UPDATE 等，如果要授予所的权限则使用ALLdatabasename：数据库名tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用 表示，如 .*远程访问MySQL设置允许root用户在任何地方进行远程登录，并具有所有库任何操作权限。登录MySQL并输入以下命令12mysql&gt; mysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'youpassword' WITH GRANT OPTION; #授权操作mysql&gt; flush privileges; #刷新权限允许root用户在一个特定的IP进行远程登录，并具有所有库任何操作权限。登录MySQL并输入如下命令12mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@"172.16.16.152" IDENTIFIED BY "youpassword" WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES;允许root用户在一个特定的IP进行远程登录，并具有所有库特定操作权限，具体操作如下：12mysql&gt; GRANT select，insert，update，delete ON *.* TO root@"172.16.16.152" IDENTIFIED BY "youpassword";mysql&gt; FLUSH PRIVILEGES;删除用户授权，需要使用REVOKE命令，具体命令格式为：REVOKE privileges ON 数据库[.表名] FROM user-name;123mysql&gt; GRANT select，insert，update，delete ON TEST-DB TO test-user@"172.16.16.152" IDENTIFIED BY "youpassword"; # 授权操作mysql&gt; REVOKE all on TEST-DB from test-user; # 删除授权操作mysql&gt; FLUSH PRIVILEGES;防火墙设置开启3306端口12firewall-cmd --zone=public --add-port=3306/tcp --permanentfirewall-cmd --reload补充：操作防火墙命systemctl list-unit-files #查看服务systemctl enable firewalld #允许开机启动systemctl stop firewalld #停止systemctl disable firewalld #禁用开机启动firewall-cmd –state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）远程连接测试mysql -u 用户名 -p密码 -h 服务器IP地址 -P 服务器端MySQL端口号 -D 数据库名若正常连接，会进入数据库操作命令行界面。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>Linux</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy从零开始到掌握]]></title>
    <url>%2Fposts%2Fc28f24c2%2F</url>
    <content type="text"><![CDATA[HAProxy是什么HAProxy是一个免费的负载均衡软件，可以运行于大部分主流的Linux操作系统上。HAProxy提供了L4(TCP)和L7(HTTP)两种负载均衡能力，具备丰富的功能。HAProxy的社区非常活跃，版本更新快速。最关键的是，HAProxy具备媲美商用负载均衡器的性能和稳定性。因为HAProxy的上述优点，它当前不仅仅是免费负载均衡软件的首选，更几乎成为了唯一选择。HAProxy的核心能力和关键特性HAProxy的核心功能负载均衡：L4和L7两种模式，支持RR/静态RR/LC/IP Hash/URI Hash/URL_PARAM Hash/HTTP_HEADER Hash等丰富的负载均衡算法健康检查：支持TCP和HTTP两种健康检查模式会话保持：对于未实现会话共享的应用集群，可通过Insert Cookie/Rewrite Cookie/Prefix Cookie，以及上述的多种Hash方式实现会话保持SSL：HAProxy可以解析HTTPS协议，并能够将请求解密为HTTP后向后端传输HTTP请求重写与重定向监控与统计：HAProxy提供了基于Web的统计信息页面，展现健康状态和流量数据。基于此功能，使用者可以开发监控程序来监控HAProxy的状态HAProxy的关键特性性能采用单线程、事件驱动、非阻塞模型，减少上下文切换的消耗，能在1ms内处理数百个请求。并且每个会话只占用数KB的内存。大量精细的性能优化，如O(1)复杂度的事件检查器、延迟更新技术、Single-buffereing、Zero-copy forwarding等等，这些技术使得HAProxy在中等负载下只占用极低的CPU资源。HAProxy大量利用操作系统本身的功能特性，使得其在处理请求时能发挥极高的性能，通常情况下，HAProxy自身只占用15%的处理时间，剩余的85%都是在系统内核层完成的。HAProxy作者在8年前（2009）年使用1.4版本进行了一次测试，单个HAProxy进程的处理能力突破了10万请求/秒，并轻松占满了10Gbps的网络带宽。稳定性作为建议以单进程模式运行的程序，HAProxy对稳定性的要求是十分严苛的。按照作者的说法，HAProxy在13年间从未出现过一个会导致其崩溃的BUG，HAProxy一旦成功启动，除非操作系统或硬件故障，否则就不会崩溃（我觉得可能多少还是有夸大的成分）。在上文中提到过，HAProxy的大部分工作都是在操作系统内核完成的，所以HAProxy的稳定性主要依赖于操作系统，作者建议使用2.6或3.x的Linux内核，对sysctls参数进行精细的优化，并且确保主机有足够的内存。这样HAProxy就能够持续满负载稳定运行数年之久。个人的建议：使用3.x内核的Linux操作系统运行HAProxy运行HAProxy的主机上不要部署其他的应用，确保HAProxy独占资源，同时避免其他应用引发操作系统或主机的故障至少为HAProxy配备一台备机，以应对主机硬件故障、断电等突发情况（搭建双活HAProxy的方法在后文中有描述）sysctl的建议配置（并不是万用配置，仍然需要针对具体情况进行更精细的调整，但可以作为首次使用HAProxy的初始配置使用）：1234567net.ipv4.tcp_tw_reuse = 1net.ipv4.ip_local_port_range = 1024 65023net.ipv4.tcp_max_syn_backlog = 10240net.ipv4.tcp_max_tw_buckets = 400000net.ipv4.tcp_max_orphans = 60000net.ipv4.tcp_synack_retries = 3net.core.somaxconn = 10000HAProxy的安装和运行下面介绍在CentOS7中安装和运行HAProxy最新稳定版(1.7.2)的方法安装为HAProxy创建用户和用户组，此例中用户和用户组都是”ha”。注意，如果想要让HAProxy监听1024以下的端口，则需要以root用户来启动下载并解压12wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.2.tar.gztar -xzf haproxy-1.7.2.tar.gz编译并安装12make PREFIX=/home/ha/haproxy TARGET=linux2628make install PREFIX=/home/ha/haproxyPREFIX为指定的安装路径，TARGET则根据当前操作系统内核版本指定：12345- linux22 for Linux 2.2- linux24 for Linux 2.4 and above (default)- linux24e for Linux 2.4 with support for a working epoll (&gt; 0.21)- linux26 for Linux 2.6 and above- linux2628 for Linux 2.6.28, 3.x, and above (enables splice and tproxy)此例中，我们的操作系统内核版本为3.10.0，所以TARGET指定为linux2628创建HAProxy配置文件12mkdir -p /home/ha/haproxy/confvi /home/ha/haproxy/conf/haproxy.cfg我们先创建一个最简单配置文件：1234567891011121314151617global #全局属性 daemon #以daemon方式在后台运行 maxconn 256 #最大同时256连接 pidfile /home/ha/haproxy/conf/haproxy.pid #指定保存HAProxy进程号的文件defaults #默认参数 mode http #http模式 timeout connect 5000ms #连接server端超时5s timeout client 50000ms #客户端响应超时50s timeout server 50000ms #server端响应超时50sfrontend http-in #前端服务http-in bind *:8080 #监听8080端口 default_backend servers #请求转发至名为"servers"的后端服务backend servers #后端服务servers server server1 127.0.0.1:8000 maxconn 32 #backend servers中只有一个后端服务，名字叫server1，起在本机的8000端口，HAProxy同时最多向这个服务发起32个连接更加详细的配置会在后面章节中进行说明注意：HAProxy要求系统的ulimit -n参数大于[maxconn*2+18]，在设置较大的maxconn时，注意检查并修改ulimit -n参数将HAProxy注册为系统服务在/etc/init.d目录下添加HAProxy服务的启停脚本：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556vi /etc/init.d/haproxy#! /bin/shset -ePATH=/sbin:/bin:/usr/sbin:/usr/bin:/home/ha/haproxy/sbinPROGDIR=/home/ha/haproxyPROGNAME=haproxyDAEMON=$PROGDIR/sbin/$PROGNAMECONFIG=$PROGDIR/conf/$PROGNAME.cfgPIDFILE=$PROGDIR/conf/$PROGNAME.pidDESC="HAProxy daemon"SCRIPTNAME=/etc/init.d/$PROGNAME# Gracefully exit if the package has been removed.test -x $DAEMON || exit 0start()&#123; echo -e "Starting $DESC: $PROGNAME\n" $DAEMON -f $CONFIG echo "."&#125;stop()&#123; echo -e "Stopping $DESC: $PROGNAME\n" haproxy_pid="$(cat $PIDFILE)" kill $haproxy_pid echo "."&#125;restart()&#123; echo -e "Restarting $DESC: $PROGNAME\n" $DAEMON -f $CONFIG -p $PIDFILE -sf $(cat $PIDFILE) echo "."&#125;case "$1" in start) start ;; stop) stop ;; restart) restart ;; *) echo "Usage: $SCRIPTNAME &#123;start|stop|restart&#125;" &gt;&amp;2 exit 1 ;;esacexit 0运行启动、停止和重启：123service haproxy startservice haproxy stopservice haproxy restart添加日志HAProxy不会直接输出文件日志，所以我们要借助Linux的rsyslog来让HAProxy输出日志修改haproxy.cfg在global域和defaults域中添加：12345678910global ... log 127.0.0.1 local0 info log 127.0.0.1 local1 warning ...defaults ... log global ...意思是将info级（及以上）的日志推送到rsyslog的local0接口，将warn级（及以上）的日志推送到rsyslog的local1接口，并且所有frontend都默认使用global中的日志配置。注：info级的日志会打印HAProxy处理的每一条请求，会占用很大的磁盘空间，在生产环境中，建议将日志级别调整为notice为rsyslog添加haproxy日志的配置1vi /etc/rsyslog.d/haproxy.conf123456$ModLoad imudp$UDPServerRun 514$FileCreateMode 0644 #日志文件的权限$FileOwner ha #日志文件的ownerlocal0.* /var/log/haproxy.log #local0接口对应的日志输出文件local1.* /var/log/haproxy_warn.log #local1接口对应的日志输出文件修改rsyslog的启动参数1vi /etc/sysconfig/rsyslog12345# Options for rsyslogd# Syslogd options are deprecated since rsyslog v3.# If you want to use them, switch to compatibility mode 2 by "-c 2"# See rsyslogd(8) for more detailsSYSLOGD_OPTIONS="-c 2 -r -m 0"重启rsyslog和HAProxy12service rsyslog restartservice haproxy restart此时就应该能在/var/log目录下看到haproxy的日志文件了用logrotate进行日志切分通过rsyslog输出的日志是不会进行切分的，所以需要依靠Linux提供的logrotate来进行切分工作使用root用户，创建haproxy日志切分配置文件：12mkdir /root/logrotatevi /root/logrotate/haproxy12345678910111213/var/log/haproxy.log /var/log/haproxy_warn.log &#123; #切分的两个文件名 daily #按天切分 rotate 7 #保留7份 create 0644 ha ha #创建新文件的权限、用户、用户组 compress #压缩旧日志 delaycompress #延迟一天压缩 missingok #忽略文件不存在的错误 dateext #旧日志加上日志后缀 sharedscripts #切分后的重启脚本只运行一次 postrotate #切分后运行脚本重载rsyslog，让rsyslog向新的日志文件中输出日志 /bin/kill -HUP $(/bin/cat /var/run/syslogd.pid 2&gt;/dev/null) &amp;&gt;/dev/null endscript&#125;并配置在crontab中运行：10 0 * * * /usr/sbin/logrotate /root/logrotate/haproxy使用HAProxy搭建L7负载均衡器总体方案本节中，我们将使用HAProxy搭建一个L7负载均衡器，应用如下功能负载均衡会话保持健康检查根据URI前缀向不同的后端集群转发监控页面架构如下：架构中共有6个后端服务，划分为3组，每组中2个服务：ms1：服务URI前缀为ms1/的请求ms2：服务URI前缀为ms2/的请求def：服务其他请求搭建搭建后端服务部署6个后端服务，可以使用任意的Web服务，如Nginx、Apache HTTPD、Tomcat、Jetty等，具体Web服务的安装过程省略。此例中，我们在192.168.8.111和192.168.8.112两台主机上分别安装了3个Nginx：ms1.srv1 - 192.168.8.111:8080ms1.srv2 - 192.168.8.112:8080ms2.srv1 - 192.168.8.111:8081ms2.srv2 - 192.168.8.112:8081def.srv1 - 192.168.8.111:8082def.srv2 - 192.168.8.112:8082在这6个Nginx服务分别部署健康检查页面healthCheck.html，页面内容任意。确保通过http://ip:port/healthCheck.html可以访问到这个页面接下来在6个Nginx服务中部署服务页面：在第一组中部署ms1/demo.html在第二组中部署ms2/demo.html在第三组中部署def/demo.htmldemo.html的内容，以部署在192.168.8.111:8080上的为例：Hello! This is ms1.srv1!部署在192.168.8.112:8080上的就应该是Hello! This is ms1.srv2!以此类推搭建HAProxy在192.168.8.110主机安装HAProxyHAProxy的安装和配置步骤如上一章中描述，此处略去HAProxy配置文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657global daemon maxconn 30000 #ulimit -n至少为60018 user ha pidfile /home/ha/haproxy/conf/haproxy.pid log 127.0.0.1 local0 info log 127.0.0.1 local1 warningdefaults mode http log global option http-keep-alive #使用keepAlive连接 option forwardfor #记录客户端IP在X-Forwarded-For头域中 option httplog #开启httplog，HAProxy会记录更丰富的请求信息 timeout connect 5000ms timeout client 10000ms timeout server 50000ms timeout http-request 20000ms #从连接创建开始到从客户端读取完整HTTP请求的超时时间，用于避免类DoS攻击 option httpchk GET /healthCheck.html #定义默认的健康检查策略frontend http-in bind *:9001 maxconn 30000 #定义此端口上的maxconn acl url_ms1 path_beg -i /ms1/ #定义ACL，当uri以/ms1/开头时，ACL[url_ms1]为true acl url_ms2 path_beg -i /ms2/ #同上，url_ms2 use_backend ms1 if url_ms1 #当[url_ms1]为true时，定向到后端服务群ms1中 use_backend ms2 if url_ms2 #当[url_ms2]为true时，定向到后端服务群ms2中 default_backend default_servers #其他情况时，定向到后端服务群default_servers中backend ms1 #定义后端服务群ms1 balance roundrobin #使用RR负载均衡算法 cookie HA_STICKY_ms1 insert indirect nocache #会话保持策略，insert名为"HA_STICKY_ms1"的cookie #定义后端server[ms1.srv1]，请求定向到该server时会在响应中写入cookie值[ms1.srv1] #针对此server的maxconn设置为300 #应用默认健康检查策略，健康检查间隔和超时时间为2000ms，两次成功视为节点UP，三次失败视为节点DOWN server ms1.srv1 192.168.8.111:8080 cookie ms1.srv1 maxconn 300 check inter 2000ms rise 2 fall 3 #同上，inter 2000ms rise 2 fall 3是默认值，可以省略 server ms1.srv2 192.168.8.112:8080 cookie ms1.srv2 maxconn 300 checkbackend ms2 #定义后端服务群ms2 balance roundrobin cookie HA_STICKY_ms2 insert indirect nocache server ms2.srv1 192.168.8.111:8081 cookie ms2.srv1 maxconn 300 check server ms2.srv2 192.168.8.112:8081 cookie ms2.srv2 maxconn 300 checkbackend default_servers #定义后端服务群default_servers balance roundrobin cookie HA_STICKY_def insert indirect nocache server def.srv1 192.168.8.111:8082 cookie def.srv1 maxconn 300 check server def.srv2 192.168.8.112:8082 cookie def.srv2 maxconn 300 checklisten stats #定义监控页面 bind *:1080 #绑定端口1080 stats refresh 30s #每30秒更新监控数据 stats uri /stats #访问监控页面的uri stats realm HAProxy\ Stats #监控页面的认证提示 stats auth admin:admin #监控页面的用户名和密码修改完成后，启动HAProxy1service haproxy start测试首先，访问一下监控页面http://192.168.8.110:1080/stats 并按提示输入用户名密码接下来就能看到监控页面：)监控页面中列出了我们配置的所有frontend和backend服务，以及它们的详细指标。如连接数，队列情况，session rate，流量，后端服务的健康状态等等接下来，我们一一测试在HAProxy中配置的功能健康检查从监控页面中就可以直接看出健康检查配置的是否正确，上图中可以看到，backend ms1、ms2、default_servers下属的6个后端服务的Status都是20h28m UP，代表健康状态已持续了20小时28分钟，而LastChk显示L7OK/200 in 1ms则代表在1ms前进行了L7的健康检查（即HTTP请求方式的健康检查），返回码为200此时我们将ms1.srv1中的healthCheck.html改名1mv healthCheck.html healthCheck.html.bak然后再去看监控页面：ms1.srv1的状态变成了2s DOWN，LastChk则是L7STS/404 in 2ms，代表上次健康检查返回了404再恢复healthCheck.html，很快就能看到ms1.srv1重新恢复到UP状态通过URI前缀转发请求访问http://192.168.8.110:9001/ms1/demo.html ：可以看到成功定向到了ms1.srv1上访问http://192.168.8.110:9001/ms2/demo.html :访问http://192.168.8.110:9001/def/demo.html :3） 负载均衡和会话保持策略在分别访问过ms1/demo.html, ms2/demo.html, m3/demo.html后，查看一下浏览器的Cookie：可以看到HAProxy已经回写了三个用于会话保持的cookie，此时反复刷新这三个页面，会发现总是被定向到*.srv1上接下来我们删除HA_STICKY_ms1这条cookie，然后再访问ms1/demo.html，会看到：同时也被新写入了一条Cookie：如果发现仍然被定位到ms1.srv1，同时也没有写入新的HA_STICKY_ms1 Cookie，那么可能是浏览器缓存了ms1/demo.html页面，请求并没有到达HAProxy。F5刷新一下应该就可以了。使用HAProxy搭建L4负载均衡器HAProxy作为L4负载均衡器工作时，不会去解析任何与HTTP协议相关的内容，只在传输层对数据包进行处理。也就是说，以L4模式运行的HAProxy，无法实现根据URL向不同后端转发、通过cookie实现会话保持等功能。同时，在L4模式下工作的HAProxy也无法提供监控页面。但作为L4负载均衡器的HAProxy能够提供更高的性能，适合于基于套接字的服务（如数据库、消息队列、RPC、邮件服务、Redis等），或不需要逻辑规则判断，并已实现了会话共享的HTTP服务。总体方案本例中，我们使用HAProxy以L4方式来代理两个HTTP服务，不提供会话保持。1234567891011121314151617181920212223242526global daemon maxconn 30000 #ulimit -n至少为60018 user ha pidfile /home/ha/haproxy/conf/haproxy.pid log 127.0.0.1 local0 info log 127.0.0.1 local1 warningdefaults mode tcp log global option tcplog #开启tcplog timeout connect 5000ms timeout client 10000ms timeout server 10000ms #TCP模式下，应将timeout client和timeout server设置为一样的值，以防止出现问题 option httpchk GET /healthCheck.html #定义默认的健康检查策略frontend http-in bind *:9002 maxconn 30000 #定义此端口上的maxconn default_backend default_servers #请求定向至后端服务群default_serversbackend default_servers #定义后端服务群default_servers balance roundrobin server def.srv1 192.168.8.111:8082 maxconn 300 check server def.srv2 192.168.8.112:8082 maxconn 300 checkL4模式下的会话保持虽然TCP模式下的HAProxy无法通过HTTP Cookie实现会话保持，但可以很方便的实现基于客户端IP的会话保持。只需将1balance roundrobin改为1balance source此外，HAProxy提供了强大的stick-table功能，HAProxy可以从传输层的数据包中采样出大量的属性，并将这些属性作为会话保持的策略写入stick-table中。本文中不对stick-table进行深入探讨，如需要了解，可参考官方文档configuration.html#4-stick-tableHAProxy关键配置详解总览HAProxy的配置文件共有5个域global：用于配置全局参数default：用于配置所有frontend和backend的默认属性frontend：用于配置前端服务（即HAProxy自身提供的服务）实例backend：用于配置后端服务（即HAProxy后面接的服务）实例组listen：frontend+backend的组合配置，可以理解成更简洁的配置方法global域的关键配置daemon：指定HAProxy以后台模式运行，通常情况下都应该使用这一配置user [username] ：指定HAProxy进程所属的用户group [groupname] ：指定HAProxy进程所属的用户组log [address] [device] [maxlevel] [minlevel]：日志输出配置，如log 127.0.0.1 local0 info warning，即向本机rsyslog或syslog的local0输出info到warning级别的日志。其中[minlevel]可以省略。HAProxy的日志共有8个级别，从高到低为emerg/alert/crit/err/warning/notice/info/debugpidfile ：指定记录HAProxy进程号的文件绝对路径。主要用于HAProxy进程的停止和重启动作。maxconn ：HAProxy进程同时处理的连接数，当连接数达到这一数值时，HAProxy将停止接收连接请求frontend域的关键配置acl [name] [criterion] [flags] [operator] [value]：定义一条ACL，ACL是根据数据包的指定属性以指定表达式计算出的true/false值。如”acl url_ms1 path_beg -i /ms1/“定义了名为url_ms1的ACL，该ACL在请求uri以/ms1/开头（忽略大小写）时为truebind [ip]:[port]：frontend服务监听的端口default_backend [name]：frontend对应的默认backenddisabled：禁用此frontendhttp-request [operation] [condition]：对所有到达此frontend的HTTP请求应用的策略，例如可以拒绝、要求认证、添加header、替换header、定义ACL等等。http-response [operation] [condition]：对所有从此frontend返回的HTTP响应应用的策略，大体同上log：同global域的log配置，仅应用于此frontend。如果要沿用global域的log配置，则此处配置为log globalmaxconn：同global域的maxconn，仅应用于此frontendmode：此frontend的工作模式，主要有http和tcp两种，对应L7和L4两种负载均衡模式option forwardfor：在请求中添加X-Forwarded-For Header，记录客户端ipoption http-keep-alive：以KeepAlive模式提供服务option httpclose：与http-keep-alive对应，关闭KeepAlive模式，如果HAProxy主要提供的是接口类型的服务，可以考虑采用httpclose模式，以节省连接数资源。但如果这样做了，接口的调用端将不能使用HTTP连接池option httplog：开启httplog，HAProxy将会以类似Apache HTTP或Nginx的格式来记录请求日志option tcplog：开启tcplog，HAProxy将会在日志中记录数据包在传输层的更多属性stats uri [uri]：在此frontend上开启监控页面，通过[uri]访问stats refresh [time]：监控数据刷新周期stats auth [user]:[password]：监控页面的认证用户名密码timeout client [time]：指连接创建后，客户端持续不发送数据的超时时间timeout http-request [time]：指连接创建后，客户端没能发送完整HTTP请求的超时时间，主要用于防止DoS类攻击，即创建连接后，以非常缓慢的速度发送请求包，导致HAProxy连接被长时间占用use_backend [backend] if|unless [acl]：与ACL搭配使用，在满足/不满足ACL时转发至指定的backendbackend域的关键配置acl：同frontend域balance [algorithm]：在此backend下所有server间的负载均衡算法，常用的有roundrobin和source，完整的算法说明见官方文档configuration.html#4.2-balancecookie：在backend server间启用基于cookie的会话保持策略，最常用的是insert方式，如cookie HA_STICKY_ms1 insert indirect nocache，指HAProxy将在响应中插入名为HA_STICKY_ms1的cookie，其值为对应的server定义中指定的值，并根据请求中此cookie的值决定转发至哪个server。indirect代表如果请求中已经带有合法的HA_STICK_ms1 cookie，则HAProxy不会在响应中再次插入此cookie，nocache则代表禁止链路上的所有网关和缓存服务器缓存带有Set-Cookie头的响应。default-server：用于指定此backend下所有server的默认设置。具体见下面的server配置。disabled：禁用此backendhttp-request/http-response：同frontend域log：同frontend域mode：同frontend域option forwardfor：同frontend域option http-keep-alive：同frontend域option httpclose：同frontend域option httpchk [METHOD] [URL] [VERSION]：定义以http方式进行的健康检查策略。如option httpchk GET /healthCheck.html HTTP/1.1option httplog：同frontend域option tcplog：同frontend域server [name] [ip]:[port] [params]：定义backend中的一个后端server，[params]用于指定这个server的参数，常用的包括有：check：指定此参数时，HAProxy将会对此server执行健康检查，检查方法在option httpchk中配置。同时还可以在check后指定inter, rise, fall三个参数，分别代表健康检查的周期、连续几次成功认为server UP，连续几次失败认为server DOWN，默认值是inter 2000ms rise 2 fall 3cookie [value]：用于配合基于cookie的会话保持，如cookie ms1.srv1代表交由此server处理的请求会在响应中写入值为ms1.srv1的cookie（具体的cookie名则在backend域中的cookie设置中指定）maxconn：指HAProxy最多同时向此server发起的连接数，当连接数到达maxconn后，向此server发起的新连接会进入等待队列。默认为0，即无限maxqueue：等待队列的长度，当队列已满后，后续请求将会发至此backend下的其他server，默认为0，即无限weight：server的权重，0-256，权重越大，分给这个server的请求就越多。weight为0的server将不会被分配任何新的连接。所有server默认weight为1timeout connect [time]：指HAProxy尝试与backend server创建连接的超时时间timeout check [time]：默认情况下，健康检查的连接+响应超时时间为server命令中指定的inter值，如果配置了timeout check，HAProxy会以inter作为健康检查请求的连接超时时间，并以timeout check的值作为健康检查请求的响应超时时间timeout server [time]：指backend server响应HAProxy请求的超时时间default域上文所属的frontend和backend域关键配置中，除acl、bind、http-request、http-response、use_backend外，其余的均可以配置在default域中。default域中配置了的项目，如果在frontend或backend域中没有配置，将会使用default域中的配置。listen域listen域是frontend域和backend域的组合，frontend域和backend域中所有的配置都可以配置在listen域下官方配置文档HAProxy的配置项非常多，支持非常丰富的功能，上文只列出了作为L7负载均衡器使用HAProxy时的一些关键参数。完整的参数说明请参见官方文档 configuration.html使用Keepalived实现HAProxy高可用尽管HAProxy非常稳定，但仍然无法规避操作系统故障、主机硬件故障、网络故障甚至断电带来的风险。所以必须对HAProxy实施高可用方案。下文将介绍利用Keepalived实现的HAProxy热备方案。即两台主机上的两个HAProxy实例同时在线，其中权重较高的实例为MASTER，MASTER出现问题时，另一台实例自动接管所有流量。原理在两台HAProxy的主机上分别运行着一个Keepalived实例，这两个Keepalived争抢同一个虚IP地址，两个HAProxy也尝试去绑定这同一个虚IP地址上的端口。显然，同时只能有一个Keepalived抢到这个虚IP，抢到了这个虚IP的Keepalived主机上的HAProxy便是当前的MASTER。Keepalived内部维护一个权重值，权重值最高的Keepalived实例能够抢到虚IP。同时Keepalived会定期check本主机上的HAProxy状态，状态OK时权重值增加。搭建HAProxy主备集群环境准备在两台物理机上安装并配置HAProxy，本例中，将在192.168.8.110和192.168.8.111两台主机上上安装两套完全一样的HAProxy，具体步骤省略，请参考“使用HAProxy搭建L7负载均衡器”一节。安装Keepalived下载，解压，编译，安装：12345wget http://www.keepalived.org/software/keepalived-1.2.19.tar.gztar -xzf keepalived-1.2.19.tar.gz./configure --prefix=/usr/local/keepalivedmakemake install注册为系统服务：1234cp /usr/local/keepalived/sbin/keepalived /usr/sbin/cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/chmod +x /etc/init.d/keepalived注意：Keepalived需要使用root用户进行安装和配置配置Keepalived创建并编辑配置文件123mkdir -p /etc/keepalived/cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/vi /etc/keepalived/keepalived.conf配置文件内容：12345678910111213141516171819202122232425global_defs &#123; router_id LVS_DEVEL #虚拟路由名称&#125;#HAProxy健康检查配置vrrp_script chk_haproxy &#123; script "killall -0 haproxy" #使用killall -0检查haproxy实例是否存在，性能高于ps命令 interval 2 #脚本运行周期 weight 2 #每次检查的加权权重值&#125;#虚拟路由配置vrrp_instance VI_1 &#123; state MASTER #本机实例状态，MASTER/BACKUP，备机配置文件中请写BACKUP interface enp0s25 #本机网卡名称，使用ifconfig命令查看 virtual_router_id 51 #虚拟路由编号，主备机保持一致 priority 101 #本机初始权重，备机请填写小于主机的值（例如100） advert_int 1 #争抢虚地址的周期，秒 virtual_ipaddress &#123; 192.168.8.201 #虚地址IP，主备机保持一致 &#125; track_script &#123; chk_haproxy #对应的健康检查配置 &#125;&#125;如果主机没有killall命令，则需要安装psmisc包：1yum intall psmisc分别启动两个Keepalived1service keepalived start验证启动后，先分别在两台主机查看虚IP 192.168.8.201由谁持有，执行命令：1ip addr sh enp0s25 （将enp0s25替换成主机的网卡名）持有虚IP的主机输出会是这样的：另一台主机输出则是这样的：如果你先启动备机的Keepalived，那么很有可能虚IP会被备机抢到，因为备机的权重配置只比主机低1，只要执行一次健康检查就能把权重提高到102，高于主机的101。此时访问http://192.168.8.201:9001/ms1/demo.html ，可以看到我们先前部署的网页。此时，检查/var/log/haproxy.log，能看到此请求落在了抢到了虚IP的主机上。接下来，我们停掉当前MASTER主机的HAProxy实例（或者Keepalive实例，效果一样）1service haproxy stop再次访问http://192.168.8.201:9001/ms1/demo.html ，并查看备机的/var/log/haproxy.log，会看到此请求落在了备机上，主备自动切换成功。也可以再次执行ip addr sh enp0s25命令，会看到虚IP被备机抢去了。在/var/log/message中，也能够看到keepalived输出的切换日志：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>HAProxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的itertools模块]]></title>
    <url>%2Fposts%2F4f4399bb%2F</url>
    <content type="text"><![CDATA[无限迭代器count(firstval=0, step=1)创建一个从firstval（默认值为0）开始，以step（默认值为1）为步长的无限整数迭代器。此迭代器不支持长整数，如果超出了sys.maxint，计数器将溢出并继续从-sys.maxint-1开始计算。123456for x, y in zip(count(1), ['a', 'b', 'c']): print(x, y)输出:1 a2 b3 ccycle(iterable)对iterable中的元素反复执行循环，返回生成的迭代器12345678index = 0for value in cycle('abcd'): index += 1 if index == 10: break print(value)输出：a b c d a b c d arepeat(object, [,items])返回一个迭代器，反复生成object，如果给定times，则重复次数为items，否则为无限1234for value in repeat('windylee', 5): print(value, end=' ')输出：windylee windylee windylee windylee windylee有限迭代器**chain(iterable1, iterable2, iterable3, …)chain接收多个可迭代对象作为参数，将他们连接起来，作为一个新的迭代器返回1234for value in chain([1, 2, 3], ['a', 'b', 'c']): print(value, end=' ')输出：1 2 3 a b ccompress(data, selectors)compress可用于对数据进行筛选，当selectors的元素为true时，则保留data对应位置的元素1234for value in compress([1, 2, 3, 4, 5], [True, False, False, True, True]): print(value, end=' ')输出:1 4 5dropwhile(predicate, iterable)创建一个迭代器，只要函数predicate(item)为True，就丢弃iterable中的项，如果predicate返回False，就会生成iterable中的项和所有后续项。123456789def predict(item): if item &lt; 3: return True return Falsefor value in dropwhile(predict, [1, 2, 3, 4, 5]): print(value, end=' ')输出：3 4 5takewhile(predicate, iterable)创建一个迭代器，只要函数predite(item)为True，就保留iterable中的项，如果predicate返回False，就会丢弃iterable中的项和所有的后续项。相当于dropwhile的反操作。123456789def predict(item): if item &lt; 3: return True return Falsefor value in takewhile(predict, [1, 2, 3, 4, 5]): print(value, end=' ')输出：1 2groupby(iterable[, keyfunc])返回一个产生按照keyfunc的返回值进行分组的值集合的迭代器。iterable是一个可迭代对象，keyfunc是分组函数，用于对iterable的连续项进行分组。如果不指定，则默认将iterable中连续相同的项作为一组，否则将keyfunc返回值相同的连续项作为一组。1234567891011def predict(item): if item &lt; 3 or item &gt; 7: return True return Falsefor key, value in groupby([1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10], predict): print(key, list(value))输出：True [1, 2]False [3, 4, 5, 5, 6, 7]True [8, 9, 10]starmap(function, iterable)创建一个迭代器，对于iterable中每一项item生成值func(*item)。1234for value in starmap(lambda x, y: x * y, [(0, 5), (1, 6), (2, 7), (3, 8), (4, 9)]): print(value, end=' ')输出：0 6 14 24 36tee(iterable, [, n])用于从iterable创建n个独立的迭代器，以元组的形式返回，n的默认值是2。由于生成的项会被缓存，并在所有新创建的迭代器中使用，所以一定要注意不要再调用tee()之后使用原始迭代器iterable，否则缓存机制可能无法正常工作。123456789iter1, iter2 = tee([1, 2, 3])for v1 in iter1: print(v1, end=' ')print()for v2 in iter2: print(v2, end=' ')输出：1 2 3 1 2 3zip_longest(*iterables, fillvalue=None)类似于内置函数zip，只不过迭代完最长的序列为止，短序列默认用None补齐。1234567for v1, v2 in zip_longest([1, 2, 3], ['a', 'b', 'c', 'd']): print(v1, v2)输出：1 a2 b3 cNone daccumulate(iterable, [,func])创建一个迭代器，返回从第一项到当前项的子列表执行reduce函数的值。func是一个二元函数12&gt;&gt;&gt; list(itertools.accumulate([1, 2, 3, 4], func=operator.add))[1, 3, 6, 10]组合生成器product(*iterables [,repeat=1])创建一个迭代器，生成多个可迭代对象的笛卡尔积，跟嵌套for循环等价，repeat用于指定重复生成序列的次数。123456for value in accumulate(['a', 'b', 'c']): print(value)输出：aababcpermutations(iterable, [, r]])创建一个迭代器，生成iterable中元素的排列，r用于指定生成排列的长度，如果省略r，生成的序列长度与iterable长度相同。123456789for value in permutations([1, 2, 3]): print(list(value))输出：[1, 2, 3][1, 3, 2][2, 1, 3][2, 3, 1][3, 1, 2][3, 2, 1]combinations(iterable, r)创建一个迭代器，生成iterable中所有长度为r的序列。序列中元素的排列顺序和iterable中元素顺序相同，序列中元素不重复123456for value in combinations([1, 2, 3], 2): print(list(value))输出：[1, 2][1, 3][2, 3]combinations_with_replacement(iterable, [, r])功能和combinations类似，不过该函数生成的序列中允许元素重复。123456789for value in combinations_with_replacement([1, 2, 3], 2): print(list(value))输出：[1, 1][1, 2][1, 3][2, 2][2, 3][3, 3]​]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String源码解析]]></title>
    <url>%2Fposts%2F827303fc%2F</url>
    <content type="text"><![CDATA[定义先看一下文档中的注释12345/** * Strings are constant; their values cannot be changed after they * are created. String buffers support mutable strings. * Because String objects are immutable they can be shared. */String对象是常量，创建之后就不能被修改，所以该对象可以被多线程共享。12345678910111213public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; private final char value[]; private int hash; // Default to 0 private static final long serialVersionUID = -6849794470754667710L; private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; ......&#125;从源码中可以看出，String是被final修饰的，说明该类不能被继承。并且实现了CharSequence, Comparable, Serializable接口。Serializable接口用于实现String的序列化和反序列化操作；Comparable接口用于实现字符串的比较操作；CharSequence是字符串类的父接口，StringBuffer和StringBuilder都继承自该接口。value字段是实现String类的底层数组，用于存储字符串内容。final修饰基本数据类型，那么在运行期间其内容不可变，如果修饰的是引用类型，那么引用的对象(包括数组)运行期地址不可变，但是对象的内容是可以改变的。hash字段用于缓存String对象的hash值，防止多次计算hash造成的时间损耗。因为String实现了Serializable接口，所以需要serialVersionUID字段用来在String反序列化时，通过对比字节流中的serialVersionUID和本地实体类中的serialVersionUID是否一致，如果相同就可以进行反序列化，否则就会抛出InvalidCastException异常。构造方法空参构造方法123public String() &#123; this.value = "".value;&#125;该构造方法会创建一个空的字符序列，因为字符串的不可变对象，之后对象的赋值会指向新的字符串，因此使用这种构造方法会多创建一个无用对象。使用字符串类型的对象初始化1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125;直接将源String中的value和hash两个属性直接赋值给目标String。因为String一旦定义之后就不可改变，所以也就不用担心源String的值会影响到目标String的值。使用字符数组初始化12345678910// 参数为char数组，通过java.utils包中的Arrays.copyOf复制public String(char value[]) &#123; this.value = Arrays.copyOf(value, value.length);&#125;// 使用字符数组的一部分初始化，通过Arrays.copyOfRange复制public String(char value[], int offset, int count) &#123; // 异常检测 ...... this.value = Arrays.copyOfRange(value, offset, offset+count);&#125;使用字节数组初始化在Java中，String实例保存有一个char[]字符数组，char[]字符数组是以Unicode编码方式存储的，String和char为内存形式，byte是网络传输或存储的序列化形式，所以在很多传输和存储过程中需要将byte[]数组和String进行相互转化。字节和字符自检的转化需要指定编码，不然很可能会出现乱码。String提供了多种字节数组的重载构造函数：123456public String(byte bytes[], int offset, int length, String charsetName)public String(byte bytes[], int offset, int length, Charset charset)public String(byte bytes[], String charsetName)public String(byte bytes[], Charset charset)public String(byte bytes[], int offset, int length)public String(byte bytes[])如果我们在使用 byte[] 构造 String 的时候，如果指定了charsetName或者charset参数的话，那么就会使用 StringCoding.decode 方法进行解码，使用的解码的字符集就是我们指定的 charsetName 或者 charset。如果没有指定解码使用的字符集的话，那么StringCoding的decode方法首先会使用系统的默认编码格式(ISO-8859-1)。使用StringBuffer和StringBuilder初始化123456789public String(StringBuffer buffer) &#123; synchronized(buffer) &#123; this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); &#125;&#125;public String(StringBuilder builder) &#123; this.value = Arrays.copyOf(builder.getValue(), builder.length());&#125;因为StringBuilder不是线程安全的，所以在初始化时不需要加锁；而StringBuilder则需要加锁。我们一般使用StringBuffer和StringBuilder的toString方法来获取String，而很少使用String的这两种构造方法。特殊的构造方法String除了提供了很多共有的构造方法，还提供了一个保护类型的构造方法：1234String(char[] value, boolean share) &#123; // assert share : "unshared not supported"; this.value = value;&#125;该方法和String(char[] value)有两点区别：该方法多了一个参数：boolean share，但该参数在函数中并没有使用。因此加入该参数的目的只是为了区分String(char[] value)方法，只有参数不同才能被重载。该方法直接修改了value数组的引用，也就是说共享char[] value数组。而String(char[] value)通过Arrays.copyOf将参数数组内容复制到String中。使用这种方式的的优点很明显：性能好，直接修改指针，避免了逐一拷贝。节约内存，底层共享同一字符数组。当然这种方式也存在缺点，如果外部修改了传进来的字符数组的内容，由于他们引用的是同一个数组，因此外部对数组的修改相当于修改了字符串。为了保证字符串对象的不变性，将其访问权限设置成了default，其他类无法通过该构造方法初始化字符串对象。这样一来，无论源字符串还是新字符串，其value数组本身都是String对象的私有属性，从外部无法访问，保证了String的安全性。该函数只能用在不能缩短String长度的函数中，如concat(str1, str2)，如果用在缩短String长度的函数如subString中会造成内存泄漏。经典方法技巧equals方法123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125;先判断两个对象的地址是否相等在判断是否是String类型如果都是String类型，就先比较长度是否相等，然后再逐一比较值。值的比较采取了短路操作，发现不一样的就返回falsecompareTo方法123456789101112131415161718public int compareTo(String anotherString) &#123; int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) &#123; char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) &#123; return c1 - c2; &#125; k++; &#125; return len1 - len2;&#125;从0开始逐一判断字符是否相等，若不相等则做差运算，巧妙的避免了三种判断情况。若字符都相等，接直接返回长度差值。所以在判断两个字符串大小时，使用是否为正数/负数/0，而不是通过1//-1/0判断。hashCode方法123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125;若第一次调用hashCode方法且value数组长度大于0，则通过算法s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]计算hash值。hash值很多时候用来判断两个对象的值是否相等，所以需要尽可能的避免冲突。选择31是因为31是一个素数，且i * 31可以通过(i &lt;&lt; 5) - 1来提高运算速度，现在很多虚拟机都有做相关优化。 hashCode可以保证相同的字符串的hash值肯定相同，但是，hash值相同并不一定是value值就相同。返回缓存的hash值。replaceFirst、replaceAll，replace区别1234String replaceFirst(String regex, String replacement)String replaceAll(String regex, String replacement)String replace(Char Sequencetarget, Char Sequencereplacement)String replace(CharSequence target, CharSequence replacement)replace的参数是char和CharSequence，既可以支持字符的替换，也支持字符串的替换replaceFirst和replaceAll的参数是regex，基于正则表达式替换replace和replaceAll方法会替换字符串中的全部字符或字符串，replaceFirst只替换第一次出现的字符或字符串copyValueOf和valueOfString的底层是通过char[]实现的，早期的String构造器的实现并不会拷贝数组。为了防止char[]数组被外部修改，提供了copyValueOf方法，每次都拷贝成新的字符数组来构造新的String对象。但是现在的String在构造器中就通过拷贝新数组实现，所以这两个方法在本质上已经没区别了。valueOf()有很多种重载形式：12345678910111213141516171819public static String valueOf(boolean b) &#123; return b ? "true" : "false"; &#125; public static String valueOf(char c) &#123; char data[] = &#123;c&#125;; return new String(data, true); &#125; public static String valueOf(int i) &#123; return Integer.toString(i); &#125; public static String valueOf(long l) &#123; return Long.toString(l); &#125; public static String valueOf(float f) &#123; return Float.toString(f); &#125; public static String valueOf(double d) &#123; return Double.toString(d);&#125;底层调用了基本数据类型的toString()方法。intern方法1public native String intern();intern方法是Native调用，它的作用是每当定义一个字符字面量，字面量进行字符串连接或final的String字面量初始化的变量的连接，都会检查常量池中是否有对应的字符串，如果有就不创建新的字符串，而是返回指向常量池对应字符串的引用。所有通过new String(str)方式创建的对象都会保存在堆中，而不是常量区。普通变量的连接，由于不能在编译期确定下来，所以不会储存在常量区。其他方法12345678910111213141516171819202122232425262728293031323334353637383940414243int length() //返回字符串长度boolean isEmpty() //返回字符串是否为空char charAt(int index) //返回字符串中第（index+1）个字符char[] toCharArray() //转化成字符数组void trim() //去掉两端空格String toUpperCase() //转化为大写String toLowerCase() //转化为小写String concat(String str) //拼接字符串String replace(char oldChar, char newChar) //将字符串中的oldChar字符换成newChar字符//以上两个方法都使用了String(char[] value, boolean share)；boolean matches(String regex) //判断字符串是否匹配给定的regex正则表达式boolean contains(CharSequence s) //判断字符串是否包含字符序列sString[] split(String regex, int limit) //按照字符regex将字符串分成limit份。String[] split(String regex) //按照regex表达式切分字符串 boolean equals(Object anObject) //比较对象 boolean contentEquals(String Buffersb) //与字符串比较内容 boolean contentEquals(Char Sequencecs) //与字符比较内容 boolean equalsIgnoreCase(String anotherString) //忽略大小写比较字符串对象 int compareTo(String anotherString) //比较字符串 int compareToIgnoreCase(String str) //忽略大小写比较字符串 boolean regionMatches(int toffset, String other, int ooffset, int len) //局部匹配 boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len) //可忽略大小写局部匹配String对“+”的重载Java不支持运算符重载，但是String可以通过+来连接两个字符串。那么java是如何实现对+的重载的呢？123456public class Main&#123; public static void main(String[] args)&#123; String str1 = "windy"; string str2 = str1 + "lee"; &#125;&#125;反编译Main.java，执行命令javap -c Main，输出结果：我们看到了StringBuilder，还有windy和lee，以及调用了StringBuilder的append和toString方法。既然编译器已经在底层为我们进行了优化，那么为什么还要提倡我们用StringBuilder呢？我们注意到在第3行代码，new了一个StringBuilder对象，如果实在一个循环里面，我们使用”+”号就会创建多个StringBuilder的对象。但是编译器事先不知道我们StringBuilder的长度，并不能事先分配好缓冲区，会加大内存的开销，而且使用重载的时候根据java的内存分配也会创建多个对象。switch对字符串支持的实现1234567891011121314public class Main &#123; public static void main(String[] args) &#123; String str = "world"; switch (str) &#123; case "hello": System.out.println("hello"); break; case "world": System.out.println("world"); break; default: break; &#125; &#125;&#125;反编译之后得到123456789101112131415public static void main(String args[]) &#123; String str = "world"; String s; switch((s = str).hashCode()) &#123; case 99162322: if(s.equals("hello")) System.out.println("hello"); break; case 113318802: if(s.equals("world")) System.out.println("world"); break; default: break; &#125; &#125;首先调用String的hashCode方法，拿到相应的Code，通过这个code然后给每个case唯一的标识判断时先获取对象的hashCode，进入对应的case分支通过equals方法进行安全检查，这个检查是必要的，因为哈希可能会发生冲突switch只支持整型，其他数据类型都是转换成整型之后在使用switch的总结String被final修饰，一旦被创建，无法修改final保证value不会指向其他的数组，但不保证数组内容不可修改private属性保证不可在类外访问数组，也就不能改变其内容String内部没有改变value内容的函数，保证String不可变String声明为final杜绝了通过集成的方法添加新的函数基于数组的构造方法，会拷贝数组元素，避免了通过外部引用修改value的情况用String构造其他可变对象时，返回的数组的拷贝final只在编译期有效，在运行期间无效，因此可以通过反射改变value引用的对象。反射虽然改变了s的内容，并没有创建新的对象。而且由于String缓存了hash值，所以通过反射改变字符数组内容，hashCode返回值不会自动更新。String类的所有方法都没有改变字符串本身的值，都是返回了一个新的对象。如果你需要一个可修改的字符串，应该使用StringBuilder或者 StringBuffer。如果你只需要创建一个字符串，你可以使用双引号的方式，如果你需要在堆中创建一个新的对象，你可以选择构造函数的方式。]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal深度解析]]></title>
    <url>%2Fposts%2Fcadd278f%2F</url>
    <content type="text"><![CDATA[ThreadLocal解决什么问题ThreadLocal不是用来解决共享对象的多线程访问问题的，不同的Thread通过ThreadLocal获取到的是不同的副本（实际是不同的实例）。线程内部的副本是其他线程不需要访问也是访问不到的。当某一个类不是线程安全，同时该类的实例需要在多个方法中被使用且每个线程需要自己独立的实例时，可以使用ThreadLocal来解决这一问题。ThreadLocal实现原理错误方式既然每个Thread通过ThreadLocal.get()获得的都是自己的一个副本，一个通常的实现方法是ThreadLocal自己维护一个Map，key是Thread，value是该线程中的副本。线程通过get()获取实例时，可以以线程（通过Thread.currentThread()获取当前线程）为key，从Map中找出对应的实例即可。但是该实现方式存在以下问题：Map作为全局变量，增加或减少线程均需要写Map，需要通过加锁来确保Map的线程安全性线程结束时，需要从该线程访问过的所有ThreadLocal中删除副本，否则可能会引起内存泄露正确方式为了提高ThreadLocal效率，需要去掉锁机制。如果Thread维护一个自己的Map，该Map存储所有用到的本地副本，这样每个Thread只需要访问自己的Map，不存在写冲突，也就不需要锁了。该方案虽然没有锁的问题，但是在每个线程内部都保存了该线程用到的本地副本。如果不删除这些引用，会导致这些副本无法被垃圾回收，造成内存泄露。ThreadLocal在JDK8中的实现ThreadLocalMap类ThreadLocalMap是ThreadLocal的静态内部类，对ThreadLocal进行的get、set操作最后都将委托给该类。同时每个Thread内部都有一个ThreadLocalMap变量，用于保存本线程用到的副本。它的结构如下：可以看到ThreadLocalMap有一个常量和三个成员变量：1234567891011121314151617181920/** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * The number of entries in the table. */ private int size = 0; /** * The next size value at which to resize. */ private int threshold; // Default to 0其中INITIAL_CAPACITY代表了这个Map的初始容量，即table的初始大小；table是一个Entry类型的数组，用于存储数据；size代表table中的存储数目；threshold代表需要扩容是对应size的阀值，默认为容量的2/3。Entry类Entry类是ThreadLocalMap的静态内部类，是线程本地副本真正保存的位置，源码如下：123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125;可见Entry继承自WeakReference&lt;ThreadLocal&lt;?&gt;&gt;，即每个Entry对象都有一个ThreadLocal的弱引用。这样当线程结束，没有引用指向线程内部的ThreadLocalMap变量时，table数组可以被垃圾回收，如此便可以防止内存泄露。Object类型的成员变量value，指向Thread用到的ThreadLocal中的本地副本。ThreadLocal.set()方法设置实例的方法如下所示：12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;线程首先通过getMap(thread)方法获取自身的ThreadLocalMap。因为ThreadLocalMap是线程私有的，只有该线程才能访问，其他线程访问不到，所有不用考虑线程安全问题。123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;从getMap源码中可见，该ThreadLocalMap的实例是Thread类的一个字段，即由ThreadLocal对象与具体实例的映射，这一点与上文分析一致。获取到ThreadLocalMap后，若map为null，调用createMap方法来创建一个ThreadLocalMap，在createMap中调用ThreadLocalMap的构造函数，返回设置了首元素的ThreadLocalMap。1234567ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);&#125;firstKey为当前调用的ThreadLocal，firstValue为set(T value)中的value。在构造函数中注意一个细节，计算下标i的时候采用了hashcode &amp; (size - 1)的算法，这相当于取模运算hashCode % size的一个更高效的实现。同时因为采用了该算法，size必须是2的指数，这可以使得hash发生冲突的次数减小。若map不为null，则调用ThreadLocalMap的set(ThreadLocal, Ojbect)方法将实例设置到table数组中。源码如下：1234567891011121314151617181920212223242526private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;首先计算该元素的hash值，如果冲突了，通过nextIndex方法再次计算hash值。nextIndex实际上获取数组的下一个下标，若已到数组最后一个元素则返回0，即返回到数组第一个元素。因此ThreadLocalMap解决冲突的方法是线性探测法。如果table中已经存在，则仅仅是更新Entry中的value值。如果entry里对应的key为null的话，表明该entry为staled entry，则调用replaceStaleEntry函数用于替换原有的key和value并进行一些清理操作(清理其他key为null的Entry防止内存泄露)，有兴趣的同学可以查看源码具体实现。若是经历了上面步骤没有命中hash，也没有发现无用的Entry，set方法就会创建一个新的Entry，并会进行启发式的垃圾清理，用于清理无用的Entry。主要通过cleanSomeSlots方法惊醒清理（清理时机通常为添加新元素或另一个无用的元素被回收时）。只要没有清理任何的stale entries并且size达到阀值的时候，就会触发rehash：1234567private void rehash() &#123; expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis if (size &gt;= threshold - threshold / 4) resize();&#125;rehash会先调用expungeStaleEntries函数，执行一次全表扫描，用于删除无用的entry。清理之后的size仍大于等于threshold的3/4时进行resize扩容（长度增加一倍）。通过replaceStaleEntry和rehash这两个方法会即时将table中无效的entry设置为null，从而使得entry可被回收，有效的防止了内存泄露。ThreadLocal.get()方法获取实例的方法如下所示12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;同set方法，首先通过getMap方法获取线程内部的ThreadLocalMap对象。若map和entry都不为null，说明线程内部存在对应副本，直接返回即可。若不存在，调用setInitialValue方法获取该ThreadLocal变量在该线程中对应的具体实例的初始值。12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;该方法为private方法，无法被重载。但是在方法中首先调用了initialValue方法来获取初始值。123protected T initialValue() &#123; return null;&#125;initialValue方法是protected的，说明是用来被继承的。所以在使用ThreadLocal时通常会重载该方法。拿到该线程对应的ThreadLocalMap对象，如该对象不为null，则直接将该ThreadLocal对象与对应实例初始值的映射set到该map中，否则创建该map并将其添加其中。若map存在，get操作最终会调用ThreadLocalMap的getEntry方法：12345678910111213141516171819202122232425private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125;hash以后如果是ThreadLocal对应的Entry就返回，否则调用getEntryAfterMiss方法，根据线性探测法继续查找，直到找到或对应entry为null，并返回。ThreadLocal.remove()方法删除实例的方法如下所示123456public void remove()&#123; ThreadLOcalMap m = getMap(Thread.currentThread()); if (m != null)&#123; m.remove(this); &#125;&#125;同理，remove方法也是先获取Thread中的ThreadLocalMap实例。若map不为null，这调用map的remove方法，从table中将entry删除。适用场景ThreadLocal适用如下场景每个线程需要有自己单独的实例实例需要在多个方法中共享应用案例在Web中，通常使用Session在各个页面中传递信息。每个客户端对应于Web中的一个线程，需要保证线程有自己单独的Session实例；而线程内部的各方法又需要共享Session。如不使用ThreadLocal，其实现方式如下：1234567891011121314151617public class Web&#123; public static class Session&#123; private string username; private int age; .... // get/set方法 &#125; public Session createSession()&#123; return new Session(); &#125; public string getUsername(Session session)&#123; return session.getUsername(); &#125; public int getAge(Session session)&#123; return session.getAge(); &#125;&#125;总结Entry会被清理的场景：Thread结束之后被垃圾回收处理set一个变量时，发现staled entry。进行替换并清理set一个变量时，size大于阀值时，调用rehash方法清理并扩容调用remove方法时，删除该entry并清理发现的staled entry尽管采用了弱引用的ThreadLocalMap不会造成内存泄露，但是并不能保证staled entry被及时清理。因此我们在使用完ThreadLocal后最好还是remove一下（使用线程池时一定要即时remove，线程使用后归还给了线程池，并没有销毁），保证即时回收无用的Entry。]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的functools模块]]></title>
    <url>%2Fposts%2Ff6b0a560%2F</url>
    <content type="text"><![CDATA[functools.partial(func[, *args][, **keywords])该函数通过包装手法，允许我们”重新定义”函数。返回用args和keywords填充了func指定位置参数后的函数，调用该函数只需传入原函数未填充的参数。123from functools import partialbasetwo = partial(int, base=2)basetwo('10010')basetwo(‘10010’)实际上等价于调用int(‘10010’, base=2)@functools.singledispatch使用过面向对象语言的同学，肯定熟悉各种方法的重载。虽然Python不支持方法重载的，但是我们可以添加@functools.singledispatch注解来动态指定相应的方法所接收的参数类型。12345678910111213from functools import singledispatchclass TestClass(object): @singledispatch def test_method(arg, verbose=False): if verbose: print('Let me just say,', end=' ') print(arg) @test_method.register(int) def _(arg): print('Strength in numbers, eh?', end=' ') @test_method.register(list) def _(arg): print('Enumerate this:')通过@test_method.register(int)和@test_method.register(list)指定当test_method的第一个参数为int或者list的时候，分别调用不同的方法来进行处理。functools.update_wrapper(**wrapper, wrapped)默认partial对象没有__name__和__doc__，这种情况下，对于装饰器函数非常难以debug。使用该函数可以将被封装函数的这些属性复制到封装函数中。12345678def my_decorator(f): def wrapper(*args, **kwds): print('print in wrapper') return f(*args, **kwds) return update_wrapper(wrapper, f)@my_decoratordef example(): print('print in example')@functools.wraps该注释内部调用了functools.update_wrapper()函数，简化编码复杂度。12345678910from functools import warpsdef my_decorator(f): @warps(f) def wrapper(*args, **kwds): print 'print in wrapper' return f(*args, **kwds) return wrapper@my_decoratordef example(): print 'print in example'@functools.lru_cache(maxsize=None, typed=False)@lru_cache用于缓存函数返回的结果，对于重复的调用直接从缓存中获取返回值。如果maxsize设置为None，则缓存没有上界。如果typed设置为true，则对于不同的参数类型会区别缓存。12345678from functools import lru_cache@luc_cache(None)def add(x, y): print('calculating: %s + %s' % (x, y)) return x + yprint(add(1, 2))print(add(1, 2))print(add(2, 3))输出结果：12345calculating: 1 + 233calculating: 2 + 35@functools.total_ordering这是一个类装饰器，用于自动实现类的比较运算。若自定义类中实现了__eq__和__lt__、__gt__、__ne__、__le__、__ge__中的一个，带有@total_ordering装饰的类会自动实现剩下的函数 。functools.cmp_to_key(func)该函数用于将旧式的比较函数转化为key(关键值)函数并应用于接受key function的工具类中(sorted(), min(), max(), heapq.nsamllest(), heapq.nlargest(), itertools,groupby())12from functools import cmp_to_keysorted(iterable, key=cmp_to_key(cmp_func))functools.reduce(func, iterable, [, initializer])与python2中的内建函数reduce等价]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git简明教程]]></title>
    <url>%2Fposts%2F6326f1e4%2F</url>
    <content type="text"><![CDATA[Git简介Git是目前世界上最先进的分布式版本控制系统。在Git出现之前，版本控制系统主要是集中式占据着绝对的统治地位，以CVS和SVN为代表。集中式版本控制系统中版本库集中存放在中央服务器，写代码的时候我们要先从中央服务器拉取最新版本，开发完成之后再讲版本推送到中央服务器，这就意味着必须联网才能工作，也存在代码丢失的风险。分布式版本控制系统去掉了中央服务器的概念，每个开发人员本地都有一份完整的版本库，在没有网络时也能进行开发工作。虽然分布式版本控制系统中去掉了中央服务器，但是为了协同开发人员之间的工作，通常会有一台充当“中央服务器”的电脑。如果不想搭建自己的gitlab服务器，可以选择第三方代码仓库，如github、coding.net、git.oschina等。配置因为Git是分布式版本控制系统，在将代码push到远程仓库时，需要告诉仓库提交者的身份。所以在安装完Git之后需要进一步配置，在命令行输入：12$ git config --global user.name "Your Name"$ git config --global user.email "email@example.com"注意git config命令的--global参数表示本机中的所有Git仓库都会使用这个配置，若想只针对当前仓库进行配置可以去掉--global参数。版本库创建版本库版本库又叫仓库，可以简单的理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除Git都能跟踪，以便在将来的某个时候将文件还原回之前的版本。创建版本库时，首先将路径切换到目标目录，执行：12$ git initInitialized empty Git repository in C:/Users/windylee/Desktop/repository/.git/这时该目录就会成为Git的一个本地仓库。这是在当前目录下就会多一个.git的目录，这个目录就是Git用来跟踪管理版本库的，千万不要手动修改这个目录里面的文件。将文件添加到版本库Git只能跟踪文本文件的改动，比如txt、网页、程序代码等等，二进制文件虽然也能有Git管理，但是不能跟踪文件的变化。进入我们的本地仓库，创建一个readme.txt文件，在里面随便写点内容保存。第一步，用命令git add告诉Git，把文件添加到仓库：1$ git add readme.txt第二步，用命令git commit告诉Git，把文件提交到仓库:1234$ git commit -m "write a readme.txt file"[master (root-commit) 096895b] write a readme.txt file 1 file changed, 1 insertion(+) create mode 100644 readme.txt-m后面输入的是本次提交的说明，可以输入任意内容，但最好可以描述本次修改的内容，引文输入说明对自己对别人阅读都很重要。commit命令输出：第一行给出了本次commit的hash值，剩下的内容描述本次修改的内容（修改了1个文件，在该文件中插入了两行）。如果本次修改文件过多，不想一个个add文件，可以通过命令：1$ git add --all这条命令会将所有修改的文件一次全部添加到仓库。版本控制查看状态123456789$ git statusOn branch masterChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txtno changes added to commit (use "git add" and/or "git commit -a")通过git status命令我们可以时刻掌握仓库的当前状态，上面的命令告诉我们readme.txt文件被修改过了，但是还没有添加到仓库。在每次执行Git命令前运行该命令是一个较好的习惯。如果修改内容过多，时间长了我们就不知道修改了文件的哪些内容。这是可以通过git diff命令来查看文件修改的内容12345678$ git diff readme.txtdiff --git a/readme.txt b/readme.txtindex 8f6e0fc..9468d46 100644--- a/readme.txt+++ b/readme.txt@@ -1 +1,2 @@ Git is a version control system+happy coding.显示的内容是本地文件与版本库中文件的difference，显示的格式正是Unix通用的diff格式。版本回退123456789101112$ git logcommit 3703210c919521c63f457341419b6daa3f38083fAuthor: windylee &lt;liwangadd@gmail.com&gt;Date: Fri Jan 12 13:52:29 2018 +0800 add happy coding linecommit 096895bbf40546221e12c16a4ea1a77d6565b16eAuthor: windylee &lt;liwangadd@gmail.com&gt;Date: Fri Jan 12 13:32:28 2018 +0800 write a readme.txt filegit log命令显示从最近到最远的提交日志，可以看到我们总共有两次提交。如果嫌输出信息太多，可以加上--pretty=oneline参数，一次提交日志就会在一行显示：123$ git log --pretty=oneline3703210c919521c63f457341419b6daa3f38083f add happy coding line096895bbf40546221e12c16a4ea1a77d6565b16e write a readme.txt file如果我们想返回上一个版本，可以使用如下命令：1$ git reset --hard HEAD^若要返回上一个版本，首先要先知道当前版本是哪个版本。在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上个版本就是HEAD^^。如果要返回上100各版本怎么办，由于每次commit都会产生一个hash值作为本次提交的唯一标识，可以将HEAD^换成会返回版本的hash值(取前7位即可)。1git reset --hard 3703210暂存区创建仓库之后，目录中会多出.git目录。该目录就是Git的版本库，其中包括成为stage的暂存区，还有自动创建的master分支以及指向master的HEAD指针。在执行git add命令时，是将文件修改添加到暂存区，执行git commit命令则是将暂存区中的内容提交到当前分支并将暂存区清空。撤销修改1$ git checkout --readme.txt命令git checkout -- filename会把文件在工作区的修改全部撤销，若文件修改后还没有添加到暂存区，撤销修改就回到和版本库一样的状态；若文件已经添加到暂存区，之后又做了修改，撤销修改就回到添加到暂存区后的状态。若文件修改已添加到暂存区，而要删除暂存区中的文件修改内容。可以使用如下命令：1$ git reset HEAD readme.txt该命令可以把暂存区的修改撤销掉，重新放回工作区。删除文件在Git中，删除也是一种修改操作。可以直接在文件管理器中将文件删除，这时工作区和版本库就不一致了。可以选择从版本库中删除该文件，使用git rm将文件从版本库删除掉，并且git commit。或者是误删，这是可以将文件从版本库中回复到最新版本：1git checkout -- readme.txtgit checkout是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。远程仓库添加远程仓库在我们开发时，通常将代码托管到github上。这样，github上的仓库既可以作为备份，又可以让其他人通过该仓库来协作。在github上创建一个新仓库之后，在本地仓库下运行如下命令：1$ git remote add origin git@github.com:liwangadd/repository.git这是本地仓库就将github上的相应仓库作为托管平台。下一步就可以把本地库的所有内容推送到远程库上：1$ git push -u origin master由于远程仓库是空的，我们第一次推送master分支时，加上-u参数。Git不但会把本地的master分支内容推送到远程新的master分支，还会把本地的master分支和远程的master分支关联起来。从远程库克隆进入到我们想要克隆到本地的项目主页，获取到仓库地址。使用如下命令将远程仓库clone到本地：1$ git clone https://github.com/yaochenkun/aiop-notice.git如果有多个人协作开发，那么每个人各自从远程clone一份就可以了。分支管理创建与合并分支创建dev分支，然后切换到dev分支：12$ git checkout -b devSwitched to a new branch 'dev'git checkout命令加上-b参数表示创建并切换分支，相当于以下两条命令：123$ git branch dev$ git checkout devSwitched to a new branch 'dev'然后就可以用git branch命令查看当前分支123$ git branch* dev mastergit branch命令会列出所有分支，当前分支前面会标一个*号git merge命令用于合并指定分支到当前分支：12345$ git merge devUpdating d17efd8..fec145aFast-forward readme.txt | 1 + 1 file changed, 1 insertion(+)注意到上面的Fast-forward信息，Git告诉我们，这次合并是”快进模式”，也就是直接把master指向dev的当前提交。但是在这种模式下，删除分之后，会丢掉分支信息。如果强制禁用Fast-forward模式，Git就会在merge时生成一个新的commit，这样从分支历史上就可以看出分支信息。强制禁用Fast-forward模式，可以使用--no-off参数，因为合并会创建一个新的commit，所有加上-m参数，把commit描述写进去。1$ git merge --no-ff -m "merge with no-ff" dev分支合并完成后，如果dev分支不需要了，可以将该分支删除:1git branch -d dev因为创建、合并和删除分支非常快，所以当我们要完成某个任务时，可以先创建分支，在新的分支上开发完成再合并到主分支。Bug分支若当前正在dev分支上进行工作，需要切换到其他分支工作，而dev分支上的任务还没有完成，不能提交到暂存区。这时可以使用stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作。123$ git stashSaved working directory and index state WIP on dev: 3703210 add happy coding lineHEAD is now at 3703210 add happy coding line这是就可以切换到其他分支进行工作了，工作完成回到该分支，可以使用git stash list命令查看工作现场。12$ git stash liststash@&#123;0&#125;: WIP on dev: 3703210 add happy coding line可以看到，工作现场还在。Git把stash内容存在了某个地方了，若要将stash的内容恢复到工作区，有两个办法：用git stash apply恢复，但是恢复后，stash内容并不删除，需要用git stash drop来删除用git stash pop，恢复的同时把stash内容删了若执行了多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令：1$ git stash apply stash@&#123;0&#125;强行删除分支如分支没有合并，使用git branch -d dev命令会提示分支没有合并，删除失败。如果要强行删除，需要使用命令git branch -D dev。12$ git branch -D devDeleted branch dev (was 3703210).多人协作标签管理发布一个版本时，我们通常现在版本库中打一个标签，这样唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以标签也是版本库的一个快照，其实就是指向某个commit的指针。由于commit给出的是一个hash值，不好记忆，所以才引入了标签这个概念。创建标签使用git tag &lt;name&gt;命令可以打一个标签：1$ git tag v1.0可以用命令git tag查看所有标签。默认标签是打在最新提交的commit上的，若想打在之前某个commit上面，就需要根据历史提交的commit id打标签：]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门教程]]></title>
    <url>%2Fposts%2F750751bd%2F</url>
    <content type="text"><![CDATA[介绍Nginx是一个开源、高性能的HTTP服务器和反向代理服务器，还可以用来作为IMAP/POP3的代理服务器，其处理静态文件、索引文件的效率非常高。相比于apache的多进程多线程的并发模型，Nginx是基于事件的异步IO的并发模型，支持epoll/kqueue等网络IO模型。安装安装Nginx主要有两种方式，通过仓库中的二级制包安装和源码安装。在Ubuntu系统中可以通过sudo apt-get install nginx从官方仓库中安装，这种安装方式可以满足用户的基本需求。但如果对Nginx的精简度和性能有非常高的要求，就需要通过源码的方式安装，分为以下三步：123./configuremakesudo make install如果要对Nginx进行定制，就需要在第一步制定需求，主要参数如下：–conf-path 指定配置文件的位置，默认为/etc/nginx/nginx.conf–error-log-path 指定错误日志文件所在位置，默认为/var/log/nginx/error.log,安装完成后可在配置文件中进行配置–http-log-path 指定http连接日志文件所在位置，默认为/var/log/nginx/access.log–with-模块名称 该模块会被编译–without-模块名称 编译时将该模块排除在外源码安装完成之后，默认Nginx服务已经启动。若想手动启动Nginx服务可以通过sudo service nginx start,同理关闭或者重启可以通过sudo service nginx stop/restart。 虽然Nginx重启速度很快，但是每次修改配置文件后，仅仅想让配置文件生效可以通过sudo nginx -s reload 命令，而不用重启服务配置文件详解Nginx是模块化的系统，整个系统被分成一个个的模块，每个模块负责不同的功能。例如http_gzip_static_module是负责压缩的，http_ssl_module是负责加密的。如果想使用某个模块需要在编译时将其加入其中，使用被编译的模块需要通过指令，整个配置文件就是通过指令组成的。默认的配置文件位于/etc/nginx/nginx.conf，内容如下12345678910111213141516171819202122232425262728user nginx;worker_processes 1;pid /run/nginx.pid;events &#123; worker_connections 768;&#125;http &#123; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; gzip on; gzip_disable "msie6"; include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125;可以看到，配置文件主要由两个block组成。Nginx是存在三个顶级block的，分别是123456events &#123;&#125;http &#123;&#125;mail&#123;&#125;从配置文件中可以看出：events模块中包含nginx中所有处理连接的设置，可以通过worker_connections指定每个工作进程可以同时接受的最大连接数；http模块主要是用来配置web服务，可以用于指定是否启用压缩，是否支持发送文件等；mail模块用来配置IMAP/POP3代理。我们主要关注http模块，如果Nginx的配置文件过大，将全部配置写在同一文件中将难以维护，此时可以将不同用途的配置写在不同的配置文件中，通过include指令加载进来。如果想要部署一个网站，就需要在http模块中添加一个server块。下面看一个例子。12345678910111213141516171819server &#123; listen 80; server_name example.org www.example.org; root /usr/nginx/www; location / &#123; index index.html index.php; &#125; location ^~ /images/ &#123; index icon.html; &#125; location ~* \.(gif|jpg|png)$ &#123; expires 30d; &#125; error_page 500 502 503 /50x.html;&#125;在电脑中的hosts文件中，加入一行127.0.0.1 www.example.org，在浏览器中输入www.example.org就可以访问了。该配置中通过listen表明监听80端口，通过server_name指定网站的域名，通过root指定网站的根目录，最下面的error_page说明当服务器发生500、502、503错误时，将网站根目录下的50x.html返回给用户。下面我们主要关注location指令，location用于URL模式设置，可以看到在匹配的URL开头有一些特殊符号，不同的符号用于限定在匹配时采用的特殊规则：=开头表示精确匹配，与指定字符串有任何区别将不能匹配成功^~开头表示匹配以指定字符串开头的URL，不适用正则~开头表示区分大小写的正则匹配~*开头表示不区分大小写的正则匹配/通用匹配，如果所有匹配都失败，则返回该默认匹配各种匹配的优先级为：(=) &gt; (完整路径) &gt; (^~) &gt; (~, ~*) &gt; (location 部分起始路径) &gt; (/)。在上面的配置文件中的$符号是正则表达式中的结束标志。在最后一个location中有expires指令，该指令的作用是让Nginx缓存请求返回的信息(这里是图片静态文件)，缓存的有效期的30天。反向代理代理可以分问正向代理和反向代理。正向代理的步骤是：用户要访问服务器C，而用户的请求会先到达代理服务器B，然后B再将用户请求转发到服务器C，此时代理服务器B才是真正访问服务器C的，代理服务器B再将得到的结果转发给用户。在这个过程中用户就像直接访问服务器C一样，过程中不知道代理服务器的存在。而反响代理的步骤是：用户只知道代理服务器的地址，通过该地址直接访问代理服务器B，代理服务器B将请求转发给真正的服务提供者C，得到结果后再返回给用户。用户根本不知道服务提供者的地址或者完全不能访问到，整个过程用户是直接与代理服务器B交互的。反向代理可以用来隐藏和保护原始服务器，实现负载均衡，加密和SSL加速等。Nginx的反向代理是通过ngx_http_proxy_module这个模块实现的，nginx可以代理的协议有http(s)、fastcgi、uswgi、memcached等。下面是实现的一个简单代理服务器的配置文件。123456789101112131415161718192021....http&#123; .... upstream java_demo&#123; # 实际服务器的地址 server 127.0.0.1:8080; &#125; server &#123; server_name www.example.com; listen 443; proxy_connect_timeout 180; # nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 180; proxy_read_timeout 180; # 连接成功后，后端服务器响应时间(代理接收超时) proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; location / &#123; # 将请求转发到实际服务提供者 proxy_pass http://java_demo; &#125; &#125;gzip压缩当css文件和js文件过大时，可以通过压缩的机制提高网站的加载速度。Nginx通过ngx_http_gzip_module模块实现对文件的压缩操作，启用压缩要在配置文件中指定。123456789101112131415161718....http &#123; gzip on; gzip_disable "msie6"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; server &#123; location ~ ^/assets/ &#123; gzip_static on; expires max; add_header Cache-Control public; &#125; &#125;&#125;使用gzip指令来启用gzip压缩功能，使用gzip_types限制了要压缩的文件类型。这两个属性时必须配置的，其他属性根据需要进行配置。同时需要在要启用压缩的location块中加入配置文件中的那三行。负载均衡听说过nginx的人肯定都知道其在负载均衡中的重要角色，几乎成熟的网站都会使用nginx作为负载均衡服务器。同时nginx也在不断发展，在1.9版本之前其只能作为http的负载均衡，而在1.9之后其也实现了对tcp进行负载均衡。nginx负载均衡模块实现了如下4种调度方式：round-robin：Nginx默认的轮询算法，每个请求按时间顺序逐一分配到不同的后端服务器。可以通过weight指定轮询权值，权值越大表明被访问到的可能性越大。1234upstream java_demo &#123; server 127.0.0.1:8080 weight=2; server 127.0.0.1:8081 weight=1;&#125;​least_conn：请求会被发送到活跃连接数最少的服务器上。12345upstream java_demo &#123; least_conn; server 127.0.0.1:8080; server 127.0.0.1:8081;&#125;​ip_hash：根据访问用户ip的hash结果分配请求，相同的ip总是会被分配到同一台应用服务器。12345upstream java_demo &#123; ip_hash; server 127.0.0.1:8080; server 127.0.0.1:8081;&#125;​hash：相比于ip_hash方式，这是一个粒度更小的控制，ip_hash默认是用户ip的hash值。而该方式根据指定字段的hash值进行分配。12345upstream java_demo &#123; hash $request_uri; # 根据请求地址分配 server 127.0.0.1:8080; server 127.0.0.1:8081;&#125;nginx对负载均衡提供了很好的支持，相对于反向代理，我们只需在upstream块中添加多个server地址和指定负载均衡算法，nginx就可以根据我们指定的负载均衡算法分发用户请求。在配置负载均衡时，upstream块中的server可以有如下配置参数down。加入该字段的server将暂时不参与负载均衡，对该服务器的请求会自动发送到下一个服务器。backup。预留的备份服务器，当其他所有的非backup都出现故障或者忙的时候，才会将请求发送到该服务器。weight。指定该服务器被访问到的概率，值越大被访问到的概率越高，默认weight的权值为1。max_fails。表示请求失败的次数，若某一服务器对同一请求失败超过max_fails次，则将该请求发送到下一服务器。max_timeout。表示请求失败的超时时间，在设定的时间内没有成功，就作为失败处理。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring定时任务]]></title>
    <url>%2Fposts%2F4016a806%2F</url>
    <content type="text"><![CDATA[关于spring的定时任务，我们在spring3.0之前一般会使用Quartz，这是一个功能相当强大的调度器，可以让你的程序在指定时间执行，也可以按照某个频度执行，但是配置起来稍显复杂。Spring3.0以后自带task，可以将它看成一个轻量级的Quartz，使用起来比Quartz简单许多，不需要额外的包，而且支持注解和配置文件两种形式。基本使用配置文件方式首先需要在配置文件中引入task命名空间12345&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:task="http://www.springframework.org/schema/task" ... http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd"&gt;然后配置需要定时执行的任务12345678&lt;!--Spring定时器注解开关，注册之后可以再java类中使用task命名空间的注解--&gt;&lt;task:annotation-driven scheduler="myScheduler"/&gt; &lt;!--内部使用的线程池，配置线程池，指定线程池的大小--&gt; &lt;task:scheduler id="myScheduler" pool-size="10&gt; &lt;!--配置定时任务，指定需要定时执行的类和方法，并配置调度方式--&gt; &lt;task:scheduled-task scheduler="myScheduler"&gt; &lt;task:scheduled ref="scheduledTaskManager" method="autoCardCalculate" cron="0 5 * * * *"/&gt; &lt;/task:scheduled-task&gt;注解形式首先我们看一下源码中注解的定义123456789101112131415161718192021@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(Schedules.class)public @interface Scheduled &#123; String cron() default ""; String zone() default ""; long fixedDelay() default -1L; String fixedDelayString() default ""; long fixedRate() default -1L; String fixedRateString() default ""; long initialDelay() default -1L; String initialDelayString() default "";&#125;我们可以看到该注解有八个参数，分别表示的意思是：cron：指定cron表达式zone：指定时区fixedRate：从上一个任务开始到下一个任务开始的间隔，单位是毫秒fixedDelay：从上一个任务完成到下一个任务开始的间隔，单位是毫秒initialDelay：任务第一次执行前需要延迟的毫秒数这些配置参数都可以在xml配置文件中使用，效果是一样的执行任务的POJO类1234567891011121314151617181920212223242526public class ScheduledTaskManager&#123; /** * 每日凌晨2点执行一次 */ @Scheduled(cron = "0 0 2 * * *") public void autoCardCalculate() &#123; System.out.println("hello world" + new Date()); &#125; /** * 心跳更新，启动时执行一次，之后每隔一分钟执行一次 */ @Scheduled(fixedRate = 1000 * 60) public void heartbeat() &#123; System.out.println("hello world" + new Date()); &#125; /** * 启动后一秒钟之后执行一次，之后每次执行完间隔2分钟执行一次 */ @Scheduled(fixedDelay = 1000 * 60 * 2, initialDelay = 1000) public void persistRecord() &#123; System.out.println("hello world" + new Date()); &#125;&#125;组合多个Scheduled@Scheduled可以让我们很方便的配置定时任务，但是有的定时任务不是一个表达式就能表达完全的，比如说我既想在周三10:10又想在周四17:40执行某项任务。这时候我们很难用一个表示式，或者根本行不通，这时候我们就要组合多个@Scheduled表达式。@Schedules注解里面只有一个参数Scheduled数组，意味着我们可以将多个@Scheduled压入数组，组合使用12//每隔18秒执行一次，并且每天的4:00执行一次@Schedules(&#123;@Scheduled(cron = "* * 4 * * *"),@Scheduled(fixedRate = 1000*18)&#125;)cronExpression的配置说明各字段意义字段允许值允许的特殊字符秒0-59, - * /分0-59, - * /小时0-23, - * /日期1-31, - * /月份1-12或JAN-DEC, - * /星期1-7或SUN-SAT, - * /年（可选）留空，1970-2099, - * /- 指定区间* 通配符? 你不想设置那个值/ 没多少执行一次例子CRON表达式含义0 0 12 * * ?每天中午12点触发0 15 10 ? * *每天上午10:15触发0 15 10 * * ?每天上午10:15触发0 15 10 * * ? *每天上午10:15触发0 15 10 * * ? 20152015年的每天上午10:15触发0 * 14 * * ?每天下午14:00到14：59每分钟触发一次0 0/5 14 * * ?每天下午14:00到14:55没5分钟触发一次0 0/5 14,18 * * ?每天14:00到14:55和18:00到18:55每5分钟触发一次0 0-5 14 * * ?每天14:00前五分钟每分钟触发一次0 10,44 14 ? 3 WED3月每周三14:10和14:44触发0 15 10 ? * MON-FRI周一到周五的10:15触发]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring异步任务]]></title>
    <url>%2Fposts%2Fc0ceddf6%2F</url>
    <content type="text"><![CDATA[在Spring3.0之前如果我们想要异步执行某项任务，需要我们自己编写线程池来实现。在Spring3.X新增了注解@Async，可以标记方法或者类中的所有方法都可以异步执行，而调用他的方法会在原来的线程中执行。这样可以避免阻塞，保证任务的实时性。适用于处理log，发送邮件等#### 配置##### 配置文件同Spring自己实现的定时任务一样，我们需要在配置文件中引入task命名空间123456789101112&lt;beans xmlns="http://www.springframework.org/schema/beans"​ xmlns:task="http://www.springframework.org/schema/task"​ ...​ http://www.springframework.org/schema/task​ http://www.springframework.org/schema/task/spring-task.xsd"&gt;\然后配置相关的线程池和缺省的异步调度器\123456789101112&lt;!--配置executor，一个应用中可以有多个executor--&gt;&lt;task:executor id="mailExecutor" pool-size="10" keep-alive="100" queue-capacity="5" rejection-policy="ABORT"/&gt;&lt;task:executor id="logExecutor" pool-size="10"/&gt;&lt;!--指定一个缺省的executor给@Async使用，当@Async没有指定使用哪个executor将默认使用该executor--&gt;&lt;task:annotation-driven executor="mailExecutor"/&gt;\##### 配置参数- id: 当配置多个executor时，被@Async(“id”)指定使用，也可以作为线程名的前缀- pool-size 指定线程池的大小- queue-capacity：当最小的线程数已经被占用满后，新的任务会被放进queue里面，当这个queue的capacity也被占满之后，pool里面会创建新线程处理这个任务，直到总线程数达到了max size，这是系统会拒绝这个任务并抛出TaskRejectedException异常(可以通过rejection-policy来决定如何处理这种情况)，缺省值为Integer.MAX_VALUE- keey-alive：超过core size的那些线程，任务完成后，经过这个时长就会被结束掉- rejection-policy：当pool已经达到max size的时候，如何处理新任务ABORT（缺省）：抛出TaskRejectedException异常，然后不执行DISCARD：不执行，也不抛出异常DISCARD_OLDEST：丢弃queue中最旧的那个任务CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行#### 注解##### 注解源码\1234567891011121314@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Async &#123;​ String value() default "";&#125;\通过@Async的源码我们可以知道，该注解可以用在方法上也可以用在类上，注解在方法上表明该方法是一部执行的，注解在类上表明该类中的所有方法都是一步执行的##### 方法返回值如果我们不想从异步线程中获取返回值，那么我们可以将返回值声明为void。如果我们想要从线程中获取数据，可以使用Future作为返回值。通过future.get()得到需要返回的对象，也可以使用future,get(time,unit)，在制定时间内获取返回值，如果超过设置的时间则抛出异常\1234567891011121314151617181920212223242526272829303132333435363738@Async("logExecutor")​ public void business() throws InterruptedException &#123;​ System.out.println("异步任务开始执行");​ Thread.sleep(2000);​ System.out.println("异步任务执行结束");​ &#125;​ /**​ \* 没有指定调度器将使用缺省值​ \* @return​ \* @throws InterruptedException​ */[^]​ @Async​ public Future&lt;String&gt; business2() throws InterruptedException &#123;​ System.out.println("异步任务开始执行");​ Thread.sleep(2000);​ System.out.println("异步任务执行结束");​ return new AsyncResult&lt;String&gt;("hello world");​ &#125;\`]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring拦截器]]></title>
    <url>%2Fposts%2F2b6e765e%2F</url>
    <content type="text"><![CDATA[处理器拦截器简介Spring MVC的处理器拦截器类型于Servlet开发中的Filter，用于对处理器进行预处理和后处理常见应用场景日志记录：记录请求信息的日志，以便进行信息监控、信息统计、计算PV（Page View）等权限检查：如登录检测，进入处理器检测检测是否登录，如果没有直接返回到登录页面性能监控：通过拦截器在进入处理器之前记录开始时间，在处理完后记录结束时间，从而得到该请求的处理时间通用行为：读取cookie得到用户信息并将用户对象放入请求，从而方便后续流程使用，还有如提取Locale、Theme信息等，只要是多个处理器都需要的即可使用拦截器实现。OpenSessionInView：如Hibernate，在进入处理器打开Session，在完成后关闭Session。本质也是AOP（面向切面编程），也就是说符合横切关注点的所有功能都可以放入拦截器实现。拦截器实现SpringMVC 中的Interceptor拦截请求是通过HandlerInterceptor来实现的。在SpringMVC中定义一个Interceptor非常简单，主要有两种方式，第一种方式是要定义的Interceptor类要实现了Spring 的HandlerInterceptor接口，或者是这个类继承实现了HandlerInterceptor接口的类，比如Spring 已经提供的实现了HandlerInterceptor接口的抽象类HandlerInterceptorAdapte；第二种方式是实现Spring的WebRequestInterceptor接口，或者是继承实现了WebRequestInterceptor的类。HandlerInterceptor接口12345678910111213141516public interface HandlerInterceptor &#123; boolean preHandle( HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; void postHandle( HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception; void afterCompletion( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception; &#125;有接口的定义我们可以看出HandlerInterceptor中定义了三个方法，我们就是通过这三个方法来对用户的请求进行拦截处理的。preHandle实现处理器的预处理，第三个参数为响应处理器（一般为Controller）。返回true表示继续流程；返回false表示中断流程，不会继续调用其他的拦截器和处理器，这时候我们需要通过response来产生响应。我们可以在该方法中进行一些前置初始化操作或者是对当前请求的一个预处理。postHandle实现处理器的后处理，但是在DispatcherServlet渲染页面之前调用，我们可以调用modelAndView进行模型数据进行处理或对视图进行处理afterCompleting视图渲染完毕后回调该方法，该方法主要用于数据清理如果我们继承自HandlerInterceptor接口，那么我们每次都需要重写三个方法。但是大多数时候我们只需要重写其中一两个方法，这时候我们可以继承HandlerInterceptorAdapter类，选择性的重写其中的方法。下面给出一个计算请求处理时间的例子123456789101112131415161718192021public class StopWatchHandlerInterceptor extends HandlerInterceptorAdapter &#123; private NamedThreadLocal&lt;Clock&gt; startTimeThreadLocal = new NamedThreadLocal&lt;Clock&gt;("StopWatch-StartTime"); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response,Object handler) throws Exception &#123; Cloxk start = Clock.now()//1、开始时间 startTimeThreadLocal.set(beginTime);//线程绑定变量（该数据只有当前请求的线程可见） return true;//继续流程 &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; Clock end = Clock.now();//2、结束时间 Clock start = startTimeThreadLocal.get();//得到线程绑定的局部变量（开始时间） long consumeTime = Duration.betwen(start, end).toMillis()//3、消耗的时间 System.out.println(String.format("%s consume %d millis", request.getRequestURI(), consumeTime)); &#125;&#125;WebRequestInterceptor接口该接口中也定义了三个方法，我们也可以通过这三个方法来实现拦截，这三个方法都传递了同一个参数WebRequest，三个方法的调用时机同HanlderInterceptor。WebRequest是Spring中定义的一个接口，方法基本和HttpServletRequest一样，对WebRequest做的任何操作都会同步到HttpServletRequest，然后在当前请求中一直传递preHandle(WebRequest request)由于没有返回值，无法控制请求流程。我们一般在该方法中进行资源的准备工作。比如我们在使用Hibernate的时候可以在这个方法中准备一个Hibernate的Session对象，然后利用WebRequest的setAttribute(name, value, scope)把它放到WebRequest 的属性中。这里可以说说这个setAttribute 方法的第三个参数scope：SCOPE_REQUEST ：它的值是0 ，代表只有在request 中可以访问。SCOPE_SESSION ：它的值是1 ，如果环境允许的话它代表的是一个局部的隔离的session，否则就代表普通的session，并且在该session范围内可以访问。SCOPE_GLOBAL_SESSION ：它的值是2 ，如果环境允许的话，它代表的是一个全局共享的session，否则就代表普通的session，并且在该session 范围内可以访问。postHandle(WebRequest request, ModelMap model)ModelMap 就是Controller 处理之后返回的Model 对象，我们可以通过改变它的属性来改变返回的Model 模型。afterCompletion(WebRequest request, Exception ex)可以在该方法中进行资源的释放操作，Exception 参数表示的是当前请求的异常对象，如果在Controller 中抛出的异常已经被Spring 的异常处理器给处理了的话，那么这个异常对象就是是null 。配置拦截器123456789&lt;mvc:interceptors&gt; &lt;bean class="com.windylee.interceptor.AllInterceptor"/&gt; &lt;mvc:interceptor&gt; &lt;!--指定拦截器的拦截路径--&gt; &lt;mvc:mapping path="/interceptor/**"/&gt; &lt;!--指定拦截器的实现类--&gt; &lt;bean class="com.windylee.interceptor.StopWatchHandlerInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;mvc:interceptors标签声明一系列的拦截器，然后它们就可以形成一个拦截器链，拦截器的执行顺序是按声明的先后顺序执行的，在mvc:interceptors标签下声明interceptor主要有两种方式：直接定义一个Interceptor实现类的bean对象。使用这种方式声明的Interceptor拦截器将会对所有的请求进行拦截。例子中的AllInterceptor会拦截所有请求使用mvc:interceptor标签进行声明。使用这种方式进行声明的Interceptor可以通过mvc:mapping子标签来定义需要进行拦截的请求路径。推荐推荐能使用servlet规范中的过滤器Filter实现的功能就用Filter实现，因为HandlerInteceptor只有在Spring Web MVC环境下才能使用，因此Filter是最通用的、最先应该使用的。如登录这种拦截器最好使用Filter来实现。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新的时间日期库]]></title>
    <url>%2Fposts%2Fb5a2dc36%2F</url>
    <content type="text"><![CDATA[综述时间API分类概述新的API： java.time，由5个包组成java.time- 包含值对象的基础包java.time.chrono - 提供对不同的日历系统的访问java.time.format - 格式化和解析时间和日期java.time.temporal - 包括底层框架和扩展特性java.time.zone - 包含市区支持的类我们平时只会用到基础和format包，也可能用到temporal包，因此虽然新的API提供了多达68个新的公开类型，但是我们一般只会用到其中的三分之一关键日期/时间概述不可变性。借鉴于java.util.Calendar的前车之鉴，设计这个API的时候着重考虑了原有方法的不可变性，不允许任何更改，如果必须改变的话就会返回一个新的实例，所以我们必须捕获该方法的返回值瞬间性。表示时间上的某个精确的时刻，使用从epoch开始计算的毫秒表示关键API使用Clock他可以通过时区来获取当前的instant，日期和时间。Clock类可以用来代替System.currentTimeMillis()和TimeZone.getDefault()123Clock clock=Clock.systemUTC();//获取格林尼治时间System.out.println(clock.instant());//获取Instant类型数据，后面会讲到System.out.println(clock.millis());//获取标准毫秒数Instant所谓的Instant累代表的是某个时间（有点类似与java.util.Date），他是精确到纳秒的，而Date是精确到毫秒的。instant表示的是时间线上的一点，而不需要任何上下文信息，例如：时区。概念上讲他只是简单的表示自1970年1月1日0是0分0秒开始的秒数。下面给去确定一个方法的运行时间长度的代码1234567Instant start = Instant.now();doSomeThing();Instant end = Instant.now();Duration duration = Duration.between(start, end);long seconds = duration.getSeconds();//秒表示long millis = duration.toMillis();//毫秒表示boolean isAfter = end.isAfter(start);//时间点end是否在start之后[^]常用函数now() 静态函数，获取当前时间戳isAfter()/isBefore() 判断两个时间点的先后顺序plusXXX() 在该时间点加上某段时间minusXXX() 在该时间点上减去某段时间Instant用在当你需要记录事件的发生时间，额如需要记录任何有关时区信息时。Instant只能包含秒数和毫秒数，例如如下代码就会抛出异常12instant.get(ChronoField.MONTH_OF_YEAR);instant.plus(6, ChronoUnit.YEARS);LocalDateLocalDate表示日期的不可变类型，不包含时间和时区。LocalDate和下面要讲的LocalTime都被设计成值类型的，这意味着我们不能用==来判断两个LocalDate是不是相等而是应该通过equals()。下面给出一个获取当前年月日的例子12345LocalDate today = LocalDate.now(); int year = today.getYear(); int month = today.getMonthValue(); int day = today.getDayOfMonth(); System.out.printf("Year : %d Month : %d day : %d \t %n", year, month, day);常用函数now()根据当前时间戳创建LocalDateof()根据制定的年月日创建LocalDateparse(charqueue, DateTimeFormatter)根据传入的format将字符串转化为LocalDate对象ofYearDay()根据指定的年和一年中的第几天创建LocalDategetXXX()获取当前LocalDate中关于日期的信息，年月日等等plusXXX()在当前的LocalDate的基础上增加指定时间类型来创建一个新的LocalDateminusXXX()在当前的LocalDate的基础上减去指定时间类型来创建一个新的LocalDatewithXXX()在当前的LocalDate的基础上指定某个时间类型的值来创建一个新的LocalDateisXXX()判断两个LocalDate的大小关系，特别（isLeepYear()判断是否为闰年）lengthOfXXX()获取LocalDate代表的年或月的天数with(TemporalAdjuster)TemporalAdjusters提供了几个用来获取TemporalAdjuster的方法，用来处理比较复杂的逻辑，比如获取当月的最后一天lastDayOfMonth()atTime()将LocalDate转化为LocalDateTimeLocalTimeLocalTime是值类型，且和日期，时区没有关联。当我们对时间进行加减操作时，以午夜为基准，24小时一个周期。因此，20:00加上6小时，结果是02:00。LocalTime用法和LocalDate类似12345LocalTime time = LocalTime.of(20, 30);int hour = date.getHour(); // 20int minute = date.getMinute(); // 30time = time.withSecond(6); // 20:30:06time = time.plusMinutes(3); // 20:33:06常用函数和LocalDate基本类似，只是将对年月日的操作转换为时分秒toSecondOfDay()获取该时间点距离0:00的秒数LocalDateTime这个值类型只是LocalDate和LocalTime的简单组合。他表示一个和时区无关的日期和时间。LocalDateTime可以直接创建或者组合时间和日期1234LocalDateTime dt1 = LocalDateTime.of(2014, Month.JUNE, 10, 20, 30);LocalDateTime dt2 = LocalDateTime.of(date, time);Month month = dt1.getMonth();int minute = dt1.getMinute();常用函数将LocalDate和LocalTime两个类的plusXXX(), minusXXX(), withXXX(),getXXX()简单相加与LocalDate对象其他函数完全类似isXXX()与LocalDate完全一样toLocalDate()/toLocalTime()将LocalDateTime转换为LocalTime或者LocalDate时间长度Duration表示以秒和纳秒位基准的时长；Period表示以年，月，日衡量的时长。他们可以作为参数，传给主要的时间/日期类的增加或减少的方法，也可以计算两个时间点之间的间隔12345Duration duration = Duration.ofDays(10);LocalTime start = LocalTime.now();doSoneThing();LocalTime end = LocalTime.now();Duration spend = Duration.between(start, end);常用函数ofXXX()根据参数指定的大小计算以XXX个单位的时间间隔between(arg1, arg2)计算两个参数时间点的时间间隔plusXXX()/minuxXXX()在当前时间间隔的基础上加上或减去指定个单位的时间toXXX()将时间间隔格式化位指定单位的时间，Duration一般使用该类型函数，Period一般使用getXXX()abs()求时间间隔的绝对值，保证时间间隔不为负数isZero()/isNegative()判断时间间隔是否为0或负withXXX()直接指定某个单位的值格式化java.time.format包是专门用来格式化输出输入时间/日期的。这个包围绕DateTimeFormatter类和它的辅助创建类DateTimeFormatterBuilder展开。静态方法ofPattern(Charqueue)和DateTimeFormatter中的常量是最通用的创建格式化器的方式常用ISO格式常量，如ISO_LOCAL_DATE字母模式，如ofPattern(“dd/MM/uuuu”)本地化样式，如ofLocalizedDate(FormatStyle.MEDIUM)有了格式化器，我们就可以将该实例传递给parse()或者format()作为参数，用来将字符串格式化为对象或者将对象格式化位字符串12345678910111213141516171819//按照内置的不同方式格式化String format = DateTimeFormatter.ISO_LOCAL_DATE.format(LocalDate.now());String format2 = DateTimeFormatter.ISO_LOCAL_TIME.format(LocalTime.now());String format3 = DateTimeFormatter.ISO_DATE.format(LocalDateTime.now());String format4 = DateTimeFormatter.ISO_INSTANT.format(Instant.now());System.out.println(format);System.out.println(format2);System.out.println(format3);System.out.println(format4); //按照标准格式格式化DateTimeFormatter formatter = DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL);String format5 = formatter.format(LocalDateTime.now());System.out.println(format5); //按照指定方式格式化DateTimeFormatter pattern = DateTimeFormatter.ofPattern("yyyy-MM-dd E HH:mm:ss");String format6 = pattern.format(LocalDateTime.now());System.out.println(format6);其他YearMonth仅仅包含年和月字段，操作也LocalDate类似MonthDay仅仅包含月和日字段，操作与LocalDate类似]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effictive-java读书笔记]]></title>
    <url>%2Fposts%2F636894a%2F</url>
    <content type="text"><![CDATA[Effective Java一书笔记对象的创建与销毁Item 1: 使用static工厂方法，而不是构造函数创建对象仅仅是创建对象的方法，并非Factory Pattern优点命名、接口理解更高效，通过工厂方法的函数名，而不是参数列表来表达其语义Instance control，并非每次调用都会创建新对象，可以使用预先创建好的对象，或者做对象缓存；便于实现单例；或不可实例化的类；对于immutable的对象来说，使得用==判等符合语义，且更高效；工厂方法能够返回任何返回类型的子类对象，甚至是私有实现；使得开发模块之间通过接口耦合，降低耦合度；而接口的实现也将更加灵活；接口不能有static方法，通常做法是为其再创建一个工厂方法类，如Collection与Collections；Read More: Service Provider Framework缺点仅有static工厂方法，没有public/protected构造函数的类将无法被继承；见仁见智，这一方面也迫使开发者倾向于组合而非继承；Javadoc中不能和其他static方法区分开，没有构造函数的集中显示优点；但可以通过公约的命名规则来改善；小结static工厂方法和public构造函数均有其优缺点，在编码过程中，可以先考虑一下工厂方法是否合适，再进行选择。Item 2: 使用当构造函数的参数较多，尤其是其中还有部分是可选参数时，使用Builder模式以往的方法Telescoping constructor：针对可选参数，从0个到最多个，依次编写一个构造函数，它们按照参数数量由少到多逐层调用，最终调用到完整参数的构造函数；代码冗余，有时还得传递无意义参数，而且容易导致使用过程中出隐蔽的bug；JavaBeans Pattern：灵活，但是缺乏安全性，有状态不一致问题，线程安全问题；Builder Pattern代码灵活简洁；具备安全性；immutable参数检查：最好放在要build的对象的构造函数中，而非builder的构建过程中支持多个field以varargs的方式设置（每个函数只能有一个varargs）一个builder可以build多个对象Builder结合泛型，实现Abstract Factory Pattern传统的抽象工厂模式，是用Class类实现的，然而其有缺点：newInstance调用总是去调用无参数构造函数，不能保证存在；newInstance方法会抛出所有无参数构造函数中的异常，而且不会被编译期的异常检查机制覆盖；可能会导致运行时异常，而非编译期错误；小结Builder模式在简单地类（参数较少，例如4个以下）中，优势并不明显，但是需要予以考虑，尤其是当参数可能会变多时，有可选参数时更是如此。Item 3: 单例模式！不管以哪种形式实现单例模式，它们的核心原理都是将构造函数私有化，并且通过静态方法获取一个唯一的实例，在这个获取的过程中你必须保证线程安全、反序列化导致重新生成实例对象等问题，该模式简单，但使用率较高。double-check-locking123456789101112private static volatile RestAdapter sRestAdapter = null;public static RestAdapter provideRestAdapter() &#123; if (sRestAdapter == null) &#123; synchronized (RestProvider.class) &#123; if (sRestAdapter == null) &#123; sRestAdapter = new RestAdapter(); &#125; &#125; &#125; return sRestAdapter;&#125;DCL可能会失效，因为指令重排可能导致同步解除后，对象初始化不完全就被其他线程获取；使用volatile关键字修饰对象，或者使用static SingletonHolder来避免该问题（后者JLS推荐）；class的static代码：一个类只有在被使用时才会初始化，而类初始化过程是非并行的，这些都由JLS能保证用enum实现单例还存在反射安全性问题：利用反射，可以访问私有方法，可通过加一个控制变量，该变量在getInstance函数中设置，如果不是从getInstance调用构造函数，则抛出异常；Item 4: 将构造函数私有化，使得不能从类外创建实例，同时也能禁止类被继承util类可能不希望被实例化，有其需求Item 5: 避免创建不必要的对象提高性能：创建对象需要时间、空间，“重量级”对象尤甚；immutable的对象也应该避免重复创建，例如String；避免auto-boxing但是因此而故意不创建必要的对象是错误的，使用object pool通常也是没必要的lazy initialize也不是特别必要，除非使用场景很少且很重量级Map#keySet方法，每次调用返回的是同一个Set对象，如果修改了返回的set，其他使用的代码可能会产生bug需要defensive copying的时候，如果没有创建一个新对象，将导致很隐藏的BugItem 6: 不再使用的对象一定要解除引用，避免memory leak例如，用数组实现一个栈，pop的时候，如果仅仅是移动下标，没有把pop出栈的数组位置引用解除，将发生内存泄漏程序发生错误之后，应该尽快把错误抛出，而不是以错误的状态继续运行，否则可能导致更大的问题通过把变量（引用）置为null不是最好的实现方式，只有在极端情况下才需要这样；好的办法是通过作用域来使得变量的引用过期，所以尽量缩小变量的作用域是很好的实践；注意，在Dalvik虚拟机中，存在一个细微的bug，可能会导致内存泄漏，详见当一个类管理了一块内存，用于保存其他对象（数据）时，例如用数组实现的栈，底层通过一个数组来管理数据，但是数组的大小不等于有效数据的大小，GC器却并不知道这件事，所以这时候，需要对其管理的数据对象进行null解引用当一个类管理了一块内存，用于保存其他对象（数据）时，程序员应该保持高度警惕，避免出现内存泄漏，一旦数据无效之后，需要立即解除引用实现缓存的时候也很容易导致内存泄漏，放进缓存的对象一定要有换出机制，或者通过弱引用来进行引用listner和callback也有可能导致内存泄漏，最好使用弱引用来进行引用，使得其可以被GCItem 7: 不要使用finalize方法finalize方法不同于C++的析构函数，不是用来释放资源的好地方finalize方法执行并不及时，其执行线程优先级很低，而当对象unreachable之后，需要执行finalize方法之后才能释放，所以会导致对象生存周期变长，甚至根本不会释放finalize方法的执行并不保证执行成功/完成使用finalize时，性能会严重下降finalize存在的意义充当“safety net”的角色，避免对象的使用者忘记调用显式termination方法，尽管finalize方法的执行时间没有保证，但是晚释放资源好过不释放资源；此处输出log警告有利于排查bug用于释放native peer，但是当native peer持有必须要释放的资源时，应该定义显式termination方法子类finalize方法并不会自动调用父类finalize方法（和构造函数不同），为了避免子类不手动调用父类的finalize方法导致父类的资源未被释放，当需要使用finalize时，使用finalizer guardian比较好：定义一个私有的匿名Object子类对象，重写其finalize方法，在其中进行父类要做的工作因为当父类对象被回收时，finalizer guardian也会被回收，它的finalize方法就一定会被触发##Object的方法尽管Object不是抽象类，但是其定义的非final方法设计的时候都是希望被重写的，finalize除外。Item 8: 当重写equals方法时，遵循其语义能不重写equals时就不要重写当对象表达的不是值，而是可变的状态时对象不需要使用判等时父类已重写，且满足子类语义当需要判等，且继承实现无法满足语义时，需要重写（通常是“value class”，或immutable对象）当用作map的key时重写equals时需要遵循的语义Reflexive（自反性）: x.equals(x)必须返回true（x不为null）Symmetric（对称性）: x.equals(y) == y.equals(x)Transitive（传递性）: x.equals(y) &amp;&amp; y.equals(z) ==&gt; x.equals(z)Consistent（一致性）: 当对象未发生改变时，多次调用应该返回同一结果x.equals(null)必须返回false实现建议先用==检查是否引用同一对象，提高性能用instanceof再检查是否同一类型再强制转换为正确的类型再对各个域进行equals检查，遵循同样的规则确认其语义正确，编写测例重写equals时，同时也重写hashCode！重写equals方法，传入的参数是ObjectItem 9: 重写equals时也重写hashCode函数避免在基于hash的集合中使用时出错语义一致性当两个对象equals返回true时，hashCode方法的返回值也要相同hashCode的计算方式要求：equals的两个对象hashCode一样，但是不equals的对象hashCode不一样取一个素数，例如17，result = 17对每一个关心的field（在equals中参与判断的field），记为f，将其转换为一个int，记为cboolean: f ? 1 : 0byte/char/short/int: (int) flong: (int) (f ^ (f &gt;&gt; 32))float: Float.floatToIntBits(f)double: Double.doubleToLongBits(f)，再按照long处理Object: f == null ? 0 : f.hashCode()array: 先计算每个元素的hashCode，再按照int处理对每个field计算的c，result = 31 * result + c返回result编写测例计算hashCode时，不重要的field（未参与equals判断）不要参与计算Item 10: 重写toString()方法增加可读性，简洁、可读、具有信息量Item 11: 慎重重写clone方法Cloneable接口是一个mixin interface，用于表明一个对象可以被cloneContractx.clone() != xx.clone().getClass() == x.getClass()：要求太弱，当一个非final类重写clone方法的时候，创建的对象一定要通过super.clone()来获得，所有父类都遵循同样的原则，如此最终通过Object.clone()创建对象，能保证创建的是正确的类实例。而这一点很难保证。x.clone().equals(x)不调用构造函数：要求太强，一般都会在clone函数里面调用对于成员变量都是primitive type的类，直接调用super.clone()，然后cast为自己的类型即可（重写时允许返回被重写类返回类型的子类，便于使用方，不必每次cast）成员变量包含对象（包括primitive type数组），可以通过递归调用成员的clone方法并赋值来实现然而上述方式违背了final的使用协议，final成员不允许再次赋值，然而clone方法里面必须要对其赋值，则无法使用final保证不可变性了递归调用成员的clone方法也会存在性能问题，对HashTable递归调用深拷贝也可能导致StackOverFlow（可以通过遍历添加来避免）优雅的方式是通过super.clone()创建对象，然后为成员变量设置相同的值，而不是简单地递归调用成员的clone方法和构造函数一样，在clone的过程中，不能调用non final的方法，如果调用虚函数，那么该函数会优先执行，而此时被clone的对象状态还未完成clone/construct，会导致corruption。因此上一条中提及的“设置相同的值”所调用的方法，要是final或者private。重载类的clone方法可以省略异常表的定义，如果重写时把可见性改为public，则应该省略，便于使用；如果设计为应该被继承，则应该重写得和Object的一样，且不应该实现Cloneable接口；多线程问题也需要考虑；要实现clone方法的类，都应该实现Cloneable接口，同时把clone方法可见性设为public，返回类型为自己，应该调用super.clone()来创建对象，然后手动设置每个域的值clone方法太过复杂，如果不实现Cloneable接口，也可以通过别的方式实现copy功能，或者不提供copy功能，immutable提供copy功能是无意义的提供拷贝构造函数，或者拷贝工厂方法，而且此种方法更加推荐，但也有其不足设计用来被继承的类时，如果不实现一个正确高效的clone重写，那么其子类也将无法实现正确高效的clone功能Item 12: 当对象自然有序时，实现Comparable接口实现Comparable接口可以利用其有序性特点，提高集合使用/搜索/排序的性能Contactsgn(x.compareTo(y)) == - sgn(y.compareTo(x))，当类型不对时，应该抛出ClassCastException，抛出异常的行为应该是一致的transitive: x.compareTo(y) &gt; 0 &amp;&amp; y.compareTo(z) &gt; 0 ==&gt; x.compareTo(z) &gt; 0x.compareTo(y) == 0 ==&gt; sgn(x.compareTo(z)) == sgn(y.compareTo(z))建议，但非必须：与equals保持一致，即 x.compareTo(y) == 0 ==&gt; x.equals(y)，如果不一致，需要在文档中明确指出TreeSet, TreeMap等使用的就是有序保存，而HashSet, HashMap则是通过equals + hashCode保存当要为一个实现了Comparable接口的类增加成员变量时，不要通过继承来实现，而是使用组合，并提供原有对象的访问方法，以保持对Contract的遵循实现细节优先比较重要的域谨慎使用返回差值的方式，有可能会溢出##Classes and InterfacesItem 13: 最小化类、成员的可见性封装（隐藏）：公开的接口需要暴露，而接口的实现则需要隐藏，使得接口与实现解耦，降低模块耦合度，增加可测试性、稳定性、可维护性、可优化性、可修改性如果一个类只对一个类可见，则应该将其定义为私有的内部类，而没必要public的类都应该定义为package private为了便于测试，可以适当放松可见性，但也只应该改为package private，不能更高成员不能是非private的，尤其是可变的对象。一旦外部可访问，将失去对其内容的控制能力，而且会有多线程问题暴露的常量也不能是可变的对象，否则public static final也将失去其意义，final成员无法改变其指向，但其指向的对象却是可变的（immutable的对象除外），长度非0的数组同样也是有问题的，可以考虑每次访问时创建拷贝，或者使用Collections.unmodifiableList(Arrays.asList(arr))Item 14: public class中，使用accessor method而非public field后者外部可以直接访问，失去了安全性package private或者private则可以不必这样把immutable的field置为public勉强可以接受，mutable的成员一定不能置为publicItem 15: 最小化可变性不提供可以改变本对象状态的方法保证类不可被继承使用final field使用private field在构造函数、accessor中，对mutable field使用defensive copy实现建议操作函数，例如BigInteger的add方法，不是static的，但也不能改变本对象的状态，则使用functional的方式，返回一个新的对象，其状态是本对象修改之后的状态如此实现的immutable对象生来就是线程安全的，无需同步操作，但应该鼓励共用实例，避免创建过多重复的对象正确实现的immutable对象也不需要clone, copy方法；可以适当引入Object cache；劣势每一个值都需要一个对象，调用改变状态的方法而创建一个新的对象，尤其是它是重量级的，开销会变大；连续调用这样的方法，影响更大；为常用的多次操作组合提供一个方法其他保证class无法被继承，除了声明为final外，还可以将默认构造函数声明为private或package private，然后提供public static工厂方法使用public static工厂方法，具体实现类可以有多个，还能进行object cache当实现Serializable接口是，一定要实现readObject/readResolve方法，或者使用ObjectOutputStream.writeUnshared/ObjectInputStream.readUnshared小结除非有很好的理由让一个Class mutable，否则应该使其immutable如果非要mutable，也应尽可能限制其可变性Item 16: Favor composition (and forwarding) over inheritance跨包继承、继承不是被设计为应该被继承的实现类，是一件很危险的事情，继承接口、继承抽象类，当然是没问题的如果子类的功能依赖于父类的实现细节，那么一旦父类发生变化，子类将有可能出现Bug，即便代码都没有修改；而设计为应被继承的类，在修改后，是应该有文档说明的，子类开发者既可以得知，也可以知道如何修改例子：统计HashSet添加元素的次数用继承方式，重写add，addAll，在其中计数，这就不对，因为HashSet内部的addAll是通过调用add实现的但是通过不重写addAll也只不对的，以后有可能HashSet的实现就变了在重写中重新实现一遍父类的逻辑也是行不通的，因为这可能会导致性能问题、bug等，而且有些功能不访问私有成员也是无法实现的还有一个原因就是父类的实现中，可能会增加方法，改变其行为，而这一点，在子类中是无法控制的而通过组合的方式，将不会有这些问题，把另一个类的对象声明为私有成员，外部将无法访问它，自己也能在转发（forwarding）过程中执行拦截操作，也不必依赖其实现细节，这种组合、转发的实现被称为wrapper，或者Decorator pattern，或者delegation（严格来说不是代理，代理一般wrapper对象都需要把自己传入到被wrap的对象方法中？）缺点不适用于callback frameworks？继承应该在is-a的场景中使用继承除了会继承父类的API功能，也会继承父类的设计缺陷，而组合则可以隐藏成员类的设计缺陷Item 17: Design and document for inheritance or else prohibit it一个类必须在文档中说明，每个可重写的方法，在该类的实现中的哪些地方会被调用（the class must document its self-use of overridable methods）。调用时机、顺序、结果产生的影响，包括多线程、初始化等情况。被继承类应该通过谨慎选择protected的方法或成员，来提供一些hook，用于改变其内部的行为，例如java.util.AbstractList::removeRange。The only way to test a class designed for inheritance is to write subclasses. 用于判断是否需要增加或者减少protected成员/方法，通常写3个子类就差不多了。You must test your class by writing subclasses before you release it.Constructors must not invoke overridable methods. 父类的构造函数比子类的构造函数先执行，而如果父类构造函数中调用了可重写的方法，那么就会导致子类的重写方法比子类的构造函数先执行，会导致corruption。如果实现了Serializable/Cloneable接口，neither clone nor readObject may invoke an overridable method, directly or indirectly. 重写方法会在deserialized/fix the clone’s state之前执行。如果实现了Serializable接口，readResolve/writeReplace必须是protected，而非privatedesigning a class for inheritance places substantial limitations on the class.The best solution to this problem is to prohibit subclassing in classes that are not designed and documented to be safely subclassed. 声明为final class或者把构造函数私有化（提供public static工厂方法）。如果确实想要允许继承，就应该为每个被自己使用的可重写方法都写好文档Item 18: Prefer interfaces to abstract classesJava类只允许单继承，接口可以多继承，使用接口定义类型，使得class hierarchy更加灵活定义mixin（optional functionality to be “mixed in”）时使用interface是很方便的，需要增加此功能的类只需要implement该接口即可，而如果使用抽象类，则无法增加一个extends语句接口允许构建没有hierarchy的类型系统使用接口定义类型，可以使得item 16中提到的wrapper模式更加安全、强大，skeletal implementation：该类为abstract，把必须由client实现的方法设为abstract，可以有默认实现的则提供默认实现simulated multiple inheritance：通过实现定义的接口，同时在内部实现一个匿名的skeletal implementation，将对对该接口的调用转发到匿名类中，起到“多继承”的效果simple implementation：提供一个非抽象的接口实现类，提供一个最简单、能work的实现，也允许被继承使用接口定义类型的缺点：不便于演进，一旦接口发布，如果想要增加功能（增加方法），则client将无法编译；而使用abstract class，则没有此问题，只需要提供默认实现即可小结通过接口定义类型，可以允许多实现（多继承）但是演进需求大于灵活性、功能性时，抽象类更合适提供接口时，提供一个skeletal implementation，同时审慎考虑接口设计Item 19: 仅仅用interface去定义一个类型，该接口应该有实现类，使用者通过接口引用，去调用接口的方法避免用接口去定义常量，应该用noninstantiable utility class去定义常量相关常量的命名，通过公共前缀来实现分组Item 20: Prefer class hierarchies to tagged classestagged class: 在内部定义一个tag变量，由其控制功能的转换tag classes are verbose, error-prone, and inefficient而class hierarchy，不同功能由不同子类实现，公共部分抽象为一个基类，也能反映出各个子类之间的关系Item 21: Use function objects to represent strategies只提供一个功能函数的类实例，没有成员变量，只需一个对象（单例），为其功能定义一个接口，则可以实现策略模式，把具体策略传入相应函数中，使用策略具体的策略实例通常使用匿名类定义，调用使用该策略的方法时才予以创建/预先创建好之后每次将其传入Item 22: Favor static member classes over nonstatic有4种nested class：non-static member class; static member class(inner class); anonymous class; local classstatic member class经常作为helper class，和外部类一起使用如果nested class的生命周期独立于外部类存在，则必须定义为static member class，否则可能造成内存泄漏private static member class用处一：表示（封装）外部类的一些成员，例如Map的Entry内部类。non-static member class将持有外部类实例的强引用，可以直接引用外部类的成员和方法用处一：定义一个Adapter，使得外部内的实例，可以作为和外部类语义不同的实例来查看（访问），例如Collection的Iterator。如果nested class不需要引用外部类的成员和方法，则一定要将其定义为static，避免空间/时间开销，避免内存泄漏anonymous class当在非static代码块内定义时，会持有外部类的引用，否则不会持有限制只能在被声明的地方进行实例化无法进行instanceof测试不能用匿名类实现多个接口不能用匿名类继承一个类的同时实现接口匿名类中新添加的方法无法在匿名类外部访问不能有static成员应该尽量保持简短用处一：创建function object用处二：创建process object，例如：Runnable, Thread, TimberTask用处三：用于public static工厂方法，例如Collections类里面的一些工厂方法，很多是返回一个匿名的内部实现local class比较少用是否static取决于其定义的上下文可以在作用域内重复使用不能有static成员也应尽量保持简短小结四种nested class如果nested class在整个外部类内都需要可见，或者定义代码太长，应使用member class能static就一定要static，即便需要对外部类进行引用，对于生命周期独立于外部类的，也应该通过WeakReference进行引用，避免内存泄漏；至于生命周期和外部类一致的，则不必这样GenericsItem 23: Don’t use raw types in new codeJava泛型，例如List&lt;E&gt;，真正使用的时候都是List&lt;String&gt;等，把E替换为实际的类型Java泛型从1.5引入，为了保持兼容性，实现的是伪泛型，类型参数信息在编译完成之后都会被擦除，其在运行时的类型都是raw type，类型参数保存的都是Object类型，List&lt;E&gt;的raw type就是List编译器在编译期通过类型参数，为读操作自动进行了类型强制转换，同时在写操作时自动进行了类型检查如果使用raw type，那编译器就不会在写操作时进行类型检查了，写入错误的类型也不会报编译错误，那么在后续读操作进行强制类型转换时，将会导致转换失败，抛出异常一旦错误发生，应该让它尽早被知道（抛出/捕获），编译期显然优于运行期List与List&lt;Object&gt;的区别前者不具备类型安全性，后者具备，例如以下代码12345678910// Uses raw type (List) - fails at runtime!public static void main(String[] args) &#123; List&lt;String&gt; strings = new ArrayList&lt;String&gt;(); unsafeAdd(strings, new Integer(42)); String s = strings.get(0); // Compiler-generated cast&#125;private static void unsafeAdd(List list, Object o) &#123; list.add(o);&#125;不会报编译错误，但会给一个编译警告：Test.java:10: warning: unchecked call to add(E) in raw type List list.add(o);，而运行时则会发生错误。但如果使用List&lt;Object&gt;，即unsageAdd参数改为List&lt;Object&gt; list, Object o，则会报编译错误：Test.java:5: unsafeAdd(List&lt;Object&gt;,Object) cannot be applied to (List&lt;String&gt;,Integer) unsafeAdd(strings, new Integer(42));因为List&lt;String&gt;是List的子类，但却不是List&lt;Object&gt;的子类。并不是说这个场景应该使用List&lt;Object&gt;，这个场景应该使用List&lt;String&gt;，这里只是为了说明List和List&lt;Object&gt;是有区别的。List v.s. List&lt;?&gt;（unbounded wildcard types），当不确定类型参数，或者说类型参数不重要时，也不应该使用raw type，而应该使用List&lt;?&gt;任何参数化的List均是List&lt;?&gt;的子类，可以作为参数传入接受List&lt;?&gt;的函数，例如以下代码均是合法的：1234567void func(List&lt;?&gt; list) &#123; ...&#125;func(new List&lt;Object&gt;());func(new List&lt;Integer&gt;());func(new List&lt;String&gt;());持有List&lt;?&gt;的引用后，并不能向其中加入任何元素，读取出来的元素也是Object类型，而不会被自动强转为任何类型。如果List&lt;?&gt;的行为不能满足需求，可以考虑使用模板方法，或者List&lt;E extends XXX&gt;（bounded wildcard types）You must use raw types in class literals.List.class, String[].class, and int.class are all legal, but List&lt;String&gt;.class and List&lt;?&gt;.class are not.instanceof不支持泛型，以下用法是推荐的，但不应该将o强转为List12345// Legitimate use of raw type - instanceof operatorif (o instanceof Set) &#123; // Raw type Set&lt;?&gt; m = (Set&lt;?&gt;) o; // Wildcard type ...&#125;相关术语汇总Item 24: Eliminate unchecked warnings当出现类型不安全的强制转换时（一般都是涉及泛型，raw type），编译器会给出警告，首先要做的是尽量消除不安全的转换，消除警告实在无法消除/确定不会导致运行时的ClassCastException，可以通过@SuppressWarnings(&quot;unchecked&quot;)消除警告，但不要直接忽略该警告使用@SuppressWarnings(&quot;unchecked&quot;)时，应该在注视内证明确实不存在运行时的ClassCastException；同时应该尽量减小其作用的范围，通常是应该为一个赋值语句添加注解Item 25: Prefer lists to arraysarrays are covariant(协变): 如果Sub是Super的子类，那么Sub[]也是Super[]的子类generics are invariant(不变): 任意两个不同的类Type1和Type2，List&lt;Type1&gt;和List&lt;Type2&gt;之间没有任何继承关系考虑以下代码1234567// Fails at runtime!Object[] objectArray = new Long[1];objectArray[0] = "I don't fit in"; // Throws ArrayStoreException// Won't compile!List&lt;Object&gt; ol = new ArrayList&lt;Long&gt;(); // Incompatible typesol.add("I don't fit in");arrays are reified(具体化): array在运行时能知道且强制要求元素的类型generics are implemented by erasure(non-reifiable): 仅仅在编译时知道元素的类型数组和泛型同时使用时会受到很大限制以下语句均不能通过编译：new List&lt;E&gt;[], new List&lt;String&gt;[], new E[]；但是声明是可以的，例如List&lt;String&gt;[] stringListsnon-reifiable type: 例如E, List&lt;E&gt;, List&lt;String&gt;，这些类型在运行时的信息比编译时的信息更少只有unbounded wildcard type才是reifiable的，如：List&lt;?&gt;, Map&lt;?, ?&gt;常规来说，不能返回泛型元素的数组，因为会报编译错误：generic array creation errors当泛型和varargs一起使用时，也会导致编译警告有时为了类型安全，不得不做些妥协，牺牲性能和简洁，使用List而不是数组把数组强转为non-reifiable类型是非常危险的，仅应在非常确定类型安全的情况下使用Item 26: Favor generic types当需要一个类成员的数据类型具备一般性时，应该用泛型，这也正是泛型的设计场景之一，不应该用Object类但使用泛型有时也不得不进行cast，例如当泛型遇上数组总的来说把suppress数组类型强转的unchecked warning比suppress一个标量类型强转的unchecked warning风险更大，但有时出于代码简洁性考虑，也不得不做出妥协有时看似与item 25矛盾，实属无奈，Java原生没有List，ArrayList不得不基于数组实现，HashMap也是基于数组实现的泛型比使用者进行cast更加安全，而且由于Java泛型的擦除实现，也可以和未做泛型的老代码无缝兼容Item 27: Favor generic methods泛型方法的类型参数在函数修饰符（可见性/static/final等）和返回值之间，例子：123456// Generic methodpublic static &lt;E&gt; Set&lt;E&gt; union(Set&lt;E&gt; s1, Set&lt;E&gt; s2) &#123; Set&lt;E&gt; result = new HashSet&lt;&gt;(s1); result.addAll(s2); return result;&#125;recursive type bound12// Using a recursive type bound to express mutual comparabilitypublic static &lt;T extends Comparable&lt;T&gt;&gt; T max(List&lt;T&gt; list) &#123;...&#125;泛型方法要比方法使用者进行cast更加安全Item 28: Use bounded wildcards to increase API flexibility考虑以下代码1234567891011121314151617public class Stack&lt;E&gt; &#123; public Stack(); public void push(E e); public E pop(); public boolean isEmpty(); public void pushAll(Iterable&lt;E&gt; src); public void popAll(Collection&lt;E&gt; dst);&#125;Stack&lt;Number&gt; numberStack = new Stack&lt;Number&gt;();Iterable&lt;Integer&gt; integers = ... ;numberStack.pushAll(integers);Stack&lt;Number&gt; numberStack = new Stack&lt;Number&gt;();Collection&lt;Object&gt; objects = ... ;numberStack.popAll(objects);pushAll和popAll的调用均无法通过编译，因为尽管Integer是Number的子类，但Iterable&lt;Integer&gt;不是Iterable&lt;Number&gt;的子类，这是由泛型的invariant特性导致的，所以Iterable&lt;Integer&gt;不能传入接受Iterable&lt;Number&gt;参数的函数，popAll的使用同理bounded wildcards: &lt;? extends E&gt;, &lt;? super E&gt;, PECS stands for producer-extends, consumer-super. 如果传入的参数是要输入给该类型数据的，则应该使用extends，如果是要容纳该类型数据的输出，则应该使用super这很好理解，作为输入是要赋值给E类型的，当然应该是E的子类（这里的extends包括E类型本身）；而容纳输出是要把E赋值给传入参数的，当然应该是E的父类（同样包括E本身）返回值类型不要使用bounded wildcards，否则使用者也需要使用，这将会给使用者造成麻烦代码对于bounded wildcards的使用在使用者那边应该是透明的，即他们不会感知到bounded wildcards的存在，如果他们也需要考虑bounded wildcards的问题，则说明对bounded wildcards的使用有问题了有时候编译器的类型推导在遇到bounded wildcards会无法完成，这时就需要显示指定类型信息，例如：123456public static &lt;E&gt; Set&lt;E&gt; union(Set&lt;? extends E&gt; s1, Set&lt;? extends E&gt; s2);Set&lt;Integer&gt; integers = ... ;Set&lt;Double&gt; doubles = ... ;//Set&lt;Number&gt; numbers = union(integers, doubles); //compile errorSet&lt;Number&gt; numbers = Union.&lt;Number&gt;union(integers, doubles); //compile passComparables are always consumers, so you should always use Comparable&lt;? super T&gt; in preference to Comparable&lt;T&gt;. The same is true of comparators, so you should always use Comparator&lt;? super T&gt; in preference to Comparator&lt;T&gt;.unbounded type parameter(&lt;E&gt; ... List&lt;E&gt;) v.s. unbounded wildcard(List&lt;?&gt;)：if a type parameter appears only once in a method declaration, replace it with a wildcard.Item 29: Consider typesafe heterogeneous containers使用泛型时，类型参数是有限个的，例如List&lt;T&gt;，Map&lt;K, V&gt;，但有时可能需要一个容器，能放入任意类型的对象，但需要具备类型安全性，例如数据库的一行，它的每一列都可能是任意类型的数据由于Class类从1.5就被泛型化了，所以使得这种需求可以实现，例如：12345// Typesafe heterogeneous container pattern - APIpublic class Favorites &#123; public &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance); public &lt;T&gt; T getFavorite(Class&lt;T&gt; type);&#125;通常这样使用的Class对象被称为type token，它传入函数，用来表述编译时和运行时的类型信息Favorites的实现也是很简单的：1234567891011121314// Typesafe heterogeneous container pattern - implementationpublic class Favorites &#123; private Map&lt;Class&lt;?&gt;, Object&gt; favorites = new HashMap&lt;Class&lt;?&gt;, Object&gt;(); public &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance) &#123; if (type == null) throw new NullPointerException("Type is null"); favorites.put(type, instance); &#125; public &lt;T&gt; T getFavorite(Class&lt;T&gt; type) &#123; return type.cast(favorites.get(type)); &#125;&#125;注意，这里的unbound wildcard并不是应用于Map的，而是应用于Class的类型参数，因此Map可以put key进去，而且key可以是任意类型参数的Class对象另外，Map的value类型是Object，一旦put到Map中去，其编译期类型信息就丢失了，将通过get方法的动态类型转换（cast）来重新获得其类型信息cast方法将检查类型信息，如果是该类型（或其子类），转换将成功，并返回引用，否则将抛出ClassCastException这一heterogeneous container实现有两个不足通过为put方法传入Class的raw type，使用者可以很轻易地破坏类型安全性，解决方案也很简单，在put时也进行一下cast：1234// Achieving runtime type safety with a dynamic castpublic &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance) &#123; favorites.put(type, type.cast(instance));&#125;这样做的效果是使得想要破坏类型安全性的put使用者产生异常，而使用get的使用者则不会因为恶意put使用者产生异常。这种做法也被java.util.Collections包中的一些方法使用，例如命名为checkedSet, checkedList, checkedMap的类。这个容器内不能放入non-reifiable的类型，例如List&lt;String&gt;，因为List&lt;String&gt;.class是有语法错误的，List&lt;String&gt;, List&lt;Integer&gt;都只有同一个class对象：List.class；另外String[].class是合法的。Favorites使用的类型参数是unbounded的，可以put任意类型，也可以使用bounded type token，使用bounded时可能需要把Class&lt;?&gt;转换为Class&lt;? extends Annotation&gt;，直接用class.cast将会导致unchecked warning，可以通过class.asSubclass来进行转换，例子：12345678910// Use of asSubclass to safely cast to a bounded type tokenstatic Annotation getAnnotation(AnnotatedElement element, String annotationTypeName) &#123; Class&lt;?&gt; annotationType = null; // Unbounded type token try &#123; annotationType = Class.forName(annotationTypeName); &#125; catch (Exception ex) &#123; throw new IllegalArgumentException(ex); &#125; return element.getAnnotation(annotationType.asSubclass(Annotation.class));&#125;##Enums and AnnotationsItem 30: Use enums instead of int constants类型安全可以为常量提供数据和方法的绑定可以遍历实现建议如果是通用的，应该定义为top level enum，否则应定义为内部类constant-specific method implementations12345678// Enum type with constant-specific method implementationspublic enum Operation &#123; PLUS &#123; double apply(double x, double y)&#123;return x + y;&#125; &#125;, MINUS &#123; double apply(double x, double y)&#123;return x - y;&#125; &#125;, TIMES &#123; double apply(double x, double y)&#123;return x * y;&#125; &#125;, DIVIDE &#123; double apply(double x, double y)&#123;return x / y;&#125; &#125;; abstract double apply(double x, double y);&#125;结合constant-specific data123456789101112131415161718192021// Enum type with constant-specific class bodies and datapublic enum Operation &#123; PLUS("+") &#123; double apply(double x, double y) &#123; return x + y; &#125; &#125;, MINUS("-") &#123; double apply(double x, double y) &#123; return x - y; &#125; &#125;, TIMES("*") &#123; double apply(double x, double y) &#123; return x * y; &#125; &#125;, DIVIDE("/") &#123; double apply(double x, double y) &#123; return x / y; &#125; &#125;; private final String symbol; Operation(String symbol) &#123; this.symbol = symbol; &#125; @Override public String toString() &#123; return symbol; &#125; abstract double apply(double x, double y);&#125;If switch statements on enums are not a good choice for implementing con- stant-specific behavior on enums, what are they good for? Switches on enums are good for augmenting external enum types with constant-specific behavior.A minor performance disadvantage of enums over int constants is that there is a space and time cost to load and initialize enum types.所以，在安卓设备（手机、平板）上，应该避免使用enum，减小空间和时间的开销Item 31: Use instance fields instead of ordinals每个enum的常量都有一个ordinal()方法获取其在该enum类型中的位置，但该方法只应该在实现EnumSet, EnumMap等类型的时候被使用，其他情形都不应该被使用如果需要为每一个常量绑定一个数据，可以使用instance field实现，如果需要绑定方法，则可以用constant-specific method implementations，参考上一个itemItem 32: Use EnumSet instead of bit fieldsbit fields的方式不优雅、容易出错、没有类型安全性EnumSet则没有这些缺点，而且对于大多数enum类型来说，其性能都和bit field相当通用建议：声明变量时，不要用实现类型，应该用接口类型，例如，应该用List&lt;Integer&gt;而不是ArrayList&lt;Integer&gt;EnumSet并非immutable的，可以通过Conllections.unmodifiableSet来封装为immutable，但是代码简洁性与性能都将受到影响]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb索引]]></title>
    <url>%2Fposts%2Fc2f6f9e3%2F</url>
    <content type="text"><![CDATA[索引简介索引是用来加速查询的，类似于数的目录一样。我们要查找某些内容不需要查遍整个数据库，只需要先在索引中查找，找到相应索引之后根据索引找到指向的文档。创建索引使用ensureIndex函数，db.people.ensureIndex({&#39;username&#39;:1}),1代表对索引内容进行正向排序，-1代表对索引内容逆向排序。对某个键创建的索引会加速以该键为查询条件的查询，对其他查询没有帮助。索引创建既可以针对单个键创建也可以针对多个键创建，例如db.people.ensureIndex({&#39;name&#39;:1,age:-1,&#39;sex&#39;:1})其作用原理与sort相同(由前到后逐个匹配)。如果创建了我们上面所看到的索引实际上是有了{name:1},{name:1,age:-1},{name:1,age:-1,sex:1}三个索引，使用{age:-1}等索引的查询不会得到优化。创建索引并不是只有优点的，他的缺点就是每次插入，更新，删除都会产生额外的开销用来更新索引。所以我们要根据实际情况合理的创建索引，通常我们要考虑实际情况中都需要经常对哪些键查询，然后对该查询字段创建索引，每个集合的最大索引个数为64个注意索引顺序当我们创建多键索引时要分清主次，一般我们可以这样认为，当根据我们创建的多键索引进行查询时会先根据前面的条件筛选，将结果用于下一次筛选。所以创建多键索引时我们要将主要索引条件放在前面，建立索引时要考虑如下问题：会做什么样的查询，其中哪些键需要索引每个键的索引方向是怎样的如何应对拓展，有没有种不同的键的排列可以是常用数据更多地保存在内存中索引内嵌文档为内嵌文档建立索引和为普通的键创建索引没有什么区别，只是在索引内嵌文档的字段的时候使用点表达式，也可以和普通键索引组成复合索引为排序创建索引随着集合的增长，需要针对大量的排序做索引。因为如果排序实在内存中完成的，如果数据量特别大超出内存的限制就是报错。如果没有对数据进行sort，默认就是查询出来的顺序，所以创建索引之后查询出来的顺序就是排序之后的结果索引名称每一个索引都有一个字符串类型的名字用来唯一标示，数据库通过这个名字来删除或操作索引。默认情况索引名类似keyname1_dir1_keyname2_dir2…形式（keynameX代表索引的键，dirX代表索引的方向）。我们可以通过ensureIndex的第二个参数来指定索引的名字1db.people.ensureIndex(&#123;'name':1,'age':-1&#125;,&#123;'name':'index1'&#125;)唯一索引唯一所以可以确保集合的每一个文档的指定键都有唯一的值，相当于关系型数据库中的unique键。要创建唯一索引需要在ensureIndex的第二个参数中指定unique为true。在创建集合是自动给我们创建了_id唯一索引，与普通唯一索引的区别是不能被删除1db.people.ensureIndex(&#123;'username':1&#125;,&#123;'unique':true&#125;)可能当我们创建唯一索引的时候，有些值已经有重复了，这时候索引的创建就会失败。但是我们可以使用dropDups选项，这样可以保留发现的第一个文档，将其他重复文档删除1db.people.ensureIndex(&#123;'username':1&#125;,&#123;'unique':true, 'dropDups':true&#125;)创建符合唯一索引的时候，单个键的值可以相同，只要所有键的值组合起来不同就好强制使用索引如果发现MongoDb没有使用预期的索引，可以用hint强制使用某个索引。例如希望使用{&#39;username&#39;:1,&#39;age&#39;:1}索引1db.people.find(&#123;'age':14,'username':'nicolas'&#125;).hint(&#123;'username':1,'age':1&#125;)多数情况下并没有这么做的必要，MongoDb会非常智能的选择使用哪个索引。在初次查询时会尝试各种查询方案，最优方案会被记录下来，还会定期重试其他方案，防止建立新的索引之后方案不再是最优索引管理索引的原信息存储在每个数据库的system.indexes集合中，不能对该集合插入或删除文档，操作只能通过ensureIndex和dropIndex进行建立索引既耗时有费力，还需要消耗很多资源，可以使用{&#39;background&#39;:true}选项是这个过程在后台完成，同时正常处理请求。一般来说为已有文档创建索引比先创建索引再插入所有文档要稍快一些。不管怎么说在无关紧要的时刻创建索引是最好的选择当索引没用的时候可以通过dropIndex选项删除索引,删除依据是创建索引的条件1db.people.dropIndex(&#123;'username':1,'age':-1&#125;)地理空间索引MongoDb为坐标平面提供了专门的索引成为地理空间索引，可以找出离某一坐标平面最近的点。创建地理空间索引同样适用ensureIndex选项，只不过参数不是1或-1而是2d。建立索引的键的值必须是包含两个元素的数组或包含两个键的内嵌文档(键名可以随意)。地理空间索引默认的范围是180·-180，如果想要指定大小可以使用第二个参数1db.start.insureIndex(&#123;'light-year':'2d'&#125;,&#123;'min':-1000,'max':1000&#125;)地理空间索引的查询和普通的find查询差别不大，只不过使用了$near，需要两个目标值的数组作为参数，默认返回100个距离给点坐标最近的文档，可以使用limit进行限制。还可以使用$maxDistance限定查询的最大距离1db.map.find(&#123;'gps':&#123;$near:[40,-73], $maxDistance:40&#125;&#125;).limit(10)MongoDb不仅可以根据距离查询，还可以根据形状查询，目前支持矩形,圆形查询和多边形查询，需要用到$within123456//要给出矩形左上角和右下角坐标db.map.find(&#123;'gps':&#123;$within:&#123;$box:&#123;[10,30],[15,40]&#125;&#125;&#125;&#125;)//需要圆的原点坐标和半径db.map.find(&#123;'gps':&#123;$within:&#123;$circle:&#123;[10,20],40&#125;&#125;&#125;&#125;)//多边形各个点的坐标db.map.find(&#123;'gps':&#123;$within:&#123;$polygon:[[1,2],[1,4],[6,3]]&#125;&#125;&#125;)我们可以组合地理空间索引和普通索引，这样可以满足继续要地里空间限制条件组合普通限制条件的查找1db.ensureIndex(&#123;'location':'2d','desc':1&#125;)]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MongoDb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb查询]]></title>
    <url>%2Fposts%2Ff3e67b24%2F</url>
    <content type="text"><![CDATA[简介使用find或者findOne对数据库执行查询使用$条件实现范围，集合包含，不等式和其他查询使用$where子句用户复杂查询查询会返回一个数据库游标，只有在需要数据的时候才会惰性的返回文档针对游标执行的元操作，比如忽略一定数量的结果，限定返回结果的数量，对结果进行排序find简介db.users.find()db.users.find({‘name’:’nicolas’,’age’:20})不带参数的find会返回全部文档。find可以指定查询文档，只返回匹配查询条件的文档，当查询文档含有多个K-V时连接条件为AND,第二个查询语句会返回name为nicolas并且age为20的文档指定返回的键db.users.find({},{‘name’:1,’age’:0})有时我们并不需要将文档中的所有K-V都返回，这种情况我们可以使用find函数的第二个参数指定要返回的键。其中1代表将返回的文档按照该字段正向排序，0代表将返回的文档按照该字段逆向排序限制db.stock.find({‘in_stock’:’this.num_sold’})查询文档必须是常量（在自己代码里可以使正常的变量），但是不能引用文档中其他键的值。故上面的这个查询是错误的查询条件比较操作符$gt,$gte,$gt,gte是全部的比较操作符，分别对应&lt;,&lt;=,&gt;,&gt;=，可以将其组合起来查找一个范围的值。其中对于日期查询尤为有用，因为对日期的精确匹配终究是徒劳的。db.users.find({‘age’:{$lt:30,$gt:20}) 查找年龄大于20小于30的人start = new Date(“01/01/2007”)db.users.find(‘registered’:{$lt:start}) 查找注册日期在2007年1月1日之前的用户OR查询$in可以用来查询键值在给定数组中的文档，与之相反的是$nin。这两者用来对单个键做OR查询db.users.find({‘name’:{$in:[‘nicolas’,’windylee’]}) 返回name为nicolas或windylee的文档$or可以对多个键做OR查询，$or接受一个包含所有可能条件的数组作为参数，只要符合数组中任何一个元素的条件就会被查询出来，$or可以包含其他条件。普通的and兴的查询，总是尽可能的用最少的条件来限定结果的范围，or型的查询真好相反，第一个条件尽可能地匹配更多的文档db.users.find({$or:[{‘name’:{$in:[‘nicolas’,’windylee’]}},’age’:20]}) 查询name为nicolas或windylee或age为20的用户$not查询$not是元条件句，可以用在任何其他条件之上，表示对其他条件的结果取反。经常与正则表达式联合使用，用来查询不匹配正则表达式的文档db.users.find({‘age’:{$not:{$mod:[5,1]}}) 查询age值模5余数不为1的文档条件句的规则条件句是内层文档的键，修改器是外层文档的键，可对一个键应用多个条件，但是一个键不能对应多个更新修改器。例如{$inc:{&#39;age&#39;:20},$set:{&#39;age&#39;:40}}修改了age两次特定于类型的查询空值查询nullnull不仅能够匹配到键值为null的文档，他还能匹配缺少这个键的所有文档$exists如果仅仅想匹配键值为null的文档，就需要使用到该关键字db.users.find({‘name’:{$exists:true}}) 返回name值不为空的文档查询数组$ll返回含有$all指向数组所有元素的文档db.users.find(‘course’:{$all:[‘english’,’chinese’]}) 返回课程含有english和chinese的用户$size返回数组长度为指定大小的文档，$size不能与其他查询子句组合(比如$gt)db.users.find({‘course’:{$size:3}}) 返回选了3门课的文档$slice返回一个数组的子集合。可以接受一个整型n，整数表示返回数组的前n条数据，负数表示返回数组的后n条数据；可以接受一个数组，数组的第一个元素表示偏移量，第二个元素表示获取的元素数量。除非特别声明，$slice返回文档中的所有键db.blog.posts.findOne(criteria,{‘comments’:{$slice,[1,2]}}) 默认会返回posts中的所有字段查询内嵌文档如果存在如下文档1234567&#123; 'name':&#123; 'first':'Jone' 'last':'Schmoe' &#125; 'age':45&#125;要查询姓名为Jon Schmoe的人可以这样db.people.find({&#39;name&#39;:{&#39;first&#39;:&#39;Jon&#39;,&#39;last&#39;:&#39;Schmoe&#39;}})这种方式采用全部匹配的规则，即查询条件中要包含内嵌文档的所有键，如果name内嵌文档中增加middle字段则上述查询条件就不起作用了。如果只想根据部分字段进行查询则需要点表达式db.people.find({&#39;name.first&#39;:&#39;Joe&#39;,&#39;name.last&#39;:&#39;Schmoe&#39;})，这也是带插入的文档不能包含’.’的原因当文档变负责以后，即内嵌文档为数组时，如果有如下文档123456789101112131415&#123; 'content':'...' 'comments':[ &#123; 'author':'joe', 'score':3, 'comment':'nice post' &#125;, &#123; 'author':'mary', 'score':6, 'comment':'terrible post' &#125; ]&#125;如果继续使用点表达式db.blog.find({&#39;comments.author&#39;:&#39;jone&#39;,&#39;score&#39;:6})则第一个条件会在comments1中找到，第二个条件会在comments2中找到，所以会返回我们上面看到的文档。若要正确指定一组条件我们需要$elemMatch，这种模糊的命名条件句能用来部分指定匹配数组中的单个嵌入文档的限定条件，所以正确的写法应该是这样的db.blog.find({&#39;comments&#39;:{$eleMatch:{&#39;author:&#39;Jone&#39;,&#39;score&#39;:&#39;6}}})$where查询我们上面说过find的查询条件只能是常量，不能是文档中的值，如果我们查询条件为文档中的数据，那这时候我们就需要$where子句了，例如db.foo.find({$where:&#39;this.x+this.y=10&#39;})。$where速度要慢很多，除非必要不要使用该条件。游标数据库使用游标来返回find的执行结果，客户端队游标的实现通常能够对最终结果进行有效的控制，可以限制结果的数量，略过部分结果，根据任意方向任意键的组合对结果进行各种排序，或者执行其他一些功能强大的操作。当调用find的时候并不立即查询数据库，而是等待真正开始要求获得结果的时候才发送查询，这样我们就可以在执行之前给查询附加额外的选项limit, skip, sortlimit限定返回结果的上限，skip跳过前n个匹配的文档；sort指定排序的键和排序条件，1为正序排序，-1为降序排序，如果指定了多个键，则按照多个键的顺序逐个排序，例如要按照username升序和age降序排序db.c.find().sort({&#39;username&#39;:1,&#39;age&#39;:-1})。find函数返回游标，这三个函数都可以组成链式操作。如果一个键对应不同的类型，则规定的类型顺序：最小值 &lt; null &lt; 数字（整形，长整形，双精度）&lt; 字符串 &lt; 对象/文旦 &lt; 数组 &lt; 二进制数据 &lt; 对象ID &lt; 布尔型 &lt; 日期型 &lt; 时间戳 &lt; 正则表达式 &lt; 最大值避免使用skip略过大量结果使用skip略过大量结果就会使操作变得非常缓慢，几乎所有的数据库都有这个问题，所以我们应尽量避免使用skip不用skip对结果分页分页最简单的方式就是结合使用limit和skip两个函数，但我们可以有更好的解决方案。例如我们最获取文档时一般按照时间顺序进行排序，我们可以获取第一次获取的文档最后一个的时间，然后可以利用该时间值最为查询条件来获取下一页123456var latest=nullwhile(page1.hasNext())&#123; latest=page1.next(); display(latest)&#125;var page2=db.foo.find(&#123;'date':&#123;$gt:latest.date&#125;).sort('date':-1).limit(10)随机选取文档一般做法是要查询文档总数，然后在0~n中选择一个随机数，使用skip跳过这些随机数来获取随机的一个文档。这样查询总数和使用skip略过文档都需要花费大量时间。我们可以再一开始就在文档中插入一个随机数的键，然后根据该随机数获取随机文档12db.people.insert(&#123;'name':'nicolas','random':Math.random()&#125;)db.people.findOne(&#123;random:&#123;$lt:Math.random()&#125;&#125;)]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MongoDb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb创建，删除，更改]]></title>
    <url>%2Fposts%2F9aa16efd%2F</url>
    <content type="text"><![CDATA[插入并保存文档db.foo.insert({‘bar’:baz”})会自动给文档增加一个”_id”键(如果原来没有的话)。驱动程序会将数据转换成BSON形式，数据库解析BSON，检验是否包含’_id’键，并且文档长度不能超过4MB删除文档db.users.remove()会删除users集合中的所有文档，但是不会删除集合本身，原来的索引也会保留。remove函数可以接受一个查询文档作为可选参数，只有符合条件的文档才会被删除，例如 &gt;db.mailing.list.remove({‘opt-out’:true})删除集合db.users.drop()会删除users集合，所有的索引也会被删除，速度要比remove()快很多更新文档文档存入数据库以后，可以使用update方法来修改他，update有两个参数，一个是查询文档，用来找出要更新的文档，另一个是修改器文档，描述对找到的文档做哪些更改文档替换db.users.update({‘name’:’nicolas’},{‘age’:20})完全用一个文档去替换另一个文档，不使用任何关键字，默认文档会变成和第二个参数文档完全一样的形式，例子中更新之后文档中就只有age字段使用修改器对字段值修改不需要改变文档的大小，修改速度非常快。对数组修改可能需要改变文档的大小，修改速度回慢一下$incdb.users.update({‘name’:’nicolas’},{$age:{‘age’,1}})更新之后age字段会增加1，当为负数时自减。当键不存在时创建一个键。只能用于整数，长整数和说京都浮点数$setdb.user.update({‘name’:’nicolas’},{$set:{‘age’:20}})$set用来指定一个键的值，如果这个键不存在就创建他。$set甚至可以修改键的数据类型。$set可以修改内嵌文档，只要将内嵌字段用”.”连接即可，类似于引用对象变量`$unset·db.users.update({‘name’:’nicolas’},{$unset:{‘age’:1}})会将age的键删除$push如果指定的键已经存在，会向已有的数组末尾加入一个元素，要是没有就会创建一个新的数组$nedb.users.update({‘course’:{$ne:’english’}},{$push:{‘course’:’english’}})当course字段中不存在english值时，会向course字段数组中放入english$addToSetdb.users.update({‘name’:’nicolas’},{$addToSet:{‘courses’:’english’}})当name为nicolas中的course字段数组中不包括english是向其中添加english$eachdb.users.update({‘name’:’nicolas’},{$addToSet:{‘course’:{$each:[‘english’,’chinese’,’math’]}}})如果不存在这像个课程就像course字段中一次添加这些课程$popdb.users.update({‘name’:’nicolas’},{$pop:{‘course’:1}})可以冲数组的任何一段删除元素，1从数组末尾删除一个元素，-1从数组头部删除$pulldb.users.update({‘name’:’nicolas’},{$pull:{‘course’:’english’}})根据特定条件删除元素，例子中删除course数组中值为english的元素$db.blog.update({‘post’:1},{$inc,{‘comments.0.votes’:1}})使comments数组下标为0的元素中votes字段的值自增1db.blog.update({‘comments.author’:’nicolas’},{$inc,{‘comments.$.votes’:1}})首先会查找comments数组中author为nicolas的元素，记录下其下标。并改变该下标中元素的votes值为1upsertdb.person.update({‘name’:’windylee’},{$set:{‘age’:21,’sex’:’man’}},true)upsert是一种特殊的更新，要是没有文档符合更新调价，就会以这个条件和更新文档为基础创建一个新的文档，如果匹配则正常更新。将update的第三个参数设置为true即可开启此功能。例子中将会插入name，age，sex三个字段更新多个文档默认情况下，更新只能对符合匹配条件的第一个文档执行操作，要使所有匹配到的文档都得到更新，可以设置update的第四个参数为true]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MongoDb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown新手指南]]></title>
    <url>%2Fposts%2Fbc135409%2F</url>
    <content type="text"><![CDATA[Markdown简介Markdown是什么Markdown是一种极简的标记语言，可以轻易的将文本转化为HTML。语法非常容易学习，简单到每个人都可以在5分钟之内学会。Markdown之所以越来越流行，不是因为它复杂，而是因为他足够简单。Markdown优点纯文本编写，兼容性很强，可以使用所有文本编辑器打开让写作者专注与文字而不是排版格式转换方便，可以将MarkDown文本轻易转换为HTML，电子书等与word对比使用word写文档需要浪费大量时间在word本身上，特别是那80%我们用不到的功能浪费时间在排版上，需要花费大量时间用在调整粗体或者斜体，黑体还是宋体上Markdown语法标题标题有两种方式：Setext方式和Atx方式12345Setext方式，三个或更多的=或者-大标题===小标题---大标题小标题1234567Atx方式，在标题前面加上#号，总共分为6个等级，#号越多，标题字号越小# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题一级标题二级标题三级标题四级标题五级标题六级标题列表无序列表，只需要在文字前面加上-,+或者×123- 文本1- 文本2- 文本3文本1文本2文本3有序列表，只需要在文字前面加上1.， 2.， 3.等。前面序号只是代表语法标记，真正序号与我们所写的内容并无实际关系，例如：我将文本3的序号标记为4，但效果仍然显示为3。1231. 文本12. 文本24. 文本3文本1文本2文本3嵌套列表，-，+，*可循环使用，但符号之后的空格不能少，符号之前的空格也不能少1234567- 一级列表 + 二级列表 + 二级列表 × 三级列表 - 四级列表- 一级列表​```language一级列表二级列表二级列表三级列表四级列表一级列表链接和图片链接，插入链接只需要使用[显示文本](连接地址 Tooltips)这样的语法实现，Tooltips可以省略，Tooltips表示鼠标悬浮时候的文本提示1[百度](http://www.baidu.com)百度图片，插入图片只需要使用![](图片链接 Tooptips)这样的语法实现，Tooltips可以省略1![](http://ww4.sinaimg.cn/bmiddle/aa397b7fjw1dzplsgpdw5j.jpg "埃菲尔铁塔")自动链接，直接显示链接网址，点击可以跳转1&lt;http://www.sina.com&gt;http://www.sina.com引用在我们写作的时候经常需要引用他人的文字，这时候就需要用到引用这个格式。这时候我们就需要在文字前面加上&gt;来表示引用内容。可以嵌套使用表示多级引用1&gt; 以眼看世界，即使站的最高，世界还是很小；以心看世界，即使身处局限，世界依然很大以眼看世界，即使站的最高，世界还是很小；以心看世界，即使身处局限，世界依然很大强调被**包含的表示斜体，被****包含的表示粗体，其中的*也可以换成_12345**一个人来到田纳西**__毫无疑问__*我做的馅饼是全天下*_最好吃的_一个人来到田纳西毫无疑问我做的馅饼是全天下最好吃的分隔符***表示page break；---表示section break；___表示sentence break；123456789page break***section break---sentence break___page breaksection breaksentence break代码使用`&#123;codeblock&#125;``` `表示代码块，language表示代码块中代码的语言类型，在&#123;codeblock&#125;中插入要写的代码123456```java ```java public static void main(String[] args)&#123; &#125; ``` `123public static void main(String[] args)&#123;&#125;特殊表示123~~删除元素~~++下划线++==高亮显示==删除元素++下划线++==高亮显示==]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
