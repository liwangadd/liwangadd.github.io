<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java开发面试问题总结]]></title>
    <url>%2Fposts%2F15e10432%2F</url>
    <content type="text"><![CDATA[集合ArrayList与LinkedList的异同是否保证线程安全：两个集合都是不同步的，不是线程安全的底层数据结构：ArrayList底层使用的是Object数组；LinkedList底层使用的是双向链表数据结构（Jdk1.6之前为循环链表，Jdk1.7取消了循环）插入和删除是否受元素为止的影响：ArrayList采用数组存储，所以是受元素位置影响的；LinkedList采用链表存储，所以不受元素位置影响是否支持快速随机访问：LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index) 方法)。内存占用：ArrayList的空间浪费主要体现在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（需要存放直接后继和前驱）ArrayList继承了RandomAccess接口，这是一个标记接口，没有定义任何方法，其作用是用于标识这个类具有随机访问功能。例如binarySearch()方法中会先判断传入的list是否是RandomAccess实例，如果是调用indexBinarySearch()方法，如果不是调用iteratorBinarySearch()方法ArrayList源码分析初始化：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10扩容。添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。序列化。ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用。该数组成员变量使用transient修饰，并自己实现了writeObject()和readObject()方法控制只序列化数组中有元素填充的那部分内容。HashMap的底层实现Jdk1.8之前底层是数组+链表实现的，HashMap通过key的hashcode经过扰动函数（采用高16位于低16位进行异或运算，用于减少hash碰撞）处理过后得到hash值，然后通过(n-1)&amp;hash（优化后的取模运算）判断当前元素存放的位置，如果当前位置存在元素的话，判断该元素与要存入元素的hash值和key是否相同，相同的话直接覆盖，否则通过拉链法解决冲突（jdk1.8之前使用头插法，之后使用尾插法）。Jdk1.8之后，当链表长度大于阀值（默认位8）时，将链表转化为红黑树，用于优化搜索时间。Jdk1.8中对hashmap扩容不是重新计算所有元素在数组的位置，因为采用的是2次幂的拓展，所以元素的位置要么是在原位置，要么是在原位置在移动2次幂的位置。所以在移动的时候没有重新计算hash值，而是通过判断最后一个bit是1还是0，如果是0说明索引没变，是1的话索引变为“原索引+oldCap”HashMap多线程导致死循环在多线程下，进行 put 操作会导致 HashMap 死循环，原因在于 HashMap 的扩容 resize()方法。由于扩容是新建一个数组，复制原数据到数组。由于数组下标挂有链表，所以需要复制链表，但是多线程操作有可能导致环形链表。复制链表过程如下:以下模拟2个线程同时扩容。假设，当前 HashMap 的空间为2（临界值为1），hashcode 分别为 0 和 1，在散列地址 0 处有元素 A 和 B，这时候要添加元素 C，C 经过 hash 运算，得到散列地址为 1，这时候由于超过了临界值，空间不够，需要调用 resize 方法进行扩容，那么在多线程条件下，会出现条件竞争，模拟过程如下：线程一：读取到当前的 HashMap 情况，在准备扩容时，线程二介入线程二：读取 HashMap，进行扩容线程一：继续执行这个过程为，先将 A 复制到新的 hash 表中，然后接着复制 B 到链头（A 的前边：B.next=A），本来 B.next=null，到此也就结束了（跟线程二一样的过程），但是，由于线程二扩容的原因，将 B.next=A，所以，这里继续复制A，让 A.next=B，由此，环形链表出现：B.next=A; A.next=B在JDK1.8中已经解决了死循环的问题HashMap和HashTable的区别是否线程安全：HashMap不是线程安全的，HashTable是线程安全的效率：由于HashTable的每个方法都是用synchronized关键字修饰，所有方法都必须同步调用，所以效率要慢一些是否支持key为null的情况：HashMap中，null可以作为键，这样的键只能有一个，可以有一个或多个值为null。在HashTable中put进的键值只要有一个为null，直接抛出NullPointerException初始容量大小和每次扩容大小的不同：①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小（使用2的幂次方是一位进行模运算时可以使用与运算提高速度(n-1) &amp; hash）ConcurrentHashMap线程安全的具体实现方式/底层具体实现JDK1.7首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。Segment 继承自 ReentrantLock，所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。因此并发度等于Segment的数量，默认为16。JDK1.8 中ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized(CAS失败后采用加锁的方式)来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生冲突。ConcurrenthashMap和HashTable的区别底层数据结构：JDK1.7的ConcurrentHashMap底层采用分段数组+链表实现，JDK1.8采用数组+链表/红黑树；HashTable一直使用数组+链表的形式实现线程安全的方式：① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。Java基础面向过程和面向对象的区别面向过程：性能比面向对象高，没有面向对象易维护、易复用、易拓展面向对象：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护，性能比面向过程低自动装箱与拆箱装箱：将基本类型（boolean、byte、char、short、int、float、long、double）用它们对应的引用类型包装起来拆箱：将包装类型转换为基本数据类型接口和抽象类的区别接口的方法默认是 public，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），抽象类可以有非抽象的方法接口中的实例变量默认是 final 和static类型的，而抽象类中则不一定一个类可以实现多个接口，但最多只能实现一个抽象类接口不能用 new 实例化，但可以声明，但是必须引用一个实现该接口的对象 从设计层面来说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。成员变量和局部变量的区别从语法形式上，看成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；成员变量可以被 public,private,static 等修饰符所修饰，而局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰；从变量在内存中的存储方式来看，成员变量是对象的一部分，而对象存在于堆，局部变量存在于栈从变量在内存中的生存时间上看，成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。成员变量如果没有被赋初值，则会自动以类型的默认值而赋值（一种情况例外被 final 修饰的成员变量也必须显示地赋值）；而局部变量则不会自动赋值String Pool字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程中将字符串添加到 String Pool 中。当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。String s1 = &quot;aaa&quot;，会自动将字符串字面量放入到String Pool中new String(&quot;aaa&quot;)，会创建两个字符串对象（String Pool中没有的情况下）:”aaa”属于字面量，编译期会在String Pool中创建一个字符串对象，并指向该字符串字面量；使用new方式会在堆中创建一个字符串对象Java中的异常在Java中Throwable是所有异常类的祖先，有两个重要的子类：Exception（程序本身可以处理的异常）和Error（程序无法处理的异常）。Exception又分为检查异常和非受检查异常，前者可以在编译期检查到，需要在代码中对异常进行捕获或者向外层抛出；后者需要在运行时才能发现，抛出后将导致程序崩溃(编译期不要求对该类异常进行捕获)。BIO、NIO和AIO的区别BIO同步阻塞，面向流，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不作任何我事情就会造成不必要的线程开销BIO适用于连接数目比较小且固定的架构NIO同步非阻塞，面向缓冲区，服务器实现为一个请求一个线程，即客户端连接的请求都会注册到多路复用器上，多路复用器轮询到连接有IO请求时才启动一个线程进行处理。适用于连接数目多且连接时间短的架构AIO异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的IO请求都是由OS先完成在通知服务器应用去启动线程处理适用于连接数目多且比较长的架构迭代器的fail-fast机制在构造迭代器时，通过expectedModCount记录了当前的修改次数，在调用next和remove方法时会调用checkForComodification方法，检查迭代器中的记录和集合中的modCount变量（该变量在调用对集合进行修改的函数时会进行自增操作，例如：add, remove, clear, ensureCapacity）是否相等，如果不相等说明在迭代器遍历过程中有其他线程对集合做出了修改，会抛出ConcurrentModificationException异常。迭代器的快速失败行为不能得到保证（尽最大努力抛出），如果存在非同步的并发修改时，有可能不会抛出异常泛型优点自动执行类型检查，可以避免运行期抛出ClassCastException异常自动执行类型推断，减少编写强制类型转换的代码泛型的实现原理Java泛型是在编译器这个层次实现的，编译时会擦除类型参数，在生成的Java字节码中是不包含泛型中的类型信息的，这个过程称为类型擦除。在字节码中类型的真正类型被称为原始类型，如果在使用泛型是指定了限定类型，则原始类型为限定类型，否则为Object。Object有哪些方法1234567891011public final Class&lt;T&gt; getClass();public int hashCode();public boolean equals(Object obj); //自反、对称、传递、一致protected Object clone() throw CloneNotSupportedException;public String toString();public final void notify();public final void notifyAll();public final void wait(long timeout) throws InterruptedException;public final void wait(long timeout, int nanos) throws InterruptedException;public final void wait() throwsInterruptedException;protected void finalize() throwsThrowable;反射机制在程序运行时，对于任意一个类都能够依赖字节码文件获取到他的所有属性和方法（属性是什么类型的，方法的返回值是什么类型，有哪些参数），更重要的是可以动态生成对象，并调用他的方法和属性。在具体编程上，就是通过字符串的形式，比如用类的全限定名获取想要的Class的字节码对象，然后同样以字符串形式执行方法名、属性名，最后这个类的各个组成部分都可以拆解为一个对象去操作。这样减轻了JVM的内存负担，使得操作更加灵活。特别是对于一些框架，比如Spring，他提供的框架是一个黑盒，已经打包成jar包，开发者是不能任意修改的，它让用户自己去定义用户需要的类，然后他通过XML或者注解的方式获取到配置的类名，然后使用注解去动态创建这些类。Java多态的实现方式方法表是实现动态调用的核心。为了优化对象调用方法的速度，方法区的类型信息会增加一个指针，该指针指向记录该类方法的方法表，方法表中的每一个项都是对应方法的指针。这些方法中包括从父类继承的所有方法以及自身重写（override）的方法。JVM 的方法调用指令有四个，分别是 invokestatic，invokespecial，invokesvirtual 和 invokeinterface。前两个是静态绑定，后两个是动态绑定的。类调用 (invokestatic) 是在编译时就已经确定好具体调用方法的情况。实例调用 (invokevirtual)则是在调用的时候才确定具体的调用方法，这就是动态绑定，多态要解决的核心问题继承：在执行某个方法时，在方法区中找到该类的方法表，再确认该方法在方法表中的偏移量，找到该方法后如果被重写则直接调用，否则认为没有重写父类该方法，这时会按照继承关系搜索父类的方法表中该偏移量对应的方法。接口：Java 允许一个类实现多个接口，从某种意义上来说相当于多继承，这样同一个接口的的方法在不同类方法表中的位置就可能不一样了。所以不能通过偏移量的方法，而是通过搜索完整的方法表。Java注解的实现方式类、字段、方法，在class结构中都有自己特定的表结构，而且各自都有自己的属性。于注解，作用的范围也可以不同，可以作用在类上，也可以作用在字段或方法上。编译器会对应将注解信息存放到类、字段、方法自己的属性(attributes)上当JVM加载class文件字节码时，就会根据注解的位置，将RuntimeVisibleAnnotations属性值保存到Class对象的对应的属性表中，就可以通过java的反射机制获得注解对象，进而拿到注解的属性值。注解被编译后的本质就是一个继承Annotation接口的接口，当通过反射方式获取注解对象时，JDK会通过动态代理生成一个实现了相应接口的对象，并将RuntimeVisibleAnnotations属性值设置进此对象中，通过它的value()方法就可以获取到注解值。JVM运行时区域有哪些，分别存什么程序计数器，用于保存当前线程所执行的字节码的行号指示器。在JVM的概念模型中，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储虚拟机栈，保存局部变量表、操作数栈等本地方法栈，为虚拟机使用到的Native方法服务，本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。堆，存放对象实例方法区，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。运行时常量池也在这个区域内，用于存放编译期生成的各种字面量，符号引用和翻译出来的直接引用。JDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。直接内存，Java NIO中的缓冲区使用的内存，不是虚拟机运行时数据区的一部分什么时候进行GCMinor GC触发条件Eden区空间不足时触发Full GC触发条件调用System.gc时，系统建议执行Full GC，但是不必然执行老年代空间不足方法区空间不足通过Minor GC后进入老年代的平均大小大于老年代的可用内存由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小GC Roots有哪些虚拟机栈(栈帧中的本地变量表)中引用的对象方法区域中的类静态属性引用的对象方法区域中常量引用的对象本地方法栈中JNI(Native方法)中引用的对象存在哪几种垃圾收集器Serial收集器（Serial Old），只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。ParNew收集器，ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。Parallel Scavenge收集器（Parallel Old），重点关注吞吐量CMS收集器初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。并发清除：不需要停顿。由于 CMS 收集器不是独占式的回收器，在 CMS 回收过程中，应用程序仍然在不停地工作。在应用程序工作过程中，又会不断地产生垃圾。这些新生成的垃圾在当前 CMS 回收过程中是无法清除的。同时，因为应用程序没有中断，所以在 CMS 回收过程中，还应该确保应用程序有足够的内存可用。因此，CMS 收集器不会等待堆内存饱和时才进行垃圾回收，而是当前堆内存使用率达到某一阈值时，便开始进行回收，以确保应用程序在 CMS 工作过程中依然有足够的空间支持应用程序运行。这个回收阈值可以使用-XX:CMSInitiatingOccupancyFraction 来指定，默认是 68。即当老年代的空间使用率达到 68%时，会执行一次 CMS 回收。如果应用程序的内存使用率增长很快，在 CMS 的执行过程中，已经出现了内存不足的情况，此时，CMS 回收将会失败，JVM 将启动老年代串行收集器进行垃圾回收。如果这样，应用程序将完全中断，直到垃圾收集完成，这时，应用程序的停顿时间可能很长。标记-清除算法将会造成大量内存碎片，离散的可用空间无法分配较大的对象。在这种情况下，即使堆内存仍然有较大的剩余空间，也可能会被迫进行一次垃圾回收，以换取一块可用的连续内存，这种现象对系统性能是相当不利的，为了解决这个问题，CMS 收集器还提供了几个用于内存压缩整理的算法。G1收集器G1收集器和之前垃圾收集器拥有完全不同的内存结构，虽然从逻辑上也存在年轻代、老年代，但是物理空间上不再连续而是散列在内存中的一个个regions。内存空间分割成很多个相互独立的空间，被称作regions。通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。G1中提供了三种垃圾回收模式，young gc、mixed gc和full gc，在不同条件下被触发。young gc发生在年轻代的GC算法，一般对象（除了巨型对象）都是在eden region中分配内存，当所有eden region被耗尽无法申请内存时，就会触发一次young gc，这种触发机制和之前的young gc差不多，执行完一次young gc，活跃对象会被拷贝到survivor region或者晋升到old region中，空闲的region会被放入空闲列表中，等待下次被使用。mixed gc当越来越多的对象晋升到老年代old region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即mixed gc，该算法并不是一个old gc，除了回收整个young region，还会回收一部分的old region，这里需要注意：是一部分老年代，而不是全部老年代，可以选择哪些old region进行收集，从而可以对垃圾回收的耗时时间进行控制。在mixed gc中有一个阀值参数：-XX:InitiatingHeapOccupancyPercent，当老年代大小占整个堆大小百分比达到该阀值时会触发一个mixed gc。如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：初始标记并发标记最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。full gc如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间。与 CMS 收集器相比，G1 收集器是基于标记-压缩算法的。因此，它不会产生空间碎片，也没有必要在收集完成后，进行一次独占式的碎片整理工作。G1 收集器还可以进行非常精确的停顿控制。OOM排查通过jmap -dump查看出现OOM时的堆转储快照，查看是否存在代码泄露。如果没有看看是否可以增加堆内存的大小或者查看代码中有没有对象生命周期过长，进行修改。如果是因为虚拟机栈或者本地方法栈导致的OOM，可以尝试通过调整-Xss参数减小分配给每个栈帧的内存大小如果是方法区导致的OOM，可能是运行过程中产生了大量的动态代理类（CGLIB or Java动态代理）或者jsp页面太大，可以通过-XX:PermSize参数调整永久代的大小类加载过程java类加载需要经历一下7个过程：加载通过一个类的全限定名获取该类的二进制流。将该二进制流中的静态存储结构转化为方法区运行时数据结构。在内存中生成该类的Class对象，作为该类的数据访问入口。验证验证的目的是为了确保Class文件的字节流中的信息不回危害到虚拟机.文件格式验证：验证字节流是否符合Class文件的规范，如主次版本号是否在当前虚拟机范围内，常量池中的常量是否有不被支持的类型.元数据验证:对字节码描述的信息进行语义分析，如这个类是否有父类，是否集成了不被继承的类等。字节码验证：是整个验证过程中最复杂的一个阶段，通过验证数据流和控制流的分析，确定程序语义是否正确，主要针对方法体的验证。如：方法中的类型转换是否正确，跳转指令是否正确等。符号引用验证：这个动作在后面的解析过程中发生，主要是为了确保解析动作能正确执行。准备准备阶段是为类的静态变量分配内存并将其初始化为默认值，这些内存都将在方法区中进行分配。准备阶段不分配类中的实例变量的内存，实例变量将会在对象实例化时随着对象一起分配在Java堆中。解析该阶段主要完成符号引用到直接引用的转换动作。解析动作并不一定在初始化动作完成之前，也有可能在初始化之后。初始化初始化时类加载的最后一步，前面的类加载过程，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。如何判断一个类是无用的类该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。加载该类的 ClassLoader 已经被回收。该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。类的加载时机使用new关键字实例化对象，读取或设置一个类的静态字段(被final修饰、已在编译期把结果放入常量池的静态字段除外)以及调用一个类的静态方法的时候反射（如 Class.forName(“com.shengsiyuan.Test”)）调用时，如果类没有经过初始化，需先进行初始化操作初始化某个类的子类，则其父类也会被初始化虚拟机启动时，用户需要制定一个要执行的主类(包含main()方法的那个类)，虚拟机会先初始化这个主类使用动态语言支持时，如果动态语言需要调用类的静态方法或者对静态变量进行操作，需要初始化对应的类双亲委派模型该模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。这里类加载器之间的父子关系一般通过组合（Composition）关系来实现，而不是通过继承（Inheritance）的关系实现。一个类加载器首先将类加载请求传送到父类加载器，只有当父类加载器无法完成类加载请求时才尝试加载。使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。例如 java.lang.Object 存放在 rt.jar 中，如果编写另外一个 java.lang.Object 的类并放到 ClassPath 中，程序可以编译通过。由于双亲委派模型的存在，所以在 rt.jar 中的 Object 比在 ClassPath 中的 Object 优先级更高，这是因为 rt.jar 中的 Object 使用的是启动类加载器，而 ClassPath 中的 Object 使用的是应用程序类加载器。rt.jar 中的 Object 优先级更高，那么程序中所有的 Object 都是这个 Object。对象初始化过程首先查看类的符号引用，看是否已经在常量池中，在说明已经加载过了，不在的话需要进行类的加载，验证，准备，解析，初始化的过程。上诉过程执行完毕以后，又将 Student 加载进内存，也就是存储 Student.class的字段信息和方法信息，存储到方法区中字段信息：存放类中声明的每一个字段的信息，包括字段的名、类型、修饰符。方法信息：类中声明的每一个方法的信息，包括方法名、返回值类型、参数类型、修饰符、异常、方法的字节码。然后在自己的线程私有的虚拟机栈中，存储该引用，然后在每个线程的私有空间里面去分配空间存储 new Student(),如果空间不足在 eden 区域进行分配空间对类中的成员变量进行默认初始化对类中的成员变量进行显示初始化有构造代码块就先执行构造代码块，如果没有，则省略(此步上文未体现)执行构造方法，通过构造方法对对对象数据进行初始化堆内存中的数据初始化完毕，把内存值复制给 s 变量JVM内存模型主内存与工作内存Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存的副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递需要在主内存中完成。内存间交互操作一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，JMM定义了一下八种操作来完成：- lock（锁定）：作用域主内存的变量，它把一个变量标识为一条线程独占的状态；- unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定；- read（读取）：作用于主内存变量，它变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用- load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中；- use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。- assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。- store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。- write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。并发ThreadLocal的原理，是如何解决内存泄露的风险的如果某个类不是线程安全的，并且还要在多线程下共享就需要使用到ThreaLocal类，ThreadLocal保证了每个线程获取到的都是对象的一个本地线程副本。ThreadLocal只是一个包装类，本身并不持有数据，每个Thread类内部都有一个threadLocals对象，该对象的结构类似于HashMap，Key是ThreadLocal类型，Value为Object类型，该对象内部真正保存了线程的本地变量副本，对ThreadLocal进行的操作都会委托给该对象进行处理。threadLocals是ThreadLocalMap类型，继承自WeakReference类，所以当创建ThreadLocal对象的线程被销毁之后，下一次GC就会将其进行回收，然后以后调用get的时候会寻找key为null的键值对，将其对应的value删除掉。但是依然存在无法及时清理的问题。所以当我们使用完ThreadLocal之后最好手动remove一下，这样当容量不足时已启动启发式的垃圾清理，代码会自动回收value值为null的slot。线程的三种写法继承自Thread类，重写run方法（单继承，无法使用线程池，继承Thread无法复用、创建成本高）继承自Runnable接口，重写run方法（无法获取返回值和捕获线程中抛出的异常）继承自Callable接口，重写call方法Java中线程同步的方式同步方法，使用synchronized关键字修饰方法同步代码块，使用synchronized关键字修饰的代码块使用volatile修饰的变量实现线程同步使用ReentranLock实现线程同步使用ThreadLocal管理变量，通过变量的线程副本实现同步通过阻塞队列实现同步通过原子变量实现同步线程池创建线程池时每个参数的作用corePoolSize：核心池的大小，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务。maximumPoolSize：线程池最大线程数，它表示在线程池中最多能创建多少个线程；keepAliveTime：表示超出corePoolSize数量的线程在空闲多长时间后终止unit：参数keepAliveTime的时间单位workQueue：一个阻塞队列，用来存储等待执行的任务threadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程做些更有意义的事情，比如设置daemon和优先级等等handler：表示当拒绝处理任务时的策略，线程创建规则线程数量小于 corePoolSize，直接创建新线程处理新的任务线程数量大于等于 corePoolSize，workQueue 未满，则缓存新任务线程数量大于等于 corePoolSize，但小于 maximumPoolSize，且 workQueue 已满。则创建新线程处理新任务线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务线程池大小估计计算密集型：CPU核心数+1，IO密集型：CUP核心数 * 2 + 1synchronized关键字的原理synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1（持有锁的线程再次获取时继续加1，从而实现可重入特性）。相应的在执行 monitorexit 指令后，将锁计数器减1，如果计数器变为0表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。synchronized 修饰的方法使用ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法。调用方法时，会首先检查该标志是否被设置，如果设置了，就会执行上述的monitor操作流程synchronized的优化Java的线程模型是通过将其映射到操作系统原生线程上的，所以在进行线程切换时需要有用户态切换到内核态，需要较长时间，时间效率较低。所以JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。自旋锁与自适应自旋，如果有多个线程同时执行，可以让后面请求锁的线程执行一段”盲等”的循环操作，不放弃处理器时间，看持有锁的线程是否很快就会释放锁。但是如果锁被占用很长时间，自旋的线程就会白白消耗处理器资源，反而会带来性能伤的浪费，默认的自旋次数时10。在JDK1.6中，引入了适应性自旋，意味着自旋的时间不再固定，可以根据历史自旋的统计结果自动调整自旋次数锁消除，虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的硕进行消除。是否消除主要的判断依据来源于逃逸分析，如果判断在一段代码中，堆伤所有数据都不会逃逸出去从而被其它线程访问到，就可以把它们当做栈上数据对待，认为它们是线程私有的锁粗化，如果一系列的连续操作都对同一个对象反复加锁和解锁（例如加锁操作出现在循环体中），虚拟机会把加锁同步的范围拓展到整个操作序列的外部轻量级锁，在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为”01”状态），虚拟机首先在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝。然后虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位转变为”00”，表示该对象处于轻量级锁定状态。如果更新操作失败，虚拟机首先检查对象的Mark Word是否指向当前线程的栈帧，如果是说明当前线程已经拥有了这个对象的锁，直接进入同步块继续执行，否则说明这个锁对象已经被其它线程抢占了。解锁过程也是通过CAS操作实现的，如果对象的Mark Word仍然指向当前线程的锁记录，就是用CAS操作吧对象当前的Mark Word和线程中复制的Mark Word替换回来，如果替换成功，整个同步过程完成。否则，说明有其他线程尝试过获取该锁，就要在释放锁的过程中，唤醒被挂起的线程偏向锁，当锁对象第一次被线程获取时，虚拟机将对象头中的标志位置为”01”，同时使用CAS操作吧获取到这个锁的线程的ID记录在对象的Mark Word中，如果cas成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，不需要进行同步操作。当有另一个线程尝试获取该锁时，偏向模式失败。AQS原理在AQS中有一个int类型的state变量，若state变量为没有锁定状态（由子类自己确定语义），则将当前请求资源的线程设置为有效的工作线程，并将state设置为锁定状态；否则将请求资源的线程加入CLH等待队列中，并使用LockSupport.park()函数将线程置为阻塞状态，等待当资源可用时被唤醒。CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。AQS使用了模板方法的设计模式，子类继承AbstractQueuedSynchronized时只需要选择性重写以下方法12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。CyclicBarrier和CountDownLatch的区别CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用CountDownLatch: 一个或者多个线程，等待其他多个线程完成某件事情之后才能执行CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行。volatitle关键字当一个变量被声明成volatile后，就具备了一下两种特性。内存可见性，即当一条线程修改了这个变量的值，新值对于其他线程来说是立即得知的。由于只能保证可见性，在不符合以下两条规则的运算场景中，仍要通过加锁来保证原子性：运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值变量不需要与其他状态变量共同参与不变约束禁止指令重排序优化，普通的变量只能保证在该方法的执行过程中所有依赖赋值结果的地方都能得到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。如何尽量减少上下文切换无锁编程：用多线程处理数据时，尽量避免使用锁，防止多线程竞争锁的时候引起的上下文切换CAS算法：使用硬件同步原语，不需要加锁根据任务类型选择线程数量：cpu密集型不需要线程数量过多（与处理器内核保持一致），io密集型可以适量加大线程数量使用协程：在单线程里面实现多任务的调度，并在单线程里维持多个任务之间的切换操作系统进程、线程、程序线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。(共享：堆，静态变量，文件描述符；独占：栈，寄存器值，线程id)程序是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码进程是程序的一次执行过程，是资源分配的基本单位线程有哪些状态新建(new)：新创建了一个线程对象就绪（runnable）：线程已经获得了除CPU之外的所有资源，等待被线程调度选中，获取CPU的使用权运行（running）：线程获取到了CPU资源，正在运行中阻塞（block）：线程因为需要等待除CPU之外的其他资源满足后才能继续运行，所以主动放弃了CPU的使用权终止（terminated）：线程结束生命周期如何创建进程，fork函数的返回值system函数，运行义字符传参数的形式传递给它的命令，他会在一个进程的内部启动另一个进程，并等待命令的完成exec系列函数，可以把当前进程替换为一个新进程，新进程的PID、PPID和nice都和原来的一样，只是用另一个新进程替换了当前进程的征文、数据、堆和栈fork函数，返回的是新子进程的PID，子进程从fork调用处执行，在子进程中fork调用返回的是0。fork函数得到的子进程从父进程继承了整个进程空间。fork系统调用之后，父子进程交替执行，如果父进程先退出，子进程还没退出–孤儿进程，子进程的父进程将变为init进程；如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程僵尸进程和孤儿进程僵尸进程放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，直到父进程通过wait/waitpid才释放。如果父进程接收到系统发出的SIGCHLD信号但没有调用wait/waitpid或者显式忽略该信号，将一直保持僵尸状态，如果父进程结束，init进程会接手并清理这个子进程，如果父进程不会结束，子进程将一直保持僵尸状态。如果存在大量的僵尸进程，将因为没有可用的进程号而导致不能产生新的进程一个父进程退出，而它的子进程还在运行，这些子进程将成为孤儿进程，孤儿进程将被init进程接管，由其完成对他们的状态收集工作COW（copy-on-write）传统的fork调用直接把所有的资源复制给新创建的进程，但是子进程可能并不需要这些资源导致效率低下。LInux采用了写时复制优化，可以退出甚至免除拷贝数据，创建子进程时并不复制整个父进程空间，而是让子进程共享父进程的数据，只有在需要写入的时候，数据才会被复制，从而使各个进程拥有自己的拷贝。也就是说，资源的复制只有在需要写入的时候才进行，在此之前，只是以只读方式共享。这种技术使地址空间上的页的拷贝被推迟到实际发生写入的时候init进程init进程由idle进程即0进程创建，Linux中的所有进程都是由init进程创建并运行的，是所有其他用户进程的祖先进程。首先Linux内核启动，然后在用户空间中启动init进程，再启动其他系统进程。在系统启动完成后，init进程将变为守护进程监视系统其他进程。init进程启动后，通过执行一些管理任务结束引导进程，该进程会检查文件系统，清理/tmp，启动各种服务以及为每个终端和虚拟控制台启动getty。init同样也会收集孤儿进程。Linux同步机制所有的futex同步操作都应该从用户空间开始，首先创建一个futex同步变量，也就是位于共享内存的一个整型计数器。当进程尝试持有锁或者要进入互斥区的时候，对futex执行”down”操作，即原子性的给futex同步变量减1。如果同步变量变为0，则没有竞争发生， 进程照常执行。如果同步变量是个负数，则意味着有竞争发生，需要调用futex系统调用的futex_wait操作休眠当前进程（进入内核态）。当进程释放锁或 者要离开互斥区的时候，对futex进行”up”操作，即原子性的给futex同步变量加1。如果同步变量由0变成1，则没有竞争发生，进程照常执行。如 果加之前同步变量是负数，则意味着有竞争发生，需要调用futex系统调用的futex_wake操作唤醒一个或者多个等待进程（进入内核态）。进程间通信方式管道/匿名管道(pipe)：提供面向字节流的通信，管道内部提供了同步机制，但有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系（具有亲缘关系的进程才能访问到管道文件）。命名管道:name_pipe克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信（不具有亲缘关系的进程可以根据管道的全路径名获取到管道文件）。管道的实质是一个内核环形缓冲队列（缓冲区的容量是有限制的），进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据如果所有指向管道写端的文件描述符都关闭了,而仍然有进程从管道的读端读数据,那么管道中剩余的数据都被读取后,再次read会返回0,就像读到文件末尾一样如果有指向管道写端的文件描述符没关闭，而持有管道写端的进程也没有向管道中写数据,这时有进程从管道读端读数据,那么管道中剩余的数据都被读取后,再次read会阻塞,直到管道中有数据可读了才读取数据并返回。如果所有指向管道读端的文件描述符都关闭了,这时有进程指向管道的写端write,那么该进程会收到信号SIGPIPE,通常会导致进程异常终止。如果有指向管道读端的文件描述符没关闭,而持有管道写端的进程也没有从管道中读数据,这时有进程向管道写端写数据,那么在管道被写满时再write会阻塞,直到管道中有空位置了才写入数据并返回。信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。消息队列：由消息组成的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。信号：信号可以在任何时候发给某一进程，而无需知道该进程的状态。如果该进程当前并未处于执行状态，则该信号就有内核保存起来，直到该进程回复执行并传递给它为止。共享内存：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。套接字：更为一般的进程间通信机制，可用于不同机器之间的进程间通信同步/非同步、阻塞/非阻塞同步指的是用户进程触发 IO 操作并等待或者轮询的去查看 IO 操作是否就绪，而异步是指用户进程触发 IO 操作以后便开始做自己的事情，而当 IO 操作已经完成的时候会得到 IO 完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据 IO 操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。同步阻塞 IO：在此种方式下，用户进程在发起一个 IO 操作以后，必须等待 IO 操作的完成，只有当真正完成了 IO 操作以后，用户进程才能运行。JAVA 传统的 IO 模型属于此种方式！同步非阻塞 IO:在此种方式下，用户进程发起一个 IO 操作以后边可返回做其它事情，但是用户进程需要时不时的询问 IO 操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的 CPU 资源浪费。其中目前 JAVA 的 NIO 就属于同步非阻塞 IO。异步阻塞 IO：此种方式下是指应用发起一个 IO 操作以后，不等待内核 IO 操作的完成，等内核完成 IO 操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问 IO 是否完成，那么为什么说是阻塞的呢？因为此时是通过 select 系统调用来完成的，而 select 函数本身的实现方式是阻塞的，而采用 select 函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！异步非阻塞 IO:在此种模式下，用户进程只需要发起一个 IO 操作然后立即返回，等 IO 操作真正的完成以后，应用程序会得到 IO 操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的 IO 读写操作，因为真正的 IO 读取或者写入操作已经由内核完成了。select、poll、epollI/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，pselect，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。select：调用后select函数会阻塞，同时将fd集合从用户态拷贝到内核态，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低poll：将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。基于链表存储，没有最大连接数的限制这两种方式都需要再返回后，通过遍历文件描述符来获取已经就绪的socket，因此随着监视的描述符数量的增长，效率会线性下降epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制)三者之间的区别支持一个进程所能打开的最大连接数| 方式 | 描述 || —— | ———————————————————— || select | 单个进程所能打开的最大连接数FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64），我们可以对其进行修改，然后重新编译内核，但是性能会受到影响 || poll | poll本质上和select没有区别，但是因为是基于链表存储的，没有最大连接数的限制 || epoll | 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右 |FD剧增后带来的IO效率问题| 方式 | 描述 || —— | ———————————————————— || select | 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题” || poll | 同上 || epoll | epoll内核中实现是根据每个fd上的callback函数实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题 |消息传递方式| 方式 | 描述 || —— | ———————————————— || select | 内核需要将消息传递到用户空间，都需要内核拷贝动作 || poll | 同上 || epoll | epoll通过内核和用户空间共享一块内存来实现的 |Linux根目录下个文件夹的作用/boot 默认存放Linux的启动文件和内核/bin 存放Linux的常用命令/sbin 存放系统管理员使用的管理程序/var 存放经常被修改的文件，包括各种日志、数据文件/etc 存放系统管理时用到的各种配置文件和子目录/dev 包含了Linux系统中使用的所有外部设备，实际上是这些外部设备的端口，访问这些外部设备和访问文件没有区别/mnt 临时将别的文件系统挂载到该目录下/root 如果是以超级用户的身份登录的，这个是超级用户的主目录/home 用户存放其他用户的主目录/usr 存放用户的应用程序和文件/lib 存放系统的动态链接库/tmp 存放不同程序执行时产生的临时文件，被自动被系统清理inode用于存储文件的元信息，包括：文件的字节数、文件拥有者的User ID、文件的Group ID、文件权限、文件的时间戳、链接数、文件的block的位置。每个文件都必须有一个inode，如果inode用光，硬盘上就无法创建新文件。每个inode有一个号码，操作系统用inode号码来标识不同的文件。inode包含了除文件名之外的所有信息，有目录维护文件名和inode号码之间的对应关系用户通过文件名，打开文件的过程：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。硬链接和软链接硬链接：多个文件名指向同一个inode号码，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。inode中有一项链接数，表明指向当前inode的文件名的数量。软链接：文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。nohup机制普通进程运行时默认会绑定TTY(虚拟终端)，关闭终端后系统会给上面所有进程发送TERM信号，这时普通进程也就退出了。Nohup的原理也很简单，终端关闭后会给此终端下的每一个进程发送TERM信号，而使用nohup运行的进程则会忽略这个信号，因此终端关闭后进程也不会退出。分段和分页的区别对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。地址空间的维度：分页是一维地址空间，分段是二维的。大小是否可以改变：页的大小不可变，段的大小可以动态改变。出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。产生死锁的条件和解决办法原因：系统资源不足、线程运行推进的顺序不对、资源分配不当4个条件：互斥、非抢占、持有并等待、循环等待解决方法：鸵鸟策略、死锁检测和死锁恢复、死锁预防（破坏4个条件中的一个）、死锁避免（银行家算法）局部性原理因为CPU寄存器与内存的速度不匹配问题，所以需要在他们之间加入L1、L2、L3三级缓存。内存里面的数据不能全部放到缓存中区，所以利用局部性原理存放一些最有希望被访问到的，时间局部性：类似于LRU算法，越是最近一段时间被访问的数据，之后就越可能再次访问空间局部性：越是与当前访问数据在空间地址上临近的，之后越可能再次访问伪共享问题CPU读取数据的时候先从CPU缓存上读取，如果不命中才访问内存。CPU缓存是以Cache Line为单位（一般为64字节）存放的，所以就出现一个问题，如果成员变量X和y都背缓存在同一个Cache LIne中，那么多线程虽然表面上访问的是不同变量，应该不存在并发访问问题，但在内核看来确实是并发访问的。解决方案有如下两种：JDK6：字节填充，一般对象头占8字节，实体占X字节，填充就占64-8-X字节JDK8：对于共享变量加上@Contended注解Linux 五种方式IO方式阻塞IO在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，直到数据准备好(等待接收到完整的数据包)，并且将数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。不能处理别的网络IO。非阻塞IO调用非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。IO多路复用I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用I/O操作函数。IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数获取数据就绪状态消息，并且其进程状态为阻塞，所以，把IO多路复用归为同步阻塞模式。I/O多路复用技术通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降底了系统的维护工作量，节省了系统资源信号驱动IO首先需要允许Socket进行信号驱动IO，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据(将数据从内核拷贝到用户空间，这个过程是阻塞的)。异步IO用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知(kernel会给用户进程发送一个signal或执行一个基于线程的回调函数来完成这次 IO 处理过程。IO两个阶段，进程都是非阻塞的。计算机网络七层协议 and 五层协议OSI体系结构：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层TCP/IP体系结构：应用层、传输层、网际层、网络接口层五层协议体系结构：应用层、传输层、网络层、数据链路层、物理层应用层：通过应用程序间的交互来实现特定网络应用。应用层协议定义的是应用程序进程间的通信和交互规则。对于不同的网络应用需要不同的应用层协议，如DNS协议、HTTP协议、SMTP协议等表示层：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。会话层：建立及管理会话。传输层：负责为两台主机进程之间的通信提供通用的数据传输服务网络层：为主机提供数据传输服务，负责在多个数据链路中选择合适的网间路由和交换节点，确保数据及时传送数据链路层：链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧（封装成帧，透明传输，差错校验CRC）物理层：实现相邻计算机结点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异TCP状态转移三次握手 and 四次挥手三次握手的过程如下：客户端A 发送SYN（seq = x）报文给服务器B，然后进入SYN_SENT状态；B收到SYN报文，回应一个SYN（seq = y） ACK （ack = x + 1）报文，进入SYN_RCVD状态；A收到SYN报文后，回应一个ACK（ACK = y + 1），进入ESTABLISHED状态；B收到ACK报文后，进入ESTABLISHED状态四次挥手的过程如下：客户端A上的某个进程，主动关闭连接，发送FIN（seq = u）报文给B，然后进入FIN_WAIT_1状态；B收到FIN报文，回应一个ACK （ACK = u + 1）报文，进入CLOSED_WAIT状态；A收到FIN报文，进入FIN_WAIT_2状态；B向A发送FIN（seq = v）报文，进入LAST_ACK状态；A收到FIN报文后，向B发送ACK(ACK = v + 1)报文，进入TIME_WAIT状态为什么采用三次握手如果A发出的第一个连接请求报文段并没有丢失，而是在某个网络节点长时间滞留了，以致延误到连接释放后的某个时间才到达B，B接收到该失效的连接请求报文段后，误认为是A发出的一次新的连接请求，就向A发出确认报文段，同意建立连接。如果不采用三次握手，只要B发出确认，新的连接就建立了，但是A并没有发出建立连接的请求，不会像B发送数据，而B却一直等待A发送数据，白白浪费了资源TIME_WAIT的作用，为什么要是2MSL保证A发送的最后一个ACK报文段能够到达B。A发送的报文段有可能丢失，因而使处于LAST-ACK状态的B不能正常关闭连接。B会超时重传这个FIN报文段，A就能在2MSL时间内收到这个重传的FIN报文段。接着A重传一次确认，重新启动2MSL计时器，最后A和B都能正常进入到CLOSED状态。如果A在TIME_WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，导致无法接收到B重传的FIN字段，因为也不会在发送一次确认报文段。这样B就无法按照正常步骤进入CLOSED状态经过2MLS之后，可以使A和B之间的传输报文在网络中消失，防止两台机器重建连接后接收到上次断开的连接传输的报文TIME_WAIT状态过多的原因和解决方案在高并发短连接(业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间)的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态，可以通过修改linux的配置文件，允许重用处于TIME_WAIT状态的socket1234net.ipv4.tcp_syncookies = 1 #表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1 #表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle = 1 #表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。net.ipv4.tcp_fin_timeout #修改系默认的 TIMEOUT 时间UDP和TCP的区别UDP 的主要特点UDP 是无连接的；UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；UDP 是面向报文的；UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）；UDP 支持一对一、一对多、多对一和多对多的交互通信；UDP 的首部开销小，只有8个字节，比TCP的20个字节的首部要短。TCP 的主要特点TCP 是面向连接的；每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）；TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。IP头部字段，TCP头部字段可靠传输应用数据被分割成 TCP 认为最适合发送的数据块。TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。TCP 的接收端会丢弃重复的数据。流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）拥塞控制： 当网络拥塞时，减少数据的发送。停止等待协议：它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段（每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些）。滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小（由此实现流量控制的功能），凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了拥塞控制拥塞控制是为了降低整个网络的拥塞程度，而流量控制是为了让接收方能来得及接收。TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。慢开始、拥塞避免发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 …注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。快重传、快恢复在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。HTTP常见状态码100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。301 Moved Permanently ：永久性重定向302 Found ：临时性重定向304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。400 Bad Request ：请求报文中存在语法错误。401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。403 Forbidden ：请求被拒绝。POST和GET的区别GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码；POST 参考支持标准字符集GET方法是安全的（不会修改服务器状态）；POST不是安全的GET方法是幂等性的；POST方法不是Restful协议restful是一套编写接口的协议，协议规定如何编写以及如何设置返回值、状态码等信息。对于同一个url，根据不同的method做不同的处理，比如：post 创建数据、get获取数据、put和patch修改数据、delete删除数据。url尽量使用名词，所以也被称为”面向资源编程”。面向资源符合HTTP的规范无状态性利用方法method属性描述对资源的操作，具有自解释性HTTP1.1和HTTP1.0的区别http1.0 需要 keep-alive 参数来告知服务器要建立一个长连接，而 http1.1 默认支持长连接HTTP 1.1 支持只发送 header 信息(不带任何 body 信息)，如果服务器认为客户端有权限请求服务器，则返回 100，否则返回 401。客户端如果接受到 100，才开始把请求 body 发送到服务器。这样当服务器返回 401 的时候，客户端就可以不用发送请求 body 了，节约了带宽。host 域 http1.0 没有 host 域，http1.1 才支持这个参数。带宽优化及网络连接的使用，HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range头域，允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。HTTP2.0和HTTP1.0的区别新的二进制格式（Binary Format），HTTP1.x 的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认 0和 1 的组合。基于这种考虑 HTTP2.0 的协议解析决定采用二进制格式，实现方便且健壮。多路复用（MultiPlexing），即连接共享，建立起一个连接请求后，可以在这个链接上一直发送，不要等待上一次发送完并且受到回复后才能发送下一个（http1.0 是这样），是可以同时发送多个请求，互相并不干扰。header 压缩，如上文中所言，对前面提到过 HTTP1.x 的 header 带有大量信息，而且每次都要重复发送，HTTP2.0 利用 HPACK 对消息头进行压缩传输，客服端和服务器维护一个动态链表（当一个头部没有出现的时候，就插入，已经出现了就用表中的索引值进行替代），将既避免了重复 header 的传输，又减小了需要传输的大小。服务端推送（server push），就是客户端请求 html 的时候，服务器顺带把此 html 需要的 css,js也一起发送给客服端，而不像 http1.0 中需要请求一次 html，然后再请求一次 css，然后再请求一次 js。Web 页面请求过程1. DHCP 配置主机信息假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。2. ARP 解析 MAC 地址主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。3. DNS 解析域名知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。4. HTTP 请求页面有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。设计模式常见设计模式单例模式、工厂模式、抽象工厂模式（抽象工厂模式创建的是对象家族，也就是很多对象而不是一个对象，并且这些对象是相关的，也就是说必须一起创建出来。而工厂方法模式只是用于创建一个对象）、装饰器模式、适配器模式、生成器模式、责任链模式、命令模式、观察者模式、代理模式、策略模式设计原则单一职责原则里氏替换原则：在使用基类的的地方可以任意使用其子类依赖倒置原则：高层模块不应该依赖底层模块，二者都该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象接口隔离原则：类间的依赖关系应该建立在最小的接口上，建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少迪米特法则：一个类对自己依赖的类知道的越少越好，高内聚、低耦合开放封闭原则：对拓展开放，对修改封闭代理模式的优点代理模式能够协调调用者和被调用者，在一定程度上降低了系 统的耦合度可以不修改代码，增加类的功能（增加远程调用，参数校验，权限校验等）数据库ACID原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。持久性（Durability）指已提交的事务修改数据会被持久保存。MySQL索引结构B+ Tree索引可以指定多个列作为索引列，多个索引列共同组成键。适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。Hash索引能以O(1)的时间复杂度进行查找，但是失去了有序性，所以无法用于排序和分组，也无法用于部分查找和范围查找全文索引MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。索引可以减少需要扫描的数据行数，避免进行排序和分组，避免了临时表的创建，将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）最左前缀匹配原则索引可以简单如一个列(a)，也可以复杂如多个列(a, b, c, d)，即联合索引。如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否存在（相等），遇到范围查询(&gt;、&lt;、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找。例子：如有索引(a, b, c, d)，查询条件a = 1 and b = 2 and c &gt; 3 and d = 4，则会在每个节点依次命中a、b、c，无法命中d。(很简单：索引命中只能是相等的情况，不能是范围匹配)慢查询优化思路使用Explain进行分析Explain 用来分析 SELECT 查询语句，比较重要的字段有：select_type : 查询类型，有简单查询、联合查询、子查询等key : 使用的索引rows : 扫描的行数优化数据访问减少请求的数据量只查询必要的列，避免使用SELECT * FROM只返回必要的行，使用LIMIT限制返回的数据使用索引减少扫描的行数重构查询方式切分大查询：一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。分解大连接查询：将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联分解之后，查询的数据粒度变细，可以提高缓存层的命中率，同时其它查询可能会重用缓存中的数据减少锁竞争MySQL存储引擎InnoDB是 MySQL 默认的事务型存储引擎，实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ），主索引是聚簇索引，在索引中保存了数据。内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。MyISAMB+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。提供了大量的特性，包括压缩表、空间数据索引等。不支持事务，不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。区别事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。外键：InnoDB 支持外键。备份：InnoDB 支持在线热备份。崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。其它特性：MyISAM 支持压缩表和空间数据索引。事务隔离级别读未提交：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读读已提交：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生可重复读(默认级别)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。串行化： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。分库分表垂直拆分可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；水平拆分常见的水平分表策略归纳起来，可以总结为随机分表和连续分表两种情况，例如，取模分表，时间维度分表，以及自定义 Hash 分表。连续分表可以快速定位到表进行高效查询，大多数情况下，可以有效避免跨表查询，但是可能存在数据热点问题。随机分表可能避免数据热点问题，但是拓展时需要进行数据迁移，需要进行跨表查询的概率增加。水平拆分之后，当需要同时操作切分后的多张表时，需要使用分布式事务解决一致性问题。单表查询变成了多表查询，需要在应用中对查询的数据进行聚合MySQL中锁的实现多版本控制多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号：创建版本号：指示创建一个数据行的快照时的系统版本号；删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。版本号在查询时的作用：把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。Record Lock锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。Gap Locks当我们用范围条件检索数据而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合范围条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”。InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。可以防止幻读数据库中的乐观锁和悲观锁乐观锁：具体实现是，表中有一个版本字段，第一次读的时候，获取到这个字段。处理完业务逻辑开始更新的时候，需要再次查看该字段的值是否和第一次的一样。如果一样更新，反之拒绝。之所以叫乐观，因为这个模式没有从数据库加锁，等到更新的时候再判断是否可以更新。悲观锁是数据库层面加锁，都会阻塞去等待锁。例如：select * from xxx from update，在select 语句后边加了 for update相当于加了排它锁(写锁)，加了写锁以后，其他的事务就不能对它修改了！需要等待当前事务修改完之后才可以修改.MySQL优化方式MySQL数据库优化的八种方式分布式Memcached和Redis的区别memcached只支持字符串类型，Redis支持string，list，set，zset，hash五种不同类型Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。Redis Cluster 实现了分布式的支持。Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。Redis持久化方式RDB持久化将某个时间点的所有数据都存放到硬盘上，可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。如果系统发生故障，将会丢失最后一次创建快照之后的数据。如果数据量很大，保存快照的时间会很长。AOF持久化将写命令添加到 AOF 文件（Append Only File）的末尾，对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，目前支持三种磁盘同步策略：always（每个命令都同步）、everysec（每秒同步一次）和no（由操作系统决定同步时间）。随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。Redis数据结构哈希表使用拉链法处理哈希冲突。内部使用两个哈希表，方便rehash操作。rehash 操作不是一次性完成，而是采用渐进方式，避免一次性执行过多的 rehash 操作给服务器带来过大的负担，在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。跳跃表zset使用跳跃表实现，跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。查找、删除、添加等操作的时间复杂度为$$O(log_n)$$Redis数据淘汰机制Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。redis提供了定期删除和惰性删除两种数据过期机制，定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。定期删除可能导致很多key到期后没有被删除，这样在客户端下次查询过期数据的时候会进行删除操作，这叫做惰性删除。如果两种过期方式都没有生效导致redis内存耗尽，就需要走内存淘汰机制。redis提供了如下6中淘汰策略：策略描述volatile-lru从已设置过期时间的数据集中挑选最近最少使用的数据淘汰volatile-ttl从已设置过期时间的数据集中挑选将要过期的数据淘汰volatile-random从已设置过期时间的数据集中任意选择数据淘汰allkeys-lru从所有数据集中挑选最近最少使用的数据淘汰allkeys-random从所有数据集中任意选择数据进行淘汰noeviction禁止驱逐数据Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。Redis主从当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。master会fork一个子进程生成RDB文件发送给slave，在生成RDB文件期间的写命令缓存在内存中。slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中。接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 resynchronization。使用哨兵机制实现主从的容灾处理Dubbo工作原理第一层：service层，接口层，给服务提供者和消费者来实现的第二层：config层，配置层，主要是对dubbo进行各种配置的第三层：proxy层，服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton第四层：registry层，服务注册层，负责服务的注册与发现第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控第七层：protocol层，远程调用层，封装rpc调用第八层：exchange层，信息交换层，封装请求响应模式，同步转异步第九层：transport层，网络传输层，抽象mina和netty为统一接口第十层：serialize层，数据序列化层。网络传输需要。因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。负载均衡策略random loadbalance。默认情况下，dubbo 是 random load balance 随机调用实现负载均衡，roundrobin loadbalance。可以对 provider 不同实例设置不同的权重，会按照权重来负载均衡，权重越大分配流量越高leastactive loadbalanceconsistanthash loadbalance。一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大集群容错策略failover cluster 模式。失败自动切换，自动重试其他机器，默认failfast cluster模式。一次调用失败就立即失败failsafe cluster 模式。出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。failback cluster 模式。失败了后台自动记录请求，然后定时重发forking cluster 模式。并行调用多个 provider，只要一个成功就立即返回。broadcacst cluster。逐个调用所有的 provider。分布式事务协议两阶段提交协议在两阶段提交协议中，引入了协调者的角色，负责决定这个分布式事务是提交还是回滚投票阶段协调者向所有参与者询问是否可以执行提交操作，并等待各参与者的响应。参与者执行的本地事务，将undo信息和redo信息写入日志。如果本地事务执行成功，将”同意”信息相应给协调者，否则将向协调者发送”终止”信息提交执行阶段当协调者获取到所有参与者的”同意”相应后，向所有参与者发送”正式提交”的请求。参与者获取到请求后正式完成操作，释放整个事务期间占用的资源，向协调者发送”完成”信息。协调者获取到所有协调者的完成信息后，标志分布式事务完成。若任意参与者的响应信息为”终止”信息或超时未收到参与者相应，协调者向所有参与者发送”回滚操作”请求，参与者利用之前的redo日志进行回滚操作，释放占用的资源，向协调者发送”回滚完成”的信息。协调者收到所有参与者的信息后，取消分布式事务。缺点：各参与者在事务执行完成前，需要一直占用本地资源；协调者需要给每个参与者执行超时时间，防止事务被阻塞；协调者存在单点故障问题；问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，无法知道事务是否已经被提交。三阶段提交协议CanCommit阶段协调者向参与者发送CanCommit请求，询问是否可以执行事务提交操作。参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈NoPreCommit阶段如所有相应为YES，协调者向参与者发送PreCommit请求，并进入Prepared阶段。参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。如果任意参与者响应为NO或响应超时，协调者向所有参与者发送abort请求，参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。DoCommit阶段协调接收到所有参与者发送的ACK响应，从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。参与者接收到doCommit请求之后，执行正式的事务提交并释放占用的资源，向协调者发送ACK相应。协调者接收到所有参与者的ack响应之后，完成事务。协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），协调者向所有参与者发送abort请求。参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并释放资源，向协调者发送ACK消息。协调者接收到参与者反馈的ACK消息之后，执行事务的中断。CAP原理一致性（Consistence）分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）强一致性当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。但是这种实现对性能影响较大。弱一致性系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别（比如秒级别）之后，可以让数据达到一致性状态。最终一致性弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。可用性（Availability）集群出现故障节点后，是否还能响应客户端的读写请求。（对数据更新具备高可用性）分区容忍性（Partition tolerance）保证数据可持久存储，在各种情况下都不会出现数据丢失的问题。为了实现数据的持久性，不但需要在写入的时候保证数据能够持久存储，还需要能够将数据备份一个或多个副本，存放在不同的物理设备上，防止某个存储设备发生故障时，数据不会丢失。Kafka顺序性、重复性、丢失性Kafka保证在同一个partition中的消息是有序的，所以生产者在向消息队列写消息时可以指定一个key，保证需要顺序消费的信息都发送到一个partition中一般消费者在消费kafka中的消息时，是不会丢失数据的。但是当kafka的offset是自动提交时，如果消费者没有处理完消息就出现了宕机的情况，恢复之后就消费不到offset前的数据了。可以设置offset成不自动提交，消费者处理完消息之后手动提交生产者将消息发送到kafka，如果leader还没来得及将消息同步到follower就出现了宕机，就会导致还没有同步的数据丢失。给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试Kafka消息的重复性没有办法得到保证，目前只提供了at-least-once和at-most-once语义，需要在消费端进行幂等性处理算法B树、B+树B树根节点的儿子树为[2, M]，除根结点之外的非叶子节点的儿子数为[M/2, M]，关键字个数为[M/2-1, M-1]，儿子结点数 = 关键字个数 + 1节点内的关键字是从左到右递增排序的所有叶子节点位于同一层B+树非叶子节点不保存关键字记录的指针，只进行数据索引叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到非叶子节点的子节点数=关键字数两者的区别B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树**快。红黑树红黑树是一种含有红黑节点并能够自平衡的二叉查找树，其具有如下性质：每个节点要么是黑色，要么是红色。根节点是黑色的，每个叶子结点（Nil）也是黑色的每个红色节点的两个子节点是黑色的任意一个节点到每个叶子结点的路径中黑色节点的个数是相等的红黑树通过左旋、右旋和变色三种方式实现自平衡：左旋：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。如图3。右旋：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。如图4。变色：结点的颜色由红变黑或由黑变红。执行插入操作时共分为如下几种情况：需要进行旋转的情况：插入节点的父节点为红色，且其叔叔节点不存在或者为黑色。二叉树删除结点找替代结点有3种情情景：情景1：若删除结点无子结点，直接删除情景2：若删除结点只有一个子结点，用子结点替换删除结点情景3：若删除结点有两个子结点，用后继结点（大于删除结点的最小结点）替换删除结点删除结点被替代后，在不考虑结点的键值的情况下，对于树来说，可以认为删除的是替代结点！所以情景2和3都可以转换为情景1，因此我们只需要考虑删除树末节点的情景。执行删除操作时共分为如下几种情况：堆堆是一颗完全二叉树堆中某个节点的值总是不大于或不小于其孩子节点的值堆中每个节点的子树都是堆一致性哈希一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1。将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。当需要访问服务器的时候，将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。如果某台服务器出现宕机，那么本应该落到该服务器的请求都会落到顺时针方向的下一个服务器，而其他服务器不会受到影响；如果增加一台服务器，则本应该落到上一台服务器的部分数据就会访问到该服务器一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜(即某台服务器承担了过多的数据请求)。引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点(一台服务器可以被映射到hash环上的多个位置)。同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，这样就解决了服务节点少时数据倾斜的问题WebSpring-AOPSpring AOP使用了动态代理的设计模式，所谓的动态代理就是说AOP框架不回去修改字节码，而是在内存中临时的为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。Spring AOP的动态代理主要有两种方式，JDK动态代理的CGLIB动态代理，JDK动态代理通过反射来接受被代理的类，并且要求被代理的类必须实现一个接口。如果目标类没有实现接口，会选择使用CGLIB来动态代理目标类，CGLIB是一个代码生成的类库，可以在运行时动态的生成某个类的子类，因此目标类需要能够被继承，并且代理的方法需要能够被重写。组成元素通知Advice：定义类需要处理的任务，以及何时完成–before/after/around/afterthrow等连接点joinPoint：程序代码里面可以插入切面的点切点PointCut：定义类需要通知的位置，会去连接点里面找对应的切面切面Aspect：组合Adivce和PointCut织入Weaving：编译时就把Advice织入到对应切点上，速度更快ApplicationContext和BeanFactory的区别BeanFactory不支持国际化功能，因为BeanFactory没有拓展Spring中MessageResource接口，不具有消息处理能力(i18n)ApplicationContext具有强大的事件机制，主要是通过ApplicationEvent和ApplicationListener这两个接口提供，当ApplicationContext发布一个事件时，所有拓展了ApplicationListener的Bean都将会接受到这个事件ApplicationContext拓展了ResourceLoader接口，从而可以用来加载多个ResourceBeanFactory采用的是延迟加载形式来注入Bean，即只有在使用到某个Bean时，才对该Bean进行加载实例化；ApplicationContext在容器启动时，一次性创建了所有的BeanSpring Bean生命周期实例化一个 Bean－－也就是我们常说的 new；按照 Spring 上下文对实例化的 Bean 进行配置－－也就是 IOC 注入；如果这个 Bean 已经实现了 BeanNameAware 接口，会调用它实现的 setBeanName(String)方法，此处传递的就是 Spring 配置文件中 Bean 的 id 值如果这个 Bean 已经实现了 BeanFactoryAware 接口，会调用它实现的 setBeanFactory(setBeanFactory(BeanFactory)传递的是 Spring 工厂自身（可以用这个方式来获取其它 Bean，只需在 Spring 配置文件中配置一个普通的 Bean 就可以）如果这个 Bean 已经实现了 ApplicationContextAware 接口，会调用 setApplicationContext(ApplicationContext)方法，传入 Spring 上下文（同样这个方式也可以实现步骤 4 的内容，但比 4 更好，因为 ApplicationContext 是 BeanFactory 的子接口，有更多的实现方法）；如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor 经常被用作是 Bean内容的更改，并且由于这个是在 Bean 初始化结束时调用那个的方法，也可以被应用于内存或缓存技术；如果 Bean 在 Spring 配置文件中配置了 init-method 属性会自动调用其配置的初始化方法。如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postProcessAfterInitialization(Object obj, String s)方法。注：以上工作完成以后就可以应用这个 Bean 了，那这个 Bean 是一个 Singleton 的，所以一般情况下我们调用同一个 id 的 Bean 会是在内容地址相同的实例，当然在 Spring配置文件中也可以配置非 Singleton，这里我们不做赘述。当 Bean 不再需要时，会经过清理阶段，如果 Bean 实现了 DisposableBean 这个接口，会调用那个其实现的 destroy()方法；最后，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调用其配置的销毁方法。Spring MVC执行流程用户发送请求至前端控制器 DispatcherServletDispatcherServlet 收到请求调用 HandlerMapping 处理器映射器。处理器映射器根据请求 url 找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给 DispatcherServlet。DispatcherServlet 通过 HandlerAdapter 处理器适配器调用处理器执行处理器(Controller，也叫后端控制器)。Controller 执行完成返回 ModelAndViewHandlerAdapter 将 controller 执行结果 ModelAndView 返回给 DispatcherServletDispatcherServlet 将 ModelAndView 传给 ViewReslover 视图解析器ViewReslover 解析后返回具体 ViewDispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中）。DispatcherServlet 响应用MyBatis架构读取XML文件或注解解析用户的Mapper配置，生成Config单例对象根据Config对象生成Mapper的动态代理类，代理Mapper接口的所有方法，每个接口方法对应一个SQL语句，根据SQL语句生成类似于PrepareStatement的对象（创建该对象的session是初始化MyBatis的时候使用MyBatis的时候使用SessionFactory创建的）SQL语句的输入值的设置，是根据Config去获取到实体的属性与数据库表字段的映射关系，然后set到prepareStatement，然后放到数据库引擎中执行，输出值根据Config构造的实体关系属性与数据库表字段的映射关系，通过反射机制设置到实体对象，然后返回。过滤器Filter和拦截器Interceptor的区别拦截器是基于Java反射机制的，过滤器是基于函数回调的拦截器是基于方法的，粒度更细（可以进行事务管理，日志记录，权限检查），过滤器依赖于servlet容器（一般进行更为通用的处理，比如编解码，非法输入拦截，跨域请求等）拦截器只能对Action请求起作用，过滤器可以对几乎所有请求HTTP、SIP器作用拦截器可以访问Action上下文，值栈里的对象，过滤器不能在Action的生命周期中，拦截器可以多次调用；过滤器只能在容器初始化时构建好Web安全性考虑参数校验：客户端做初始校验，服务端做最后检验用户权限拦截校验SQL注入：PrepareStatement预编译成模板解决、正则表达式校验、在后端加入拦截器对输入参数进行过滤校验跨站脚本攻击（XSS）：客户端信任服务器，所以黑客一旦在服务端返回的页面中插入一段JS代码，前端渲染出来，便为用户设下了陷阱，用户提交的数据就有可能被传输到黑客的服务器上，可以采用输出编码比如htmlencoder在输出到页面中，也可以对用户提交的内容进行特殊字符的过滤cookie泄露：尽可能避免在cookie中存放隐私数据，实在不行利用MD5等Hash算法多次散列之后存放中间人攻击：客户端请求的公钥并非来自合法服务器，而是中间人自己的服务器生成的公钥，造成了信息泄露。可以采用HTTPS替换HTTP在传输层上保证安全性，服务端要设置证书，客户端会验证证书的有效期、颁发机构等MD5加盐跨站请求伪造CSRF：token放header中不会被记录到浏览器、验证HTTP Referer中的IP地址证书：客户端持有CA根证书和CA公钥，服务端把证书下发给客户端，客户端先去验证服务端证书的合法性（域名、过期时间），通过后再用CA公钥解密证书里的数字摘要，看与自己的CA根证书是否匹配，若是则信任它发请求，不是则不允许发送。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink windows详解(一)]]></title>
    <url>%2Fposts%2Ff5b05e29%2F</url>
    <content type="text"><![CDATA[Windowwindow代表一个有限数据的集合，一个窗口有一个maxTimestamp，表示在该时刻窗口中的所有元素都已经到达。在Flink内部window有两个实现类：GlobalWindow：没有起止时间的窗口，运行期间接收到的所有元素都会被放在同一个窗口中。TimeWindow：该窗口会维护窗口的起止时间，同时为了满足sessionWindows的需要，还通过静态函数mergeWindows()提供了窗口合并的功能（将具有重合部分的窗口合并为一个窗口）。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static void mergeWindows(Collection&lt;TimeWindow&gt; windows, MergingWindowAssigner.MergeCallback&lt;TimeWindow&gt; c) &#123; // 当用户使用继承自MergingWindowAssigner的类时，就需要涉及到窗口的合并，默认是委托给该函数实现的 List&lt;TimeWindow&gt; sortedWindows = new ArrayList&lt;&gt;(windows); // 根据窗口的左边界时间排序 Collections.sort(sortedWindows, new Comparator&lt;TimeWindow&gt;() &#123; @Override public int compare(TimeWindow o1, TimeWindow o2) &#123; return Long.compare(o1.getStart(), o2.getStart()); &#125; &#125;); // key为合并后的窗口，value为被合并的窗口集合 List&lt;Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt;&gt; merged = new ArrayList&lt;&gt;(); Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt; currentMerge = null; for (TimeWindow candidate: sortedWindows) &#123; if (currentMerge == null) &#123; currentMerge = new Tuple2&lt;&gt;(); currentMerge.f0 = candidate; currentMerge.f1 = new HashSet&lt;&gt;(); currentMerge.f1.add(candidate); &#125; else if (currentMerge.f0.intersects(candidate)) &#123; // 窗口存在重叠，得到重叠窗口合并后的窗口 currentMerge.f0 = currentMerge.f0.cover(candidate); currentMerge.f1.add(candidate); &#125; else &#123; // 窗口与之前的窗口没有重叠，将之前的窗口添加到List中，开启新一轮的合并 merged.add(currentMerge); currentMerge = new Tuple2&lt;&gt;(); currentMerge.f0 = candidate; currentMerge.f1 = new HashSet&lt;&gt;(); currentMerge.f1.add(candidate); &#125; &#125; if (currentMerge != null) &#123; merged.add(currentMerge); &#125; for (Tuple2&lt;TimeWindow, Set&lt;TimeWindow&gt;&gt; m: merged) &#123; if (m.f1.size() &gt; 1) &#123; // 若该窗口是合并之后得到的，调用传入的方法进行回调通知 c.merge(m.f1, m.f0); &#125; &#125;&#125; // 发生在指定时间段的元素聚合到同一窗口public static long getWindowStartWithOffset(long timestamp, long offset, long windowSize) &#123; return timestamp - (timestamp - offset + windowSize) % windowSize;&#125;WindowAssignerWindowAssigner 用于决定将到达的元素分配给哪个window，在flink内部window和key决定了该元素应该存放在哪些窗格中，当trigger被触发时就会将窗口函数应用到窗格中的元素上并输出结果元素。该抽象类内部提供了如下核心函数：assignWindows(T element, long timestamp, WindowAssignerContext context)：每一个元素的到达都会调用该函数，返回该元素所属窗口的集合。getDefaultTrigger(StreamExecutionEnvironment env)：当用户没有指定trigger时，通过调用该函数获得默认的trigger。isEventTime()：返回该WindowAssigner是使用ProcessingTime还是EventTime决定元素窗口的分配Tumbling Windows的构造函数需要两个参数：size(窗口大小)，offset(时间偏移量)。生成的窗口具有固定大小并且窗口间没有重合。12345678910111213141516171819202122232425/*** TumblingProcessingTimeWindows类*/public Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; // 得到当前的机器时间，内部通过System.currentTimeMillis()获取 final long now = context.getCurrentProcessingTime(); // 计算元素所在窗口的左边界时间 long start = TimeWindow.getWindowStartWithOffset(now, offset, size); return Collections.singletonList(new TimeWindow(start, start + size));&#125;/*** TumblintEventTimeWindows类*/@Override public Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; // 和TumblingProcessingTimeWindows类似，不过不是获取的当前机器时间，而是直接使用传入的timestamp参数，即元素的EventTime if (timestamp &gt; Long.MIN_VALUE) &#123; // Long.MIN_VALUE is currently assigned when no timestamp is present long start = TimeWindow.getWindowStartWithOffset(timestamp, offset, size); return Collections.singletonList(new TimeWindow(start, start + size)); &#125; else &#123; .... &#125; &#125;Sliding Windows的构造函数需要三个参数：size(窗口大小)，slide(窗口滑动距离)，offset(时间偏移量)。生成的窗口同样具有固定大小，但是窗口每次都滑动距离不再是窗口大小，而是自定义的slide长度，因此窗口之间存在重叠。12345678910111213141516171819202122232425262728293031323334353637/*** SlidingProcessingTimeWindows类*/public Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; timestamp = context.getCurrentProcessingTime(); // 使用Sliding Windows时，一个元素可能被划分到多个的窗口中，使用List容器返回该元素所属的窗口 List&lt;TimeWindow&gt; windows = new ArrayList&lt;&gt;((int) (size / slide)); // 获取该元素所属最后一个窗口的左边界时间 long lastStart = TimeWindow.getWindowStartWithOffset(timestamp, offset, slide); // 不同窗口的滑动距离为slide，每次递减slide，依次添加前一个窗口 for (long start = lastStart; start &gt; timestamp - size; start -= slide) &#123; windows.add(new TimeWindow(start, start + size)); &#125; return windows;&#125;/*** SlidingEventTimeWindows类*/public Collection&lt;TimeWindow&gt; assignWindows(Object element, long timestamp, WindowAssignerContext context) &#123; if (timestamp &gt; Long.MIN_VALUE) &#123; // 同理，使用的是timestamp，即元素的EventTime List&lt;TimeWindow&gt; windows = new ArrayList&lt;&gt;((int) (size / slide)); long lastStart = TimeWindow.getWindowStartWithOffset(timestamp, offset, slide); for (long start = lastStart; start &gt; timestamp - size; start -= slide) &#123; windows.add(new TimeWindow(start, start + size)); &#125; return windows; &#125; else &#123; // 如果timestamp == Long.MIN_VALUE，说明元素没有EventTime，抛出异常 ...... &#125; &#125;Session Windows继承自MergingWindowAssigner，从名字就可以看出生成的窗口是可以合并的，使用这个窗口分配类的时候，每个元素的出现都会创建一个新的窗口，并和之前保存的窗口进行比较，当存在窗口重叠时会将重叠的窗口合并。和前两种不同，该类生成的窗口没有固定的起始时间，窗口的大小也是不确定的。从类图中可以看出，Session Windows分为两种：Dynamic开头的和不是Dynamic开头的，前者用户需要传入一个SessionWindowTimeGapExtractor接口的实现类，根据当前元素动态返回sessionTimeout；后者直接在构造函数中出固定的sessionTimeout。Global Windows相同的key只存在一个窗口，所有具有相同key的元素都会进入该窗口，同时默认返回的trigger也是NeverTrigger类型，表示永远不会触发窗口计算。TriggerTrigger 决定了一个窗格 pane 中的元素触发计算窗口函数的时机，按照上面对 WindowAssigner 的描述，一个元素可以被分到多个 window，按照 key和window 做 grouping 的元素集组成一个窗格，每个窗格都有自己的 Trigger 实例。Trigger 管理了 event-timer/processing-timer 的注册；同时在处理元素以及对应的 timer event 在 WindowOperator 上触发时决策是否真正触发计算[ FIRE/CONTINUE ]。该抽象类提供了如下函数：onElement: 处理每个添加到窗格中的元素onEventTime: TriggerContext 注册的 event-time timer 被触发时调用onProcessingTime: TriggerContext 注册的 processing-time timer 被触发时调用onMerge: window 被 merge 时触发Flink根据trigger的返回值即TriggerResult来决定接下来如何操作，TriggerResult是一个枚举类，内部有两个参数：fire(触发窗口计算)、purge(清空窗口元素)。共定义了4个枚举常量：CONTINUE(不触发计算也不清空元素，继续等待下一个元素)、FIRE_AND_PURGE(触发计算并清空元素)、FIRE(触发计算，但不清空)、PURGE(清空窗口中的元素)。典型的 trigger 实现用途：ContinuousEventTimeTrigger：指定的 interval 或 event window 的边界小于当前 watermark 时触发 onEventTime 计算。12345678910111213141516171819202122232425262728293031323334353637383940414243public class ContinuousEventTimeTrigger&lt;W extends Window&gt; extends Trigger&lt;Object, W&gt; &#123; ...... @Override public TriggerResult onElement(Object element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; if (window.maxTimestamp() &lt;= ctx.getCurrentWatermark()) &#123; // 如果窗口的右边界大于小于等于当前的watermark触发计算 return TriggerResult.FIRE; &#125; else &#123; // 否则将窗口右边界注册为触发时间 ctx.registerEventTimeTimer(window.maxTimestamp()); &#125; // 获取保存的由Interval触发计算的时间 ReducingState&lt;Long&gt; fireTimestamp = ctx.getPartitionedState(stateDesc); if (fireTimestamp.get() == null) &#123; // 之前没有保存的状态，计算Interval触发计算的时间并注册 long start = timestamp - (timestamp % interval); long nextFireTimestamp = start + interval; ctx.registerEventTimeTimer(nextFireTimestamp); fireTimestamp.add(nextFireTimestamp); &#125; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onEventTime(long time, W window, TriggerContext ctx) throws Exception &#123; if (time == window.maxTimestamp())&#123; // 窗口右边界触发计算 return TriggerResult.FIRE; &#125; ReducingState&lt;Long&gt; fireTimestampState = ctx.getPartitionedState(stateDesc); Long fireTimestamp = fireTimestampState.get(); // interval触发，清空之前保存的状态并保存计算出的新的interval触发时间 if (fireTimestamp != null &amp;&amp; fireTimestamp == time) &#123; fireTimestampState.clear(); fireTimestampState.add(time + interval); ctx.registerEventTimeTimer(time + interval); return TriggerResult.FIRE; &#125; return TriggerResult.CONTINUE; &#125; ......&#125;ContinuousProessingTimeTrigger：每隔Interval触发一次，触发后将当前时间+interval注册为下一次触发时间。12345678910111213141516171819202122232425262728293031public class ContinuousProcessingTimeTrigger&lt;W extends Window&gt; extends Trigger&lt;Object, W&gt; &#123; ...... @Override public TriggerResult onElement(Object element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; // 由于该触发器是基于机器时间的，故不需要判断watermark，只需要注册interval的触发时间 ReducingState&lt;Long&gt; fireTimestamp = ctx.getPartitionedState(stateDesc); timestamp = ctx.getCurrentProcessingTime(); if (fireTimestamp.get() == null) &#123; long start = timestamp - (timestamp % interval); long nextFireTimestamp = start + interval; ctx.registerProcessingTimeTimer(nextFireTimestamp); fireTimestamp.add(nextFireTimestamp); return TriggerResult.CONTINUE; &#125; return TriggerResult.CONTINUE; &#125; @Override public TriggerResult onProcessingTime(long time, W window, TriggerContext ctx) throws Exception &#123; ReducingState&lt;Long&gt; fireTimestamp = ctx.getPartitionedState(stateDesc); // 判断传入的时间是否等于上次注册的时间，true则触发计算并注册新的触发时间 if (fireTimestamp.get().equals(time)) &#123; fireTimestamp.clear(); fireTimestamp.add(time + interval); ctx.registerProcessingTimeTimer(time + interval); return TriggerResult.FIRE; &#125; return TriggerResult.CONTINUE; &#125; ......&#125;CountTrigger: 当窗口内的元素个数大于构造函数传入的maxCount时触发窗口计算。123456789101112131415161718public class CountTrigger&lt;W extends Window&gt; extends Trigger&lt;Object, W&gt; &#123; ...... @Override public TriggerResult onElement(Object element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; // 由于是根据窗口元素个数决定是否触发计算，所以该方法是唯一可能触发计算的地方 // onEventTime和onProcessingTime都只返回Continue ReducingState&lt;Long&gt; count = ctx.getPartitionedState(stateDesc); count.add(1L); // 统计窗口中元素个数，大于maxCount时触发计算 if (count.get() &gt;= maxCount) &#123; // 清空计数器，用于下一次计数 count.clear(); return TriggerResult.FIRE; &#125; return TriggerResult.CONTINUE; &#125; ......&#125;DeltaTrigger: 用户需要提供deltaFunction函数，用于计算当前元素和上次触发窗口计算元素之间的距离，当距离大于构造函数传入的threshold时，触发计算。1234567891011121314151617181920212223242526272829public class DeltaTrigger&lt;T, W extends Window&gt; extends Trigger&lt;T, W&gt; &#123; ...... /** * @param threshold 触发计算的阀值，当deltaFunction的返回值大于该阀值时触发 * @param deltaFunction delta计算函数，该函数会传入两个参数：上次触发计算的元素和当前进入窗口的元素 */ private DeltaTrigger(double threshold, DeltaFunction&lt;T&gt; deltaFunction, TypeSerializer&lt;T&gt; stateSerializer) &#123; this.deltaFunction = deltaFunction; this.threshold = threshold; stateDesc = new ValueStateDescriptor&lt;&gt;("last-element", stateSerializer); &#125; @Override public TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx) throws Exception &#123; ValueState&lt;T&gt; lastElementState = ctx.getPartitionedState(stateDesc); if (lastElementState.value() == null) &#123; // 状态不存在，则更新为当前元素 lastElementState.update(element); return TriggerResult.CONTINUE; &#125; // delta的值大于threshold时，触发计算并更新状态为当前元素 if (deltaFunction.getDelta(lastElementState.value(), element) &gt; this.threshold) &#123; lastElementState.update(element); return TriggerResult.FIRE; &#125; return TriggerResult.CONTINUE; &#125; ......&#125;EventTimeTrigger：event window 的边界小于当前 watermark 时触发 onEventTime 计算1234567891011121314151617181920212223public class EventTimeTrigger extends Trigger&lt;Object, TimeWindow&gt; &#123; ...... @Override public TriggerResult onElement(Object element, long timestamp, TimeWindow window, TriggerContext ctx) throws Exception &#123; // 当前窗口的右边界小于等于watermark时触发计算 if (window.maxTimestamp() &lt;= ctx.getCurrentWatermark()) &#123; return TriggerResult.FIRE; &#125; else &#123; // 否则注册触发时间，当大于该触发时间的watermark到达时，会回调onEventTime函数 ctx.registerEventTimeTimer(window.maxTimestamp()); return TriggerResult.CONTINUE; &#125; &#125; @Override public TriggerResult onEventTime(long time, TimeWindow window, TriggerContext ctx) &#123; // watermark到达后，所有小于watermark的注册事件的回调方法 return time == window.maxTimestamp() ? TriggerResult.FIRE : TriggerResult.CONTINUE; &#125; ......&#125;ProessingTimeTrigger：event window 的边界小于当前机器时间时触发 onProcessingTime 计算12345678910111213141516public class ProcessingTimeTrigger extends Trigger&lt;Object, TimeWindow&gt; &#123; ...... @Override public TriggerResult onElement(Object element, long timestamp, TimeWindow window, TriggerContext ctx) &#123; // 元素到达时，直接将当前元素所在窗口的右边界注册为触发时间，并不会触发计算 ctx.registerProcessingTimeTimer(window.maxTimestamp()); return TriggerResult.CONTINUE; &#125; ...... @Override public TriggerResult onProcessingTime(long time, TimeWindow window, TriggerContext ctx) &#123; // 触发时间到达后的回调方法，直接触发窗口的计算 return TriggerResult.FIRE; &#125; ......&#125;Evitor用于在窗口函数触发前或者触发后，删除窗口中不符合条件的元素，其提供了如下两个函数用于实现该功能：evictBefore(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext);在窗口计算前，会首先调用该方法evictAfter(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, int size, W window, EvictorContext evictorContext);在窗口计算后，调用该方法CountEvictor：如果窗口中的元素大于maxCount，就从窗口的开头删除元素，直到窗口内的元素等于maxCountTimeEvictor：首先获取窗口中所有元素的最大时间戳，使用该时间戳减去窗口大小得到窗口中元素应具有的最小时间戳，遍历删除所有时间戳小于该值的元素DeltaEvictor：首先获取窗口最后一个元素，然后一次遍历窗口中的元素，将该元素和最后一个元素传递给用户定义的DeltaFunction，如果返回值大于传入的threshold，则删除]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式计算</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出Thrift]]></title>
    <url>%2Fposts%2F4ed356c2%2F</url>
    <content type="text"><![CDATA[介绍Apache Thrift是Facebook实现的一种高效的、支持多种编程语言的远程服务调用框架，包括一个软件库和一组代码生成引擎，以加快高效率、可拓展的后端服务的开发与实现速度。它采用接口描述语言定义并创建服务，支持可拓展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如C++、Java、Python、PHP、Ruby、Erlang、Perl等创建高效的、无缝的服务，传输数据格式采用二进制格式，相对于JSON和XML体积更小，对于高并发、大数据量和多语言的环境更有优势。架构Thrift包含一个完整的堆栈结构用于构建客户端和服务端，下图描绘了Thrift的整体架构如图所示，黄色部分是用户实现的业务逻辑，褐色部分是根据Thrift定义的服务接口文件生成的客户端和服务端代码框架，红色部分是根据Thrift文件生成代码实现数据的读写操作。红色部分以下是Thrift的传输体系、协议及底层I/O通信，使用Thrift可以很方便的定义一个服务并且选择不同的传输协议和传输层而不用重新生成代码支持的协议、传输层和服务器类型Thrift的网络栈如下图所示：协议Protocol抽象层定义了一种将内存中数据结构映射成可传输格式的机制。换句话说，Protocol定义了datatype怎样使用底层的Transport对自己进行编解码。因此，Protocol的实现要给出编码机制并负责对数据进行序列化，在传输协议上总体划分为文本(text)和二进制(binary)传输协议。TBinaryProtocol 直接使用二进制编码格式进行传输TCompactProtocol 使用高效率的、密集的二进制编码格式进行数据传输TJSONProtocol 使用JSON的数据编码格式进行数据传输TSimpleJSONProtocol 只提供JSON只写的协议，适用于通过脚本语言解析requestTimeoutUnit = args.requestTimeoutUnit;requestTimeout = args.requestTimeout;beBackoffSlotInMillis = args.beBackoffSlotLengthUnit.toMillis(args.beBackoffSlotLength);传输协议描述了应该传输什么样的数据，而传输层则负责如何传输数据，Thrift提供了如下几种传输方式：TSocket 使用阻塞式I/O进行传输，是最常见的模式TFrameTransport 使用非阻塞方式，按块的大小进行传输。若使用该传输层，其服务器必须修改为非阻塞的服务类型TFileTransport 以文件形式进行传输TMemoryTransport 将内存用于I/O，java实现时内部实际使用了简单的ByteArrayOutputStreamTNonblockingTransport 使用非阻塞方式，用于构建异步客户端Transport层提供了一个简单的网络读写抽象层。这使得thrift底层的transport从系统其它部分（如：序列化/反序列化）解耦，以下是一些Transport接口提供的方法:除了以上几个接口，Thrift使用ServerTransport接口接受或者创建原始transport对象。正如名字暗示的那样，ServerTransport用在server端，为到来的连接创建Transport对象。服务端Server将以上所有特性集成在一起：（1） 创建一个transport对象（2） 为transport对象创建输入输出protocol（3） 基于输入输出protocol创建processor（4） 等待连接请求并将之交给processor处理TSimpleServer 单线程服务器端，使用标准的阻塞式I/O，循环监听新请求的到来并完成对请求的处理，通常在演示时候使用。TThreadPoolServer 多线程服务端，使用标准的阻塞式I/O。主线程负责阻塞式监听是否有新的请求到来，业务处理交由一个线程池处理。TNonblockingServer 用于构建异步客户端，使用非阻塞式I/O。使用单线程模型，效率提升主要体现在IO多路复用上(需使用TFramedTransport数据传输方式)THaHaServer 是TNonblockingServer的子类，引入了线程池来专门进行业务处理。主线程需要完成对所有socket的监听以及数据读写工作，业务处理教程交给一个线程池来完成。TThreadSelectorServer 其包括如下几个部分一个AcceptThread线程对象，专门用于处理监听socket上的新连接若干个SelectorThread对象专门用于处理业务socket的网络I/O操作，所有网络数据的读写均是由这些线程来完成一个负载均衡器SelectorThreadLoadBanancer对象，主要用于AcceptThread县城接收到一个新socket连接请求时，决定将这个新连接请求分配给哪个SelectorThread线程一个ExecutorService类型的工作线程池，在SelectorThread线程将请求数据读取之后，交给ExecutorService线程池中的线程完成此次调用的具体执行。调用过程Thrift调用过程中，Thrift客户端和服务器之间主要用到输出层类、协议层类和处理类三个主要的核心类，这三个类互相协作共同完成rpc的整个调用过程。将客户端程序调用的函数名和参数传递给协议层，协议层将函数名和参数按照协议格式进行封装，然后封装的结果交给下层的传输层。需要保证与Thrift服务器程序所使用的协议类型一致，否则Thrift服务器程序便无法在其协议层进行数据解析传输层将协议层传递过来的数据进行处理，例如传输层实现类TFramedTransport就是将数据封装成帧的格式，然后将处理之后的数据通过网络发送给Thrift服务器。需要保证与Thrift服务器程序所采用的传输层的实现类一致，否则Thrift的传输层也无法将数据进行逆向的处理。Thrfit服务器通过传输层接受网络上传输过来的调用请求数据，将接收到的数据进行逆向的处理，然后在交付给Thrift服务器的协议类。dushubijiThrift服务端的协议类将传输层处理之后的数据按照协议进行解封装，并将解封装之后的数据交给Processor处理器类进行处理Thrift服务端的Processor类根据协议层解析的记过，按照函数名找到函数名所对应的函数对象Thrift服务端使用传过来的参数调用这个找到的函数对象Thrift服务端将函数对象执行的结果交给协议层Thrift服务端的协议层将函数的执行结果进行协议封装，传输层将协议层封装的结果进行处理，然后发送给Thrift客户端程序Thrift客户端程序的传输层将受到的网络结果进行逆向处理，得到实际的协议数据。协议层将数据按照写一个数进行解封装，然后得到具体的函数执行结果，并将其交付给调用函数示例首先使用接口描述语言编写脚本文件Hello.thrift，代码如下123456789namespace java cn.windylee.thriftservice Hello&#123; string helloString(1:string para); i32 helloInt(1:i32 para); bool helloBoolean(1:bool para); void helloVoid(); string helloNull();&#125;在文件中定义了五个方法，每个方法包含一个方法名，参数列表和返回类型。每个参数包括参数序号，参数类型以及参数名。使用Thrift工具变异Hello.Thrift，就会生成对应语言的文件。该文件包含了在Hello.thrift文件中描述的服务Hello的接口定义，即Hello.Iface接口，以及服务调用的底层通信细节，包括客户端的调用逻辑Hello.Client以及服务端的处理逻辑Hello.Processor，用于构建客户端和服务端的功能。12thrift -gen py Hello.thrift # 生成python2的接口代码thrift -gen java HelloService.thrift # 生成java的接口代码创建Java客户端实现代码，调用Hello.Client访问服务端的逻辑实现123456789101112131415161718192021222324252627import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TProtocol;import org.apache.thrift.transport.TSocket;import org.apache.thrift.transport.TTransport;public class HelloClient &#123; public static void main(String[] args) throws Exception &#123; TTransport transport = new TSocket("127.0.0.1", 9090); transport.open(); TProtocol protocol = new TBinaryProtocol(transport); Hello.Client client = new Hello.Client(protocol); client.helloVoid(); String recvStr = client.helloString("hello world"); System.out.println(recvStr); int recvInt = client.helloInt(123); System.out.println(recvInt); String RecvNull = client.helloNull(); System.out.println(RecvNull); transport.close(); &#125;&#125;创建服务端实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/env python# -*- coding:utf-8 -*-from hello import Hellofrom hello.ttypes import *from thrift.transport import TSocketfrom thrift.transport import TTransportfrom thrift.protocol import TBinaryProtocolfrom thrift.server import TServerclass HelloServerHandler: def helloString(self, para): ret = "Received: " + para print(ret) return ret def helloInt(self, para): ret = "Received: " + str(para) print(ret) return para * 2 def helloBoolean(self, para): ret = "Received: "+ str(para) print(ret) return True def helloVoid(self): ret = "A request from client" print(ret) def helloNull(self): ret = "Received Nothing" return retif __name__ == '__main__': handler = HelloServerHandler() processor = Hello.Processor(handler) transport = TSocket.TServerSocket("127.0.0.1", 9090) tfactory = TTransport.TBufferedTransportFactory() pfactory = TBinaryProtocol.TBinaryProtocolFactory() server = TServer.TSimpleServer(processor, transport, tfactory, pfactory) print("Starting thrift server in python...") server.serve() print("done!")]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>thrift</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thrift IDL详解]]></title>
    <url>%2Fposts%2F4ed356c2%2F</url>
    <content type="text"><![CDATA[IDLThrift采用IDL(Interface Definition Language)来定义通用的服务接口，然后通过Thrift提供的编译器，可以将服务接口编译成不同语言编写的代码，通过这个方式来实现跨语言调用。语法参考基本类型bool: 布尔值(true or false)byte: 有符号字节i16: 16位有符号整型i32: 32位有符号整型i64: 64位有符号整型double: 64位浮点型string: 字符串类型binary: byte[]数组，主要在java中使用注意：Thrift不支持无符号整型，因为很多目标语言不存在无符号整型(如：java)结构体Thrift结构体在概念上同C语言结构体类型–一种将相关属性聚集在一起的方式。在面向对象语言中，thrift结构体被转换成类。struct不能继承，但是可以嵌套，不能嵌套自己其成员必须有明确类型成员必须通过正整数进行编号，且同一个struct中的成员编号不能重复。建议不要轻易修改数字编号，修改之后如果客户端和服务端的生成代码没有同步，解析就会出现问题成员分割符可以使逗号(,)或是分号(;)，而且可以混用，但是为了表述清晰，建议在定义中只使用其中一种字段会有optional和required之分，如果不指定则为无类型–可以不填充该值，但是在序列化传输的时候也会序列化进去，optional是不填充则不序列化，required是必须填充也必须序列化每个字段可以设置默认值同一文件可以定义多个struct，也可以定义在不同文件，使用include进行引入例子：12345struct Person&#123; 1: required string name, // 该字段必须填充 2: optional i32 age = 20, // 该字段可以不填充，使用默认值：20 3: i32 height // 对于基本类型，会序列化到字节数组中，解析的时候不会校验。对于对象类型，如果不为空，则序列化到自己数组中&#125;规则：如果required标识的域没有赋值，thrift将给予提示如果optional标识的域没有赋值，该域将不会被序列化传输如果某个optional标识的域有缺省值而用户没有重新赋值，则该域的值为缺省值如果某个optional标识的域有缺省值或者用户已经重新赋值，而不设置它的__isset为true，也不会被序列化传输容器类型thrift容器域类型密切相关，它与当前流行编程语言提供的容器类型相对应，采用java泛型风格表示。提供了3种容器类型list: 元素类型为T的有序表，允许元素重复。对应c++的vector，java的ArrayList或者其它语言的数组set: 元素类型为T的无序表，不允许元素重复，对应c++中的set，java中的HashSet，python中的set，php中没有set，则转换为list类型map&lt;K, V&gt;: 键类型为K，值类型为V的键值对类型，键不允许重复。对应c++中的map，Java中的HashMap，PHP中的array，Python中的dictionary容器中元素类型可以使除了service外的任何合法thrift类型(包括结构体和异常)。例子：12345struct Test &#123; 1: map&lt;string, Person&gt; personMap, 2: set&lt;i32&gt; personIds, 3: list&lt;double&gt; prices&#125;枚举可以像C/C++那样定义枚举类型编译器默认从0开始赋值可以赋予某个常量某个整数允许常量是十六进制整数末尾没有分号给常量赋缺省值时，使用常量的全称例子：123456enum EnOpType &#123; CMD_OK = 0, // (0) CMD_NOT_EXIT = 2000, // (2000) CMD_EXIT = 2001, // (2001) CMD_ADD = 2002 // (2002)&#125;123456struct StUser &#123; 1: required i32 userId; 2: required string userName; 3: optional EnOpType cmd_code = EnOpType.CMD_OK; 4: optional string language = “english”&#125;注意，不同于protocal buffer，thrift不支持枚举类嵌套，枚举常量必须是32位的正整数常量定义thrift允许用户定义常量，复杂的类型和结构体可使用JSON形式表示，通过在变量前面使用const修饰来定义常量。123const i32 INT_CONST = 1234; // a const map&lt;string,string&gt; MAP_CONST = &#123;"hello": "world", "goodnight": "moon"&#125;类型定义thrift支持C/C++风格的typedef123typedef i32 MyInteger \\a typedef Tweet ReTweet \\b注意，类型定义的末尾没有逗号或者分号；也可以使用typedef对struct类型进行重命名异常异常在语法和功能上类似于结构体，差别是异常使用关键字exception，而且异常是继承每种语言的基础异常类。1234exception MyException &#123; 1: i32 errorCode, 2: string message&#125;服务服务的定义方法在语义上等同于面向对象语言中的接口，thrift编译器会产生执行这些接口的client和server stub。thrift编译器会根据选择的目标语言为server产生服务接口代码，为client产生stubs。函数定义可以使用逗号或者分号标识结束参数可以是基本类型或者结构体，参数是只读的（const），不可以作为返回值！！！返回值可以是基本类型或者结构体，也可以是voidservice支持继承，一个service可使用extends关键字继承另一个service，但是不支持重载123456service HelloService &#123; i32 sayInt(1:i32 param) string sayString(1:string param) bool sayBoolean(1:bool param) void sayVoid()&#125;命名空间Thrift中的命名空间类似于C++中的namespace和Java中的package，它们提供了一种组织（隔离）代码的简便方式。命名空间也可以用于解决类型定义中的名字冲突。因为每种语言均有自己的命名空间定义方式（如python中有module），thrift允许开发者针对特定语言定义namespace：123namespace cpp com.example.testnamespace java com.example.testnamespace py com.example.test注释Thrift支持C多行风格和Java/C++单行风格。12345/** * This is a multi-line comment. * Just like in C. */ // C++/Java style single-line comments work just as well.包含为了便于管理、重用和提高模块性/组织性，我们常常分割Thrift定义在不同的文件中。包含文件搜索方式与c++一样。Thrift允许文件包含其它thrift文件，用户需要使用thrift文件名作为前缀访问被包含的对象，如：12345include "tweet.thrift" // a struct TweetSearchResult &#123; 1: list&lt;tweet.Tweet&gt; tweets; // b&#125;注意：thrift文件名要用双引号包含，末尾没有逗号或者分号综合示例entity.thrift1234567891011121314151617181920212223242526272829303132namespace java cn.windylee.thrift.entitynamespace py course.entityenum PhoneType&#123; HOME, WORK, MOBILE, OTHER&#125;struct Phone&#123; 1: i32 id, 2: string number, 3: PhoneType type&#125;struct Person&#123; 1: i32 id, 2: string firstName, 3: string lastName, 4: string email, 5: list&lt;Phone&gt; phones&#125;struct Course&#123; 1: i32 id, 2: string number, 3: string name, 4: Person instructor, 5: string roomNumber, 6: list&lt;Person&gt; students&#125;exception.thrift12345678910namespace java cn.windylee.thrift.exceptionnamespace py course.exceptionexception CourseNotFound&#123; 1: string message&#125;exception UnacceptableCourse&#123; 1: string message&#125;courseService.thrift123456789101112namespace java cn.windylee.thrift.servicenamespace py course.serviceinclude "Phone.thrift"include "Exception.thrift"service CourseService&#123; list&lt;string&gt; getCourseInventory(); Phone.Course getCourse(1:string courseNumber) throws (1: Exception.CourseNotFound cnf); void addCourse(1: Phone.Course course) throws (1: Exception.UnacceptableCourse uc); void deleteCourse(1:string courseNumber) throws (1:Exception.CourseNotFound cnf);&#125;接口文件升级thrift文件内容可能会随着时间变化的。如果已经存在的消息类型不再符合设计要求，比如，新的设计要在message格式中添加一个额外字段，但你仍想使用以前的thrift文件产生的处理代码。如果想要达到这个目的，只需：不要修改已存在域的整数编号新添加的域必须是optional的，以便格式兼容。对于一些语言，如果要为optional的字段赋值，需要特殊处理，比如对于C++语言，要将新添加字段的__isset设置为true，这样才能序列化并传输或者存储（不然optional字段被认为不存在，不会被传输或者存储）。非required域可以删除，前提是它的整数编号不会被其他域使用。对于删除的字段，名字前面可添加“OBSOLETE_”以防止其他字段使用它的整数编号。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>thrift</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL开发规范]]></title>
    <url>%2Fposts%2F4827c64b%2F</url>
    <content type="text"><![CDATA[基础规范表存储引擎必须是innoDB表字符集默认使用utf8，必要时使用utf8mb4（utf8mb4是utf8的超集，可以存储4字节如表情符号）禁止使用存储过程，视图，触发器，Event（对数据库性能影响较大，互联网业务，能让站点层和服务层干的事情，不要交到数据库层）禁止在数据库中存储大文件，例如照片（可以将大文件存储在对象存储系统，数据库中存储路径）命名规范库名，表名，列名必须用小写，采用下划线分隔，长度不要超过32个字符库备份必须以bak为前缀，以日期为后缀从库必须以-s为后缀备库必须以-ss为后缀表设计规范表必须有主键，推荐使用UNSIGNED整数为主键禁止使用外键，如果要保证完整性，应由应用程序实现（外键使得表之间相互耦合，影响update/delete等SQL性能，有可能造成死锁，高并发情况下容易成为数据库瓶颈）建议讲大字段，访问频度低的字段才分到单独的表中存储，分离冷热数据列设计规范根据业务区分使用tinyint/int/bigint，分别会占用1/4/8字节根据业务区分使用char/varchar（字段长度固定或者长度近似的业务场景，适合使用char，能够减少碎片，查询性能高；字段长度相差较大或者更新较少的业务场景，适合使用varchar，能够减少空间）根据业务区分使用datetime/timestamp（前者占用5个字节，后者占用4个字节，存储年使用YEAR，存储日起使用DATE，存储时间使用datetime）必须把字段定义为NOT NULL并设置默认值（NULL的列使用索引，索引统计都更加复杂，MySQL更难优化；NULL需要更多的存储空间；NULL只能采用IS NULL或者IS NOT NULL）使用INT UNSIGNED存储ipv4，不要使用char(15)使用varchar(20)存储手机号，不要使用整数（牵扯到国家代号，可能出现+/-/()等字符，例如+86；手机号不会用来做数学运算；varchar可以模糊查询）使用TINYINT来代替ENUM（ENUM增加新值都需要进行进行DDL操作）索引规范唯一索引使用uniq_[字段名]来命名，非唯一索引使用idx_[字段名]来命名单张表索引数量建议控制到5个以内（太多索引会影响写性能；生成执行计划时，如果索引太多，会降低性能，并可能导致MySQL选择不到最有索引；异常复杂的查询需求，可以选择ES等更为合适的方式存储）组合索引字段数不建议超过5个（如果5个还不能极大缩小row范围，可能是设计问题）不建议在更新频繁的字段上建立索引非必要不要进行JOIN查询，如果要进行JOIN查询，被JOIN的字段必须类型相同，并建立索引理解组合索引最左前缀原则，避免重复建立索引。如果建立了(a, b, c)，相当于建立了(a), (a, b), (a, b, c)SQL规范禁止使用select , 只获取必要字段（select 会增加cpu/io/内存/带宽的消耗; 指定字段能有效利用索引覆盖；指定字段查询，在表结构变更时，能保证对应用程序无影响）insert必须指定字段，禁止使用insert into T values()，（指定字段插入，在表结构变更时，能保证对应用程序无影响）禁止在where条件列使用函数或者表达式（导致不能命中索引，全表扫描）禁止大表JOIN和子查询同一个字段上的OR必须改写为IN，IN的值必须少于50个应用程序必须捕获SQL异常]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty实战读书笔记]]></title>
    <url>%2Fposts%2Fbc6b2f71%2F</url>
    <content type="text"><![CDATA[第三章Channel、EventLoop和ChannelFuture是Netty网络抽象的代表。Channel—对Java中的Socket的封装。Netty拥有许多预定义的、专门化实现的广泛类层次结构的根(EmbeddedChannel、LocalServerChannel、NioDatagramChannel、NioSctpChannel和NioSocketChannel)EventLoop—控制流、多线程处理、并发。EventLoopGroup是一个EventLoop的容器，可以包含一个或多个EventLoop。每个EventLoop在其生命周期内只和一个Thread绑定；EventLoop处理的IO事件都在它专有的Thread上被处理。一个Channel在其生命周期内只注册于一个EventLoop，一个EventLoop可能会被分配给一个或多个Channel。（在这种设计中，一个给定的Channel的I/O操作都是由同一个Thread执行的，实际上消除了对于同步的需要）ChannelFuture—-异步通知，可以通过该接口的addListener()方法注册一个ChannelFutureListener监听类，以便在某个操作完成时得到通知。在Netty中，有两种发送消息的方式。可以直接写到Channel中，会导致消息从ChannelPipeline的尾端开始流动；也可以写到和ChannelHandler相关联的ChannelHandlerContext对象中，会导致消息从ChannelPipeline中的下一个ChannelHandler流动。第四章ChannelPipeline的典型用途包括：将数据从一个格式转换为另一种格式提供异常的通知提供Channel变为活动的或者非活动的通知提供当Channel注册到EventLoop或者从EventLoop注销时的通知提供有关用户自定义事件的通知Netty的Channel实现是线程安全的，因此可以存储一个指向Channel的引用，每当需要向远程节点写数据时，都可以使用存储的引用，可以保证消息按顺序发送。Netty内置的传输：| 名称 | 包 | 描述 || ——– | ————————— | ———————————————————— || NIO | io.netty.channel.socket.nio | 使用java.nio.channelds包作为基础–给予选择器的方式 || Epoll | io.netty.channel.epoll | 有JNI驱动的epoll()和非阻塞IO。这个传输支持只有在LInux上可用的多种特性，如SO_REUSEPORT，比NIO传输更快，而且是完全非阻塞的 || OIO | io.netty.channel.socket.io | 使用java.net包作为基础–使用阻塞流 || Local | io.netty.channel.local | 可以在JVM内部通过管道进行通信的本地传输 || Embedded | io.netty.channel.embedded | Embedded传输，允许是用ChannelHandler而又不需要一个真正的基于网络的传输，可以用来作为测试使用。 |第五章ByteBuf对比原生ByteBuffer的有点可以被用户自定义的缓冲区类型拓展通过内置的复合缓冲区类型实现透明的零拷贝容量可以按需增长，(可以指定最大容量，试图移动写索引超过这个值会触发异常)在读和写两种模式之间不需要调用ByteBuffer的flip()方法，读和写使用了不同的索引支持方法的链式调用支持引用计数支持池化名称以read或者write开头的ByteBuf方法，将会推进其对应的索引，而名称以set或get开头的操作不会修改索引。ByteBuf的三种模式堆缓冲区，将数据存储在JVM的堆空间中，又称为支撑数据模式。可以在没有使用池化的情况下提供快速的分配和释放直接缓冲区，该数据不会被JVM的垃圾回收机制回收，也避免了每次调用本地I/O操作之前（或之后）将缓冲区的内容复制到一个中间缓冲区（或从中间缓冲区把内容复制到缓冲区）；其分配和释放都比较昂贵复合缓冲区，为多个ByteBuf提供了一个聚合视图。ByteBuf字节级操作如图所示，标记为可丢弃字节的分段包含了已经被读过的字节。通过调用discardReadBytes()方法可以丢弃他们以回收空间。因为可读字段必须被移动到缓冲区的开始位置，调用该方法后会导致内存复制，不建议频繁调用该方法。可读字节分段存储了实际数据，任何名称以read或skip开头的操作都将检索或者跳过位于当前readIndex的数据，并且将它增加已读字节数。可读字节分段是指一个拥有未定义内容的、写入就绪的内存区域，任何名称以write开头的操作都将从当前的writeIndex处开始写数据，并将它增加已经写入的字节数。ByteBuf可以通过调用markReaderIndex()、markWriterIndex()、resetWriterIndex()和resetReaderIndex()来标记和重置ByteBuf的readIndex和writeIndex。也可以通过调用readerIndex(int)或者writerIndex(int)来将索引移动到指定位置。通过调用clear()方法来将readerIndex和writerIndex都置为0，但不会清除内存中的内容，因为只是重置索引所以比discardReadBytes()轻量的多。派生缓冲区为ByteBuf提供了以专门的方式来呈现其内容的视图，可以通过duplicate()、slice()、slice(int, int)、Unpooled.unmodifiableBuffer(...)、order(ByteOrder)、readSlice(int)等方法创建。这些方法都将返回一个新的ByteBuf实例，它具有自己的读写索引和标记索引，其共享源ByteBuf内存。意味着修改了它的内容也会同时修改其对应源的实例。第六章Channel的4具有4中状态状态描述ChannelUnregisteredChannel已经被创建，但还未注册到EventLoopChannelResisteredChannel已经被注册到EventLoopChannelActiveChannel处于活动状态(已经连接到它的远程节点)。他现在可以接受和发送数据了ChannelInactiveChannel没有连接到远程节点当状态发生变化时，将会生成对应的事件。这些事件将会被转发给ChannelPipeline中的ChannelHandler，其可以随后对它们做出相应。ChannelHandler定义了3中生命周期操作，每个方法都能接受一个ChannelHandlerContext参数。类型描述handlerAddedChannelHandler添加到ChannelPipeline中时被调用handlerRemoved从ChannelPipeline中移除ChannelHandler时被调用exceptionCaught当处理过程中在ChannelPipeline中有错误产生时被调用ChannelInboundHandler接口负责处理入站数据以及各种状态的变化，其实现类在重写channelRead()方法时，需要显式的释放和池化ByteBuf实例相关的内存。继承自SimpleChannelInboundHandler的类在重写channelRead0()方法时，该抽象类会自动释放ByteBuf资源，所以我们不应该存储指向任何消息的引用。ChannelOutboundHandler用来处理出站操作和数据如果再该Handler中消息被消费或者丢弃了，并且没有传递给ChannelPipeline中的下一个ChannelOutboundHandler，就需要调用realease方法释放内存。如果消息到达了实际的传输层，当它被写入时或者Channel关闭时，就将会被自动释放。该接口中的大部分方法都需要一个ChannelPromise参数，以便在操作完成时得到通知。ChannelPromise是ChannelFuture的一个子类，其定义了一些可写的方法，如setSuccess()和setFailure()。ChannelPipline中的每一个ChannelHandler都是通过它的EventLoop(I/O线程)来处理传递给他的事件的，所以一定不要阻塞这个线程，否则的话会对整体的I/O处理产生负面的影响。ChannelHandleContext有很多方法，其中一些方法也存在与Channel和ChannelPipeline中。如果调用Channel或者ChannelPipeline上的这些方法，他们将沿着整个ChannelPipeline进行传播；而调用位于ChannelHandlerContext上的相同方法，则将从当前所关联的ChannelHandler开始，并且只会传播给位于该ChannelPipeline中的下一个能够处理改事件的ChannelHandler。ChannelHandler的数据入站异常处理逻辑ChannelHandler.exceptionCaught()的默认实现是简单得将当前一场转发给ChannelPipeline中的下一个ChannelHandler如果异常到达了ChannelPipeline的尾端，他将会通过Warning级别的日志被记录为未被处理可以重写exceptionCaught()方法来自定义异常处理逻辑ChannelHandler处理出站异常每个出站操作都将返回一个ChannelFuture。注册到ChannelFuture的ChannelFutureListener都将在操作完成时被通知该操作是否成功。几乎所有的ChannelOutboundHandler上的方法都会传入一个ChannelPromise的实例，其提供了立即通知的可写方法。第七章 &amp; 第八章EventLoop继承了ScheduledExcutorService的同时，只定义了一个方法parent()，用于返回所属的EventLoopGroup。故其提供了ScheduledExecutorService的所有方法，并提供了更好的性能。EventLoop线程分配时，每个EventLoop都将分配给一个Thread，Channel和EventLoop的分配方式根据所选IO类型有所不同。使用异步传输时，一个EventLoop可以被多个Channel共享。在使用ThreadLocal时，共享同一EventLoop的Channel获取到的ThreadLocal都是一样的使用同步传输时，每个EventLoop只能分配给一个Channel，保证了阻塞发生时编程的灵活性。AbstractBootstrap类的完整声明如下：1public abstract class AbstracBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt;在这个签名中，子类型B是其符类型的一个类型参数，因此可以返回到运行实例的引用以支持方法的链式调用。Bootstrap在调用bind或者connect方法之前，必须调用如下方法来设置所需的组件：group()、channel()或channelFactory()、handler()，否则会抛出IllegalStateException异常。第十章Netty内置了三种解码器：ByteToMessageDecoder将字节解码为消息，由于远程节点不一定能一次性发送一个完整的消息，所以这个类会对入站数据进行缓冲，直到准备好处理。| 方法 | 描述 || ———————————————————— | ———————————————————— || decode(ChannelHandlerContext ctx, ByteBuf in, Listout) | 该方法必须在子类中实现。decode()方法被调用时将会传入一个包含了传入数据的ByteBuf，以及一个用来添加解码消息的List。对这个方法的调用将会重复进行，直到确定没有新的元素被添加到List，或者该ByteBuf中没有更多可读取的字节时为止。如果该List不为空，那么它的内容将会被传递给ChannelPipeline中的下一个ChannelInboundHandler || decodeLast(ChannelHandlerContext ctx, ByteBuf in, Listout) | Netty提供的默认实现只是简单地调用decode()方法。当Channel的状态变为非活动时，这个方法将会被调用一次。 |123456public class ToIntegerDecoder extends ByteToMessageDecoder&#123; @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception&#123; if(in.readableBytes() &gt;= 4) out.add(in.readInt()); &#125;&#125;对于编码器和解码器来说，一旦消息被编码或者解码，他就会被ReferenceCountUtil.release(msg)调用自动释放，如果需要保留引用以便稍后使用，可以调用ReferenceCountUtil.retain(msg)方法，这将增加该引用计数，防止该消息被释放。ReplayingDecoder是对ByteToMessageDecoder的封装，使得我们不需要调用readableBytes()方法来检查ByteBuf中是否有足够的字节数。如果没有足够的字节可用，ByteBuf的read方法将会抛出一个Error，其将在基类中被捕获并处理。当有更多的数据可供读取时，该decode()方法将会被再次调用。并不是所有的ByteBuf操作都被支持，如果调用了一个不被支持的方法，将会抛出一个异常ReplayingDecoder稍慢于ByteToMessageDecoder如果使用ByteToMessageDecoder不会引入太多的复杂性，就使用它；否则使用ReplayingDecoderMessageToMessageDecoder用于两个消息格式之间进行转换12public abstract class MessageToMessageDecoder&lt;I&gt; extends ChannelInboundAdapter// 参数类型I指定了decode()方法的输入参数msg的类型该类将调用I类的方法进行编码，调用O类的方法进行解码。综合考虑了实现的灵活性和简洁性。由于需要在解码之前在内存中缓存接收到的数据，但数据量太大有可能耗尽可用内存。Netty提供了一个TooLongFrameException异常类，其可由解码器在帧超出指定大小限制时抛出。Netty提供了两种编码器MessageToByteEncoder和MessageToMessage，其使用方法和解码器类似。如果要想把编码和解码集成到一个类中，Netty提供了抽象的编解码器类：ByteToMessageCodec和MessageToMessageCodec，但是这样对编解码组件的可重用性造成了影响。CombinedChannelDuplexHandler类可以整合一个已经实现好的编码器和解码器，其方法签名如下1public class CombinedChannelDuplexHandler &lt;I extends ChannelInboundHandler, O extends ChannelOutboundHandler&gt;第十一章Netty内置的Http协议编解码器名称描述HttpRequestEncoder将HttpRequest，HttpContent和LastHttpContent消息编码为字节HttpResponseEncoder将HttpResponse，HttpContent和LastHttpContent消息解码为字节HttpRequestDecoder将字节解码为HttpRequest，HttpContent和LastHttpContent消息HttpResponseDecoder将字节解码为HttpResponse，HttpContent和LastHttpContent消息HttpObjectAggregator将多个消息部分合并为FullHttpRequest或者FullHttpResponse消息HttpContentCompressor用来压缩Http的request或response用于空闲连接及超时的ChannelHandler名称描述IdleStateHandler当连接空闲时间太长时，将会触发一个IdleStateEvent事件。可以通过在自定义的ChannelInboundHandler中重写userEventTriggered()方法来处理该IdleStateEvent事件ReadTimeoutHandler如果在指定的时间间隔没有收到任何的入站数据，则抛出一个ReadTimeoutException并关闭对应的Channel。可以通过重写ChannelHandler中的exceptionCaught()方法来检测该ReadTimeoutExceptionWriteTimeoutHandler如果在指定的时间间隔没有任何入站数据写入，则抛出一个WriteTimeoutException并关闭对应的Channel。可以通过重写ChannelHandler中的exceptionCaugh()方法检测该WriteTimeoutException基于分隔符的解码器名称描述LineBasedFrameDecoder提取由行尾符（\n或者\r\n）分隔的帧的解码器DelimiterBasedFrameDecoder使用任何由用户提供的分割符来提取帧的通用解码器基于长度的解码器名称描述FixedLengthFrameDecoder提取在调用构造函数时指定的定长帧LengthFieldBasedFrameDecoder根据编码进帧头部中的长度值提取帧，该类接收三个参数，分别用于指定maxFrameLength(帧最大长度)、lengthFieldOffset(长度字段偏移量)、lengthFieldLength(长度字段的长度)Protocol Buffers编解码器名称描述ProtobufDecoder使用protobuf对消息进行解码ProtobufEncoder使用protobuf对消息进行编码ProtobufVarint32FrameDecoder根据消息中的Google Protocol Buffers的“Base 128 Varints”整形长度字段值动态的分割所接收到的ByteBufProtobufVarint32LengthFieldPrepender向Bytebuf前追加一个Google Protocol Buffers的“Base 128Varints”整形的长度字段]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop NameNode 高可用 (High Availability) 实现解析.md]]></title>
    <url>%2Fposts%2F523baf91%2F</url>
    <content type="text"><![CDATA[NameNode 高可用整体架构概述在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。HDFS NameNode 和 YARN ResourceManger 的高可用 (High Availability，HA) 方案基本类似，两者也复用了部分代码，但是由于 HDFS NameNode 对于数据存储和数据一致性的要求比 YARN ResourceManger 高得多，所以 HDFS NameNode 的高可用实现更为复杂一些，本文从内部实现的角度对 HDFS NameNode 的高可用机制进行详细的分析。HDFS NameNode 的高可用整体架构如图 1 所示 (图片来源于参考文献 [1])：图 1.HDFS NameNode 高可用整体架构从上图中，我们可以看出 NameNode 的高可用架构主要分为下面几个部分：Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。Zookeeper 集群：为主备切换控制器提供主备选举支持。共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。下面开始分别介绍 NameNode 的主备切换实现和共享存储系统的实现，在文章的最后会结合笔者的实践介绍一下在 NameNode 的高可用运维中的一些注意事项。NameNode 的主备切换实现NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现：ZKFailoverController 作为 NameNode 机器上一个独立的进程启动 (在 hdfs 启动脚本之中的进程名为 zkfc)，启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举。ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。NameNode 实现主备切换的流程如图 2 所示，有以下几步：HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调 ZKFailoverController 注册的相应方法进行处理。如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。图 2.NameNode 的主备切换流程下面分别对 HealthMonitor、ActiveStandbyElector 和 ZKFailoverController 的实现细节进行分析：HealthMonitor 实现分析ZKFailoverController 在初始化的时候会创建 HealthMonitor，HealthMonitor 在内部会启动一个线程来循环调用 NameNode 的 HAServiceProtocol RPC 接口的方法来检测 NameNode 的状态，并将状态的变化通过回调的方式来通知 ZKFailoverController。HealthMonitor 主要检测 NameNode 的两类状态，分别是 HealthMonitor.State 和 HAServiceStatus。HealthMonitor.State 是通过 HAServiceProtocol RPC 接口的 monitorHealth 方法来获取的，反映了 NameNode 节点的健康状况，主要是磁盘存储资源是否充足。HealthMonitor.State 包括下面几种状态：INITIALIZING：HealthMonitor 在初始化过程中，还没有开始进行健康状况检测；SERVICE_HEALTHY：NameNode 状态正常；SERVICE_NOT_RESPONDING：调用 NameNode 的 monitorHealth 方法调用无响应或响应超时；SERVICE_UNHEALTHY：NameNode 还在运行，但是 monitorHealth 方法返回状态不正常，磁盘存储资源不足；HEALTH_MONITOR_FAILED：HealthMonitor 自己在运行过程中发生了异常，不能继续检测 NameNode 的健康状况，会导致 ZKFailoverController 进程退出；HealthMonitor.State 在状态检测之中起主要的作用，在 HealthMonitor.State 发生变化的时候，HealthMonitor 会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。而 HAServiceStatus 则是通过 HAServiceProtocol RPC 接口的 getServiceStatus 方法来获取的，主要反映的是 NameNode 的 HA 状态，包括：INITIALIZING：NameNode 在初始化过程中；ACTIVE：当前 NameNode 为主 NameNode；STANDBY：当前 NameNode 为备 NameNode；STOPPING：当前 NameNode 已停止；HAServiceStatus 在状态检测之中只是起辅助的作用，在 HAServiceStatus 发生变化时，HealthMonitor 也会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。ActiveStandbyElector 实现分析Namenode(包括 YARN ResourceManager) 的主备选举是通过 ActiveStandbyElector 来完成的，ActiveStandbyElector 主要是利用了 Zookeeper 的写一致性和临时节点机制，具体的主备选举实现如下：创建锁节点如果 HealthMonitor 检测到对应的 NameNode 的状态正常，那么表示这个 NameNode 有资格参加 Zookeeper 的主备选举。如果目前还没有进行过主备选举的话，那么相应的 ActiveStandbyElector 就会发起一次主备选举，尝试在 Zookeeper 上创建一个路径为/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 的临时节点 (${dfs.nameservices} 为 Hadoop 的配置参数 dfs.nameservices 的值，下同)，Zookeeper 的写一致性会保证最终只会有一个 ActiveStandbyElector 创建成功，那么创建成功的 ActiveStandbyElector 对应的 NameNode 就会成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Active 状态。而创建失败的 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Standby 状态。注册 Watcher 监听不管创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点是否成功，ActiveStandbyElector 随后都会向 Zookeeper 注册一个 Watcher 来监听这个节点的状态变化事件，ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件。自动触发主备选举如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock，这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。防止脑裂Zookeeper 在工程实践的过程中经常会发生的一个现象就是 Zookeeper 客户端“假死”，所谓的“假死”是指如果 Zookeeper 客户端机器负载过高或者正在进行 JVM Full GC，那么可能会导致 Zookeeper 客户端到 Zookeeper 服务端的心跳不能正常发出，一旦这个时间持续较长，超过了配置的 Zookeeper Session Timeout 参数的话，Zookeeper 服务端就会认为客户端的 session 已经过期从而将客户端的 Session 关闭。“假死”有可能引起分布式系统常说的双主或脑裂 (brain-split) 现象。具体到本文所述的 NameNode，假设 NameNode1 当前为 Active 状态，NameNode2 当前为 Standby 状态。如果某一时刻 NameNode1 对应的 ZKFailoverController 进程发生了“假死”现象，那么 Zookeeper 服务端会认为 NameNode1 挂掉了，根据前面的主备切换逻辑，NameNode2 会替代 NameNode1 进入 Active 状态。但是此时 NameNode1 可能仍然处于 Active 状态正常运行，即使随后 NameNode1 对应的 ZKFailoverController 因为负载下降或者 Full GC 结束而恢复了正常，感知到自己和 Zookeeper 的 Session 已经关闭，但是由于网络的延迟以及 CPU 线程调度的不确定性，仍然有可能会在接下来的一段时间窗口内 NameNode1 认为自己还是处于 Active 状态。这样 NameNode1 和 NameNode2 都处于 Active 状态，都可以对外提供服务。这种情况对于 NameNode 这类对数据一致性要求非常高的系统来说是灾难性的，数据会发生错乱且无法恢复。Zookeeper 社区对这种问题的解决方法叫做 fencing，中文翻译为隔离，也就是想办法把旧的 Active NameNode 隔离起来，使它不能正常对外提供服务。ActiveStandbyElector 为了实现 fencing，会在成功创建 Zookeeper 节点 hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 从而成为 Active NameNode 之后，创建另外一个路径为/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 的持久节点，这个节点里面保存了这个 Active NameNode 的地址信息。Active NameNode 的 ActiveStandbyElector 在正常的状态下关闭 Zookeeper Session 的时候 (注意由于/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 是临时节点，也会随之删除)，会一起删除节点/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb。但是如果 ActiveStandbyElector 在异常的状态下 Zookeeper Session 关闭 (比如前述的 Zookeeper 假死)，那么由于/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 是持久节点，会一直保留下来。后面当另一个 NameNode 选主成功之后，会注意到上一个 Active NameNode 遗留下来的这个节点，从而会回调 ZKFailoverController 的方法对旧的 Active NameNode 进行 fencing，具体处理见后文 ZKFailoverController 部分所述。ZKFailoverController 实现分析ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调函数，ZKFailoverController 的处理逻辑主要靠 HealthMonitor 和 ActiveStandbyElector 的回调函数来驱动。对 HealthMonitor 状态变化的处理如前所述，HealthMonitor 会检测 NameNode 的两类状态，HealthMonitor.State 在状态检测之中起主要的作用，ZKFailoverController 注册到 HealthMonitor 上的处理 HealthMonitor.State 状态变化的回调函数主要关注 SERVICE_HEALTHY、SERVICE_NOT_RESPONDING 和 SERVICE_UNHEALTHY 这 3 种状态：如果检测到状态为 SERVICE_HEALTHY，表示当前的 NameNode 有资格参加 Zookeeper 的主备选举，如果目前还没有进行过主备选举的话，ZKFailoverController 会调用 ActiveStandbyElector 的 joinElection 方法发起一次主备选举。如果检测到状态为 SERVICE_NOT_RESPONDING 或者是 SERVICE_UNHEALTHY，就表示当前的 NameNode 出现问题了，ZKFailoverController 会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举，这样其它的 NameNode 就有机会成为主 NameNode。而 HAServiceStatus 在状态检测之中仅起辅助的作用，在 HAServiceStatus 发生变化时，ZKFailoverController 注册到 HealthMonitor 上的处理 HAServiceStatus 状态变化的回调函数会判断 NameNode 返回的 HAServiceStatus 和 ZKFailoverController 所期望的是否一致，如果不一致的话，ZKFailoverController 也会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举。对 ActiveStandbyElector 主备选举状态变化的处理在 ActiveStandbyElector 的主备选举状态发生变化时，会回调 ZKFailoverController 注册的回调函数来进行相应的处理：如果 ActiveStandbyElector 选主成功，那么 ActiveStandbyElector 对应的 NameNode 成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeActive 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToActive 方法，将 NameNode 转换为 Active 状态。如果 ActiveStandbyElector 选主失败，那么 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeStandby 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，将 NameNode 转换为 Standby 状态。如果 ActiveStandbyElector 选主成功之后，发现了上一个 Active NameNode 遗留下来的/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 节点 (见“ActiveStandbyElector 实现分析”一节“防止脑裂”部分所述)，那么 ActiveStandbyElector 会首先回调 ZKFailoverController 注册的 fenceOldActive 方法，尝试对旧的 Active NameNode 进行 fencing，在进行 fencing 的时候，会执行以下的操作：首先尝试调用这个旧 Active NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，看能不能把它转换为 Standby 状态。如果 transitionToStandby 方法调用失败，那么就执行 Hadoop 配置文件之中预定义的隔离措施，Hadoop 目前主要提供两种隔离措施，通常会选择 sshfence：sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死；shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离；只有在成功地执行完成 fencing 之后，选主成功的 ActiveStandbyElector 才会回调 ZKFailoverController 的 becomeActive 方法将对应的 NameNode 转换为 Active 状态，开始对外提供服务。NameNode 的共享存储实现过去几年中 Hadoop 社区涌现过很多的 NameNode 共享存储方案，比如 shared NAS+NFS、BookKeeper、BackupNode 和 QJM(Quorum Journal Manager) 等等。目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现，本部分只针对基于 QJM 的共享存储方案的内部实现原理进行分析。为了理解 QJM 的设计和实现，首先要对 NameNode 的元数据存储结构有所了解。NameNode 的元数据存储概述一个典型的 NameNode 的元数据存储目录结构如图 3 所示 (图片来源于参考文献 [4])，这里主要关注其中的 EditLog 文件和 FSImage 文件：图 3 .NameNode 的元数据存储目录结构NameNode 在执行 HDFS 客户端提交的创建文件或者移动文件这样的写操作的时候，会首先把这些操作记录在 EditLog 文件之中，然后再更新内存中的文件系统镜像。内存中的文件系统镜像用于 NameNode 向客户端提供读服务，而 EditLog 仅仅只是在数据恢复的时候起作用。记录在 EditLog 之中的每一个操作又称为一个事务，每个事务有一个整数形式的事务 id 作为编号。EditLog 会被切割为很多段，每一段称为一个 Segment。正在写入的 EditLog Segment 处于 in-progress 状态，其文件名形如 edits_inprogress_${start_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，例如上图中的 edits_inprogress_0000000000000000020。而已经写入完成的 EditLog Segment 处于 finalized 状态，其文件名形如 edits_${start_txid}-${end_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，${end_txid} 表示这个 segment 的结束事务 id，例如上图中的 edits_0000000000000000001-0000000000000000019。NameNode 会定期对内存中的文件系统镜像进行 checkpoint 操作，在磁盘上生成 FSImage 文件，FSImage 文件的文件名形如 fsimage_${end_txid}，其中${end_txid} 表示这个 fsimage 文件的结束事务 id，例如上图中的 fsimage_0000000000000000020。在 NameNode 启动的时候会进行数据恢复，首先把 FSImage 文件加载到内存中形成文件系统镜像，然后再把 EditLog 之中 FsImage 的结束事务 id 之后的 EditLog 回放到这个文件系统镜像上。基于 QJM 的共享存储系统的总体架构基于 QJM 的共享存储系统主要用于保存 EditLog，并不保存 FSImage 文件。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法 (参见参考文献 [3])，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。基于 QJM 的共享存储系统的内部实现架构图如图 4 所示，主要包含下面几个主要的组件：图 4 . 基于 QJM 的共享存储系统的内部实现架构图FSEditLog：这个类封装了对 EditLog 的所有操作，是 NameNode 对 EditLog 的所有操作的入口。JournalSet： 这个类封装了对本地磁盘和 JournalNode 集群上的 EditLog 的操作，内部包含了两类 JournalManager，一类为 FileJournalManager，用于实现对本地磁盘上 EditLog 的操作。一类为 QuorumJournalManager，用于实现对 JournalNode 集群上共享目录的 EditLog 的操作。FSEditLog 只会调用 JournalSet 的相关方法，而不会直接使用 FileJournalManager 和 QuorumJournalManager。FileJournalManager：封装了对本地磁盘上的 EditLog 文件的操作，不仅 NameNode 在向本地磁盘上写入 EditLog 的时候使用 FileJournalManager，JournalNode 在向本地磁盘写入 EditLog 的时候也复用了 FileJournalManager 的代码和逻辑。QuorumJournalManager：封装了对 JournalNode 集群上的 EditLog 的操作，它会根据 JournalNode 集群的 URI 创建负责与 JournalNode 集群通信的类 AsyncLoggerSet， QuorumJournalManager 通过 AsyncLoggerSet 来实现对 JournalNode 集群上的 EditLog 的写操作，对于读操作，QuorumJournalManager 则是通过 Http 接口从 JournalNode 上的 JournalNodeHttpServer 读取 EditLog 的数据。AsyncLoggerSet：内部包含了与 JournalNode 集群进行通信的 AsyncLogger 列表，每一个 AsyncLogger 对应于一个 JournalNode 节点，另外 AsyncLoggerSet 也包含了用于等待大多数 JournalNode 返回结果的工具类方法给 QuorumJournalManager 使用。AsyncLogger：具体的实现类是 IPCLoggerChannel，IPCLoggerChannel 在执行方法调用的时候，会把调用提交到一个单线程的线程池之中，由线程池线程来负责向对应的 JournalNode 的 JournalNodeRpcServer 发送 RPC 请求。JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。下面对基于 QJM 的共享存储系统的两个关键性问题同步数据和恢复数据进行详细分析。基于 QJM 的共享存储系统的数据同步机制分析Active NameNode 和 StandbyNameNode 使用 JouranlNode 集群来进行数据同步的过程如图 5 所示，Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog：图 5 . 基于 QJM 的共享存储的数据同步机制Active NameNode 提交 EditLog 到 JournalNode 集群当处于 Active 状态的 NameNode 调用 FSEditLog 类的 logSync 方法来提交 EditLog 的时候，会通过 JouranlSet 同时向本地磁盘目录和 JournalNode 集群上的共享存储目录写入 EditLog。写入 JournalNode 集群是通过并行调用每一个 JournalNode 的 QJournalProtocol RPC 接口的 journal 方法实现的，如果对大多数 JournalNode 的 journal 方法调用成功，那么就认为提交 EditLog 成功，否则 NameNode 就会认为这次提交 EditLog 失败。提交 EditLog 失败会导致 Active NameNode 关闭 JournalSet 之后退出进程，留待处于 Standby 状态的 NameNode 接管之后进行数据恢复。从上面的叙述可以看出，Active NameNode 提交 EditLog 到 JournalNode 集群的过程实际上是同步阻塞的，但是并不需要所有的 JournalNode 都调用成功，只要大多数 JournalNode 调用成功就可以了。如果无法形成大多数，那么就认为提交 EditLog 失败，NameNode 停止服务退出进程。如果对应到分布式系统的 CAP 理论的话，虽然采用了 Paxos 的“大多数”思想对 C(consistency，一致性) 和 A(availability，可用性) 进行了折衷，但还是可以认为 NameNode 选择了 C 而放弃了 A，这也符合 NameNode 对数据一致性的要求。Standby NameNode 从 JournalNode 集群同步 EditLog当 NameNode 进入 Standby 状态之后，会启动一个 EditLogTailer 线程。这个线程会定期调用 EditLogTailer 类的 doTailEdits 方法从 JournalNode 集群上同步 EditLog，然后把同步的 EditLog 回放到内存之中的文件系统镜像上 (并不会同时把 EditLog 写入到本地磁盘上)。这里需要关注的是：从 JournalNode 集群上同步的 EditLog 都是处于 finalized 状态的 EditLog Segment。“NameNode 的元数据存储概述”一节说过 EditLog Segment 实际上有两种状态，处于 in-progress 状态的 Edit Log 当前正在被写入，被认为是处于不稳定的中间态，有可能会在后续的过程之中发生修改，比如被截断。Active NameNode 在完成一个 EditLog Segment 的写入之后，就会向 JournalNode 集群发送 finalizeLogSegment RPC 请求，将完成写入的 EditLog Segment finalized，然后开始下一个新的 EditLog Segment。一旦 finalizeLogSegment 方法在大多数的 JournalNode 上调用成功，表明这个 EditLog Segment 已经在大多数的 JournalNode 上达成一致。一个 EditLog Segment 处于 finalized 状态之后，可以保证它再也不会变化。从上面描述的过程可以看出，虽然 Active NameNode 向 JournalNode 集群提交 EditLog 是同步的，但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。基于 QJM 的共享存储系统的数据恢复机制分析处于 Standby 状态的 NameNode 转换为 Active 状态的时候，有可能上一个 Active NameNode 发生了异常退出，那么 JournalNode 集群中各个 JournalNode 上的 EditLog 就可能会处于不一致的状态，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 EditLog 恢复为一致。另外如前所述，当前处于 Standby 状态的 NameNode 的内存中的文件系统镜像有很大的可能是落后于旧的 Active NameNode 的，所以在 JournalNode 集群中各个节点上的 EditLog 达成一致之后，接下来要做的事情就是从 JournalNode 集群上补齐落后的 EditLog。只有在这两步完成之后，当前新的 Active NameNode 才能安全地对外提供服务。补齐落后的 EditLog 的过程复用了前面描述的 Standby NameNode 从 JournalNode 集群同步 EditLog 的逻辑和代码，最终调用 EditLogTailer 类的 doTailEdits 方法来完成 EditLog 的补齐。使 JournalNode 集群上的 EditLog 达成一致的过程是一致性算法 Paxos 的典型应用场景，QJM 对这部分的处理可以看做是 Single Instance Paxos(参见参考文献 [3]) 算法的一个实现，在达成一致的过程中，Active NameNode 和 JournalNode 集群之间的交互流程如图 6 所示，具体描述如下：图 6.Active NameNode 和 JournalNode 集群的交互流程图生成一个新的 EpochEpoch 是一个单调递增的整数，用来标识每一次 Active NameNode 的生命周期，每发生一次 NameNode 的主备切换，Epoch 就会加 1。这实际上是一种 fencing 机制，为什么需要 fencing 已经在前面“ActiveStandbyElector 实现分析”一节的“防止脑裂”部分进行了说明。产生新 Epoch 的流程与 Zookeeper 的 ZAB(Zookeeper Atomic Broadcast) 协议在进行数据恢复之前产生新 Epoch 的过程完全类似：Active NameNode 首先向 JournalNode 集群发送 getJournalState RPC 请求，每个 JournalNode 会返回自己保存的最近的那个 Epoch(代码中叫 lastPromisedEpoch)。NameNode 收到大多数的 JournalNode 返回的 Epoch 之后，在其中选择最大的一个加 1 作为当前的新 Epoch，然后向各个 JournalNode 发送 newEpoch RPC 请求，把这个新的 Epoch 发给各个 JournalNode。每一个 JournalNode 在收到新的 Epoch 之后，首先检查这个新的 Epoch 是否比它本地保存的 lastPromisedEpoch 大，如果大的话就把 lastPromisedEpoch 更新为这个新的 Epoch，并且向 NameNode 返回它自己的本地磁盘上最新的一个 EditLogSegment 的起始事务 id，为后面的数据恢复过程做好准备。如果小于或等于的话就向 NameNode 返回错误。NameNode 收到大多数 JournalNode 对 newEpoch 的成功响应之后，就会认为生成新的 Epoch 成功。在生成新的 Epoch 之后，每次 NameNode 在向 JournalNode 集群提交 EditLog 的时候，都会把这个 Epoch 作为参数传递过去。每个 JournalNode 会比较传过来的 Epoch 和它自己保存的 lastPromisedEpoch 的大小，如果传过来的 epoch 的值比它自己保存的 lastPromisedEpoch 小的话，那么这次写相关操作会被拒绝。一旦大多数 JournalNode 都拒绝了这次写操作，那么这次写操作就失败了。如果原来的 Active NameNode 恢复正常之后再向 JournalNode 写 EditLog，那么因为它的 Epoch 肯定比新生成的 Epoch 小，并且大多数的 JournalNode 都接受了这个新生成的 Epoch，所以拒绝写入的 JournalNode 数目至少是大多数，这样原来的 Active NameNode 写 EditLog 就肯定会失败，失败之后这个 NameNode 进程会直接退出，这样就实现了对原来的 Active NameNode 的隔离了。选择需要数据恢复的 EditLog Segment 的 id需要恢复的 Edit Log 只可能是各个 JournalNode 上的最后一个 Edit Log Segment，如前所述，JournalNode 在处理完 newEpoch RPC 请求之后，会向 NameNode 返回它自己的本地磁盘上最新的一个 EditLog Segment 的起始事务 id，这个起始事务 id 实际上也作为这个 EditLog Segment 的 id。NameNode 会在所有这些 id 之中选择一个最大的 id 作为要进行数据恢复的 EditLog Segment 的 id。向 JournalNode 集群发送 prepareRecovery RPC 请求NameNode 接下来向 JournalNode 集群发送 prepareRecovery RPC 请求，请求的参数就是选出的 EditLog Segment 的 id。JournalNode 收到请求后返回本地磁盘上这个 Segment 的起始事务 id、结束事务 id 和状态 (in-progress 或 finalized)。这一步对应于 Paxos 算法的 Phase 1a 和 Phase 1b(参见参考文献 [3]) 两步。Paxos 算法的 Phase1 是 prepare 阶段，这也与方法名 prepareRecovery 相对应。并且这里以前面产生的新的 Epoch 作为 Paxos 算法中的提案编号 (proposal number)。只要大多数的 JournalNode 的 prepareRecovery RPC 调用成功返回，NameNode 就认为成功。选择进行同步的基准数据源，向 JournalNode 集群发送 acceptRecovery RPC 请求 NameNode 根据 prepareRecovery 的返回结果，选择一个 JournalNode 上的 EditLog Segment 作为同步的基准数据源。选择基准数据源的原则大致是：在 in-progress 状态和 finalized 状态的 Segment 之间优先选择 finalized 状态的 Segment。如果都是 in-progress 状态的话，那么优先选择 Epoch 比较高的 Segment(也就是优先选择更新的)，如果 Epoch 也一样，那么优先选择包含的事务数更多的 Segment。在选定了同步的基准数据源之后，NameNode 向 JournalNode 集群发送 acceptRecovery RPC 请求，将选定的基准数据源作为参数。JournalNode 接收到 acceptRecovery RPC 请求之后，从基准数据源 JournalNode 的 JournalNodeHttpServer 上下载 EditLog Segment，将本地的 EditLog Segment 替换为下载的 EditLog Segment。这一步对应于 Paxos 算法的 Phase 2a 和 Phase 2b(参见参考文献 [3]) 两步。Paxos 算法的 Phase2 是 accept 阶段，这也与方法名 acceptRecovery 相对应。只要大多数 JournalNode 的 acceptRecovery RPC 调用成功返回，NameNode 就认为成功。向 JournalNode 集群发送 finalizeLogSegment RPC 请求，数据恢复完成上一步执行完成之后，NameNode 确认大多数 JournalNode 上的 EditLog Segment 已经从基准数据源进行了同步。接下来，NameNode 向 JournalNode 集群发送 finalizeLogSegment RPC 请求，JournalNode 接收到请求之后，将对应的 EditLog Segment 从 in-progress 状态转换为 finalized 状态，实际上就是将文件名从 edits_inprogress_${startTxid} 重命名为 edits_${startTxid}-${endTxid}，见“NameNode 的元数据存储概述”一节的描述。只要大多数 JournalNode 的 finalizeLogSegment RPC 调用成功返回，NameNode 就认为成功。此时可以保证 JournalNode 集群的大多数节点上的 EditLog 已经处于一致的状态，这样 NameNode 才能安全地从 JournalNode 集群上补齐落后的 EditLog 数据。需要注意的是，尽管基于 QJM 的共享存储方案看起来理论完备，设计精巧，但是仍然无法保证数据的绝对强一致，下面选取参考文献 [2] 中的一个例子来说明：假设有 3 个 JournalNode：JN1、JN2 和 JN3，Active NameNode 发送了事务 id 为 151、152 和 153 的 3 个事务到 JournalNode 集群，这 3 个事务成功地写入了 JN2，但是在还没能写入 JN1 和 JN3 之前，Active NameNode 就宕机了。同时，JN3 在整个写入的过程中延迟较大，落后于 JN1 和 JN2。最终成功写入 JN1 的事务 id 为 150，成功写入 JN2 的事务 id 为 153，而写入到 JN3 的事务 id 仅为 125，如图 7 所示 (图片来源于参考文献 [2])。按照前面描述的只有成功地写入了大多数的 JournalNode 才认为写入成功的原则，显然事务 id 为 151、152 和 153 的这 3 个事务只能算作写入失败。在进行数据恢复的过程中，会发生下面两种情况：图 7.JournalNode 集群写入的事务 id 情况如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段收到了 JN2 的回复，那么肯定会以 JN2 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 153。从恢复的结果来看，实际上可以认为前面宕机的 Active NameNode 对事务 id 为 151、152 和 153 的这 3 个事务的写入成功了。但是如果从 NameNode 自身的角度来看，这显然就发生了数据不一致的情况。如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段没有收到 JN2 的回复，那么肯定会以 JN1 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 150。在这种情况下，如果从 NameNode 自身的角度来看的话，数据就是一致的了。事实上不光本文描述的基于 QJM 的共享存储方案无法保证数据的绝对一致，大家通常认为的一致性程度非常高的 Zookeeper 也会发生类似的情况，这也从侧面说明了要实现一个数据绝对一致的分布式存储系统的确非常困难。NameNode 在进行状态转换时对共享存储的处理下面对 NameNode 在进行状态转换的过程中对共享存储的处理进行描述，使得大家对基于 QJM 的共享存储方案有一个完整的了解，同时也作为本部分的总结。NameNode 初始化启动，进入 Standby 状态在 NameNode 以 HA 模式启动的时候，NameNode 会认为自己处于 Standby 模式，在 NameNode 的构造函数中会加载 FSImage 文件和 EditLog Segment 文件来恢复自己的内存文件系统镜像。在加载 EditLog Segment 的时候，调用 FSEditLog 类的 initSharedJournalsForRead 方法来创建只包含了在 JournalNode 集群上的共享目录的 JournalSet，也就是说，这个时候只会从 JournalNode 集群之中加载 EditLog，而不会加载本地磁盘上的 EditLog。另外值得注意的是，加载的 EditLog Segment 只是处于 finalized 状态的 EditLog Segment，而处于 in-progress 状态的 Segment 需要后续在切换为 Active 状态的时候，进行一次数据恢复过程，将 in-progress 状态的 Segment 转换为 finalized 状态的 Segment 之后再进行读取。加载完 FSImage 文件和共享目录上的 EditLog Segment 文件之后，NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式。如前所述，EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog。而 StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点。NameNode 从 Standby 状态切换为 Active 状态当 NameNode 从 Standby 状态切换为 Active 状态的时候，首先需要做的就是停止它在 Standby 状态的时候启动的线程和相关的服务，包括上面提到的 EditLogTailer 线程和 StandbyCheckpointer 线程，然后关闭用于读取 JournalNode 集群的共享目录上的 EditLog 的 JournalSet，接下来会调用 FSEditLog 的 initJournalSetForWrite 方法重新打开 JournalSet。不同的是，这个 JournalSet 内部同时包含了本地磁盘目录和 JournalNode 集群上的共享目录。这些工作完成之后，就开始执行“基于 QJM 的共享存储系统的数据恢复机制分析”一节所描述的流程，调用 FSEditLog 类的 recoverUnclosedStreams 方法让 JournalNode 集群中各个节点上的 EditLog 达成一致。然后调用 EditLogTailer 类的 catchupDuringFailover 方法从 JournalNode 集群上补齐落后的 EditLog。最后打开一个新的 EditLog Segment 用于新写入数据，同时启动 Active NameNode 所需要的线程和服务。NameNode 从 Active 状态切换为 Standby 状态当 NameNode 从 Active 状态切换为 Standby 状态的时候，首先需要做的就是停止它在 Active 状态的时候启动的线程和服务，然后关闭用于读取本地磁盘目录和 JournalNode 集群上的共享目录的 EditLog 的 JournalSet。接下来会调用 FSEditLog 的 initSharedJournalsForRead 方法重新打开用于读取 JournalNode 集群上的共享目录的 JournalSet。这些工作完成之后，就会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，EditLogTailer 线程会定时从 JournalNode 集群上同步 Edit Log。NameNode 高可用运维中的注意事项本节结合笔者的实践，从初始化部署和日常运维两个方面介绍一些在 NameNode 高可用运维中的注意事项。初始化部署如果在开始部署 Hadoop 集群的时候就启用 NameNode 的高可用的话，那么相对会比较容易。但是如果在采用传统的单 NameNode 的架构运行了一段时间之后，升级为 NameNode 的高可用架构的话，就要特别注意在升级的时候需要按照以下的步骤进行操作：对 Zookeeper 进行初始化，创建 Zookeeper 上的/hadoop-ha/${dfs.nameservices} 节点。创建节点是为随后通过 Zookeeper 进行主备选举做好准备，在进行主备选举的时候会在这个节点下面创建子节点 (具体可参照“ActiveStandbyElector 实现分析”一节的叙述)。这一步通过在原有的 NameNode 上执行命令 hdfs zkfc -formatZK 来完成。启动所有的 JournalNode，这通过脚本命令 hadoop-daemon.sh start journalnode 来完成。对 JouranlNode 集群的共享存储目录进行格式化，并且将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件 (具体可参照“NameNode 的元数据存储概述”一节的叙述) 之后的 EditLog 拷贝到 JournalNode 集群上的共享目录之中，这通过在原有的 NameNode 上执行命令 hdfs namenode -initializeSharedEdits 来完成。启动原有的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。对新增的 NameNode 节点进行初始化，将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件拷贝到这个新增的 NameNode 的本地磁盘上，同时需要验证 JournalNode 集群的共享存储目录上已经具有了这个 FSImage 文件之后的 EditLog(已经在第 3 步完成了)。这一步通过在新增的 NameNode 上执行命令 hdfs namenode -bootstrapStandby 来完成。启动新增的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。在这两个 NameNode 上启动 zkfc(ZKFailoverController) 进程，谁通过 Zookeeper 选主成功，谁就是主 NameNode，另一个为备 NameNode。这通过脚本命令 hadoop-daemon.sh start zkfc 完成。日常维护笔者在日常的维护之中主要遇到过下面两种问题：Zookeeper 过于敏感：Hadoop 的配置项中 Zookeeper 的 session timeout 的配置参数 ha.zookeeper.session-timeout.ms 的默认值为 5000，也就是 5s，这个值比较小，会导致 Zookeeper 比较敏感，可以把这个值尽量设置得大一些，避免因为网络抖动等原因引起 NameNode 进行无谓的主备切换。单台 JouranlNode 故障时会导致主备无法切换：在理论上，如果有 3 台或者更多的 JournalNode，那么挂掉一台 JouranlNode 应该仍然可以进行正常的主备切换。但是笔者在某次 NameNode 重启的时候，正好赶上一台 JournalNode 挂掉宕机了，这个时候虽然某一台 NameNode 通过 Zookeeper 选主成功，但是这台被选为主的 NameNode 无法成功地从 Standby 状态切换为 Active 状态。事后追查原因发现，被选为主的 NameNode 卡在退出 Standby 状态的最后一步，这个时候它需要等待到 JournalNode 的请求全部完成之后才能退出。但是由于有一台 JouranlNode 宕机，到这台 JournalNode 的请求都积压在一起并且在不断地进行重试，同时在 Hadoop 的配置项中重试次数的默认值非常大，所以就会导致被选为主的 NameNode 无法及时退出 Standby 状态。这个问题主要是 Hadoop 内部的 RPC 通信框架的设计缺陷引起的，Hadoop HA 的源代码 IPCLoggerChannel 类中有关于这个问题的 TODO，但是截止到社区发布的 2.7.1 版本这个问题仍然存在。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>分布式存储</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Manjaro安装配置]]></title>
    <url>%2Fposts%2F33ff7b7%2F</url>
    <content type="text"><![CDATA[0. 安装启动时选择第二项boot（non-free),Manjaro自带的驱动精灵会帮你安装好所需驱动，笔记本双显卡则会帮你安装bumblebeedriver boot（non-free)如果是WIndows+Manjaro双系统安装，步骤可以参考：https://my.oschina.net/langxSpirit/blog/16333841.系统信息查看系统信息1inxi -Fx2.网络设置查看网络状态1ping 8.8.8.8-———–connect: Network is unreachable-———–如果网卡驱动是正常，请尝试手动设置IP地址、网关、DNS信息3.笔记本双显卡设置查看显卡NVIDIA状态1lspci| grep -i vga01:00.0 VGA compatible controller: NVIDIA Corporation GK107M [GeForce GTX 660M] (rev ff)Nvidia 卡信息的末尾是 rev ff，表示独显已经关闭。现在运行的是intel核显，这正是我们安装bumblebee目的。bumblebee的作用是禁用nvidia独立显卡，需要使用独显时，使用”optirun 程序名“手动开启nvidia来运行需要加速的程序，如optirun vmware。https://wiki.archlinux.org/index.php/Bumblebeehttps://wiki.archlinux.org/index.php/Bumblebee_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)要使用 Bumblebee，请确保添加你的用户到 bumblebee 组：$ gpasswd -a svenaugustus bumblebee #gpasswd -a 您的用户名 bumblebee启用服务：1systemctl enable bumblebeed.service重启测试 Bumblebee 是否工作：1optirun glxgears -info如果一个内有动画的窗口出现，那么 Optimus 和 Bumblebee 正在工作。-—————–NVIDIA(0): Failed to assign any connected display devices to X screen 0如果终端输出如下:[ERROR]Cannot access secondary GPU - error: [XORG] (EE) NVIDIA(0): Failed to assign any connected display devices to X screen 0[ERROR]Aborting because fallback start is disabled.你要修改 /etc/bumblebee/xorg.conf.nvidia 里的这行:Option “ConnectedMonitor” “DFP”为:Option “ConnectedMonitor” “CRT”-—————–打开N卡设置：1optirun nvidia-settings -c :8如果需要不依赖Bumblebee来使用CUDA, 为开启NVIDIA显卡，运行:1sudo tee /proc/acpi/bbswitch &lt;&lt;&lt; ON注意，重启完N卡又会回复关闭状态。4.时间和日期如果安装的是双系统，注意Manjaro Setting Manager &gt; Time and Date勾选以下选项–set time and date automatically–hardware clock in local time zoneIf you has Windows as well, please install NTP. http://www.satsignal.eu/ntp/setup.htmlTips: NTP server ,please select your nearest country or region from the drop-down list.Here are some links in chinese: http://blog.csdn.net/aaazz47/article/details/78696899#如果你装了双系统，那么Windows系统需要装NTP同步为UTC时间，或者委屈Manjaro使用本地时间localtime。5.源镜像与系统更新排列源1sudo pacman-mirrors -i -c China -m rank #只留下清华源能令带宽跑满同步并优化（类似磁盘整理，固态硬盘无需操作）$ sudo pacman-optimize &amp;&amp; sync增加archlinuxcn库和antergos库1echo -e &quot;\n[archlinuxcn]\nSigLevel = TrustAll\nServer = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/\$arch\n\n[antergos]\nSigLevel = TrustAll\nServer = https://mirrors.tuna.tsinghua.edu.cn/antergos/\$repo/\$arch\n&quot;|sudo tee -a /etc/pacman.conf升级系统：1sudo pacman -Syyu安装archlinuxcn签名钥匙&amp;antergos签名钥匙1sudo pacman -S --noconfirm archlinuxcn-keyring antergos-keyring6.中文输入法安装搜狗输入法#xfce桌面1sudo pacman -S --noconfirm fcitx-im fcitx-configtool fcitx-sogoupinyin安装搜狗输入法#kde桌面1sudo pacman -S --noconfirm fcitx-im kcm-fcitx fcitx-sogoupinyin#配置fcitx1sudo echo -e &quot;export GTK_IM_MODULE=fcitx\nexport QT_IM_MODULE=fcitx\nexport XMODIFIERS=@im=fcitx&quot;&gt;&gt;~/.xprofilethen restart.fcitx的激活输入法方式改为ctrl+逗号,避免jetbrains系列快捷键冲突额外的激活输入法快捷键禁用输入法切换取消,上一页下一页改为逗号句号在窗口间共享状态改为所有(所有的话就是windows的习惯)#对于jetbrians系列fcitx无法跟随的情况 fcitx输入法配置&gt;附加组件&gt;勾选高级&gt;xim前端&gt;勾选on the spot7.中文汉化#切换系统语言为中文，可以在登录界面右下角选择zh_CN.utf8然后重启login screen choose zh_CN.UTF8then restart.1sudo pacman -S --noconfirm firefox-i18n-zh-cn thunderbird-i18n-zh-cn gimp-help-zh_cn libreoffice-still-zh-CN man-pages-zh_cn7-1.火狐汉化https://support.mozilla.org/en-US/kb/use-firefox-interface-other-languages-language-pack安装火狐汉化$ sudo pacman -S firefox-i18n-zh-cn在add-ons检查language是否已包含。如果已包含，在火狐浏览器中敲about:config然后回车。搜索intl.locale.requested如果没有那么右键new一个 键是 intl.locale.requested 值 是 zh_CN。最后重启Firefox,解决。8.中文字体1sudo pacman -S --noconfirm wqy-microhei &amp;&amp; fc-cache -fv安装完可以 在”外观&gt;字体”中设置应用程序的默认字体。可以在”QT5设置&gt;字体”设置qt窗体的默认字体。还可以在各个应用程序中，如notepadqq中设置显示的字体。其他文泉驿家族：$ sudo pacman -S wqy-microhei-lite$ sudo pacman -S wqy-bitmapfont$ sudo pacman -S wqy-zenhei选用：$ sudo pacman -S adobe-source-han-sans-cn-fonts$ sudo pacman -S adobe-source-han-serif-cn-fonts$ sudo pacman -S noto-fonts-cjk9.AUR助手yaourtManjaro有自己的图形化包管理器,pamac，当然也可以命令行使用archlinux系的，还有AUR助手 yaourt 更方便。Yaourt可用于查找软件包(包括[core][extra] [community] AUR的软件包，pacman只能查找非AUR的软件包)。1sudo pacman -S --noconfirm yaourt10.桌面菜单或启动器应用程序配置项，即 .desktop 文件是原信息资源和应用程序快捷图标的集合。系统程序的配置项通常位于 /usr/share/applications 或 /usr/local/share/applications目录，单用户安装的程序位于 ~/.local/share/applications 目录，优先使用用户的配置项。1cd ~/.local/share/applications[Desktop Entry]Type=ApplicationVersion=1.0Name=IntelliJ IDEAExec=/opt/ide/idea/bin/idea.shIcon=/opt/ide/idea/bin/idea.pngTerminal=falseCategories=Development;Languages;Java;11.快速设置系统全面更新1sudo pacman -Syyu --noconfirm登录后开启数字锁1yaourt -S --noconfirm systemd-numlockontty&amp;&amp;sudo systemctl enable numLockOnTty.service安装常用软件1yaourt -Sy --noconfirm netease-cloud-music smplayer smplayer-skins smplayer-themes google-chrome sublime-text-dev-zh-cn masterpdfeditor remarkable uget filezilla shadowsocks-qt5 deepin-screenshot shutternetease-cloud-music 网易云音乐；smplayer 视频播放器；google-chrome 谷歌浏览器；notepadqq 像notepad++文本编辑；sublime-text-dev-zh-cn 强大的开发必备文本编辑器；(有能力采用付费许可证)masterpdfeditor 对linux用户免费的PDF浏览及编辑器，支持实时预览；remarkable 卓越且功能齐全的 Markdown 编辑器；uget 媲美迅雷的下载工具；filezilla 强大的FTP工具；shadowsocks-qt5 翻墙工具，配合浏览器插件SwitchyOmega使用；deepin-screenshot 深度截图工具；shutter 强大的截图工具，gnome-web-photo配合使用；variety 随即更换壁纸的应用；ccal 终端农历日历，终端启动ccal；1yaourt -Sy --noconfirm bleachbit redshiftbleachbit 快速释放磁盘空间并不知疲倦地守卫你的隐私。释放缓存，删除 cookie，清除互联网浏览历史，清理临时文件，删除日志，以及更多功能…i-nex 小而全的系统信息查看软件；redshift 根据你的周边调整你屏幕的色温。当你夜晚在屏幕前工作时，它也许能帮助你减少对眼睛的伤害；1yaourt -Sy --noconfirm keepassx-git screenfetch-git freefilesync #需要网络gitkeepassx-git 密码管理器；screenfetch-git 系统信息工具，终端使用screenfetch命令；freefilesync 文件夹比较和同步工具；生产力1yaourt -Sy --noconfirm wiznote meld goldendict easystroke catfish peekwiznote 为知笔记；meld 文本比较；goldendict 词典软件；easystroke 鼠标手势；catfish 基于GTK+的非常快速，轻量级的文件搜索工具；peek 屏幕录像工具，小巧玲珑，可保存录像为gif动图和兼容于html5的webm视频；1yaourt -Sy --noconfirm xmind #需要网络xmind 跨平台的思维导图工具，关键还是可以导入MindManage的文件；编程开发1yaourt -Sy --noconfirm eclipse-jee jetbrains-toolbox openjdk8-doc openjdk8-src dbeaver dbeaver-plugin-apache-poi dbeaver-plugin-batik dbeaver-plugin-officeeclipse-jee 企业Java 集成开发环境；jetbrains-toolbox 著名的jetbrains序列的IDE管理工具；openjdk8-doc openjdk8-src 针对OpenJDK8的文档和源码；dbeaver 通用数据库客户端，支持多个平台及多种数据库，社区版是免费的；1yaourt -Sy --noconfirm nginx tomcat8 zookeeperdbeaver 通用数据库客户端，支持多个平台及多种数据库，社区版是免费的；nginx 终端执行 sudo nginx 启动，sudo nginx -s stop/realod 停止或重启；tomcat8 开发必备，轻量的应用服务器；zookeeper 终端执行sudo zkServer.sh start 启动；虚拟机（全面更新系统重启后最后安装）1sudo pacman -Sy virtualbox linux414-virtualbox-host-modules virtualbox-ext-oraclevirtualbox 虚拟机工具，linux首选，比vmware还好用。linux414-virtualbox-host-modules 根据安装的内核版本选择，比如有 uname -r 如果是4.14内核，则安装 linux414-virtualbox-host-modules ；展示Linux系统信息(装逼)1screenfetch]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Manjaro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装MySQL]]></title>
    <url>%2Fposts%2Fdf149a46%2F</url>
    <content type="text"><![CDATA[总所周知，MySQL 被 Oracle 收购后，CentOS 的镜像仓库中提供的默认的数据库也变为了 MariaDB，如果想了解 MariaDB 和 CentOS 的区别，可以参考官网介绍，想用 MariaDB 的同学可以参考 MariaDB 安装指南言归正传，在 CentOS 上安装 MySQL 差不多有四个步骤添加 MySQL YUM 源根据自己的操作系统选择合适的安装源，和其他公司一样，总会让大家注册账号获取更新，注意是 Oracle 的账号，如果不想注册，下方有直接下载的地址，下载之后通过 rpm -Uvh 安装。123456789101112131415161718192021$wget 'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm'$sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpm$yum repolist all | grep mysqlmysql-cluster-7.5-community/x86_64 MySQL Cluster 7.5 Community disabledmysql-cluster-7.5-community-source MySQL Cluster 7.5 Community - disabledmysql-cluster-7.6-community/x86_64 MySQL Cluster 7.6 Community disabledmysql-cluster-7.6-community-source MySQL Cluster 7.6 Community - disabledmysql-connectors-community/x86_64 MySQL Connectors Community enabled: 51mysql-connectors-community-source MySQL Connectors Community - disabledmysql-tools-community/x86_64 MySQL Tools Community enabled: 63mysql-tools-community-source MySQL Tools Community - Sourc disabledmysql-tools-preview/x86_64 MySQL Tools Preview disabledmysql-tools-preview-source MySQL Tools Preview - Source disabledmysql55-community/x86_64 MySQL 5.5 Community Server disabledmysql55-community-source MySQL 5.5 Community Server - disabledmysql56-community/x86_64 MySQL 5.6 Community Server disabledmysql56-community-source MySQL 5.6 Community Server - disabledmysql57-community/x86_64 MySQL 5.7 Community Server enabled: 267mysql57-community-source MySQL 5.7 Community Server - disabledmysql80-community/x86_64 MySQL 8.0 Community Server disabledmysql80-community-source MySQL 8.0 Community Server - disabled可以看出该安装源包含了MySQL5.5，5.6，5.7和8.0四个版本，默认安装的是MySQL5.7版本。选择安装版本如果想安装最新版本的，直接使用 yum 命令即可1$sudo yum install mysql-community-server如果想要安装 5.6 版本的，有2个方法。命令行支持 yum-config-manager 命令的话，可以使用如下命令：123456789101112131415161718192021$ sudo dnf config-manager --disable mysql57-community$ sudo dnf config-manager --enable mysql56-community$yum repolist all | grep mysqlmysql-cluster-7.5-community/x86_64 MySQL Cluster 7.5 Community disabledmysql-cluster-7.5-community-source MySQL Cluster 7.5 Community - disabledmysql-cluster-7.6-community/x86_64 MySQL Cluster 7.6 Community disabledmysql-cluster-7.6-community-source MySQL Cluster 7.6 Community - disabledmysql-connectors-community/x86_64 MySQL Connectors Community enabled: 51mysql-connectors-community-source MySQL Connectors Community - disabledmysql-tools-community/x86_64 MySQL Tools Community enabled: 63mysql-tools-community-source MySQL Tools Community - Sourc disabledmysql-tools-preview/x86_64 MySQL Tools Preview disabledmysql-tools-preview-source MySQL Tools Preview - Source disabledmysql55-community/x86_64 MySQL 5.5 Community Server disabledmysql55-community-source MySQL 5.5 Community Server - disabledmysql56-community/x86_64 MySQL 5.6 Community Server enabledmysql56-community-source MySQL 5.6 Community Server - disabledmysql57-community/x86_64 MySQL 5.7 Community Server disabled: 267mysql57-community-source MySQL 5.7 Community Server - disabledmysql80-community/x86_64 MySQL 8.0 Community Server disabledmysql80-community-source MySQL 8.0 Community Server - disabled或者直接修改 /etc/yum.repos.d/mysql-community.repo 这个文件1234567891011121314# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/7/$basearch/enabled=1 #表示当前版本是安装gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/enabled=0 #默认这个是 1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql通过设置 enabled 来决定安装哪个版本。设置好之后使用 yum 安装即可。启动 MySQL 服务启动命令很简单12345678910111213$sudo service mysqld start $sudo systemctl start mysqld #CentOS 7$sudo systemctl status mysqld #检查MySQL运行状态● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sun 2018-06-24 21:23:53 EDT; 20min ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 2776 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 2758 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 2779 (mysqld) CGroup: /system.slice/mysqld.service └─2779 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid说明已经正在运行中了。为了加强安全性，MySQL5.7为root用户随机生成了一个密码，在error log中，关于error log的位置，如果安装的是RPM包，则默认是/var/log/mysqld.log，使用sudo grep ‘temporary password’ / /var/log/mysqld.log查看。使用该密码登录数据库，然后修改密码：12$ mysql -uroot -p #输入查看到的密码mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;MyNewPass4!&apos;;若设置的密码太简单，会报ERROR 1819 (HY000): Your password does not satisfy the current policy requirements错误。如果一定要设置简单密码，需要修改两个全局参数：修改validate_password_policy参数的值mysql&gt; set global validate_password_policy=0;修改密码的长度mysql&gt; set global validate_password_length=1;再次修改密码就可以了。MySQL 5.6 的安全设置由于 5.7 版本在安装的时候就设置好了，不需要额外设置，但是 5.6 版本建议从安全角度完善下，运行官方脚本即可1$ mysql_secure_installation会提示设置5个关键位置设置 root 密码禁止 root 账号远程登录禁止匿名账号（anonymous）登录删除测试库是否确认修改安装第三方组件查看 yum 源中有哪些默认的组件：1$ yum --disablerepo=\* --enablerepo=&apos;mysql*-community*&apos; list available需要安装直接通过 yum 命令安装即可。修改编码在 /etc/my.cnf 中设置默认的编码123456789[client]default-character-set = utf8[mysqld]default-storage-engine = INNODBcharacter-set-server = utf8collation-server = utf8_general_ci #不区分大小写collation-server = utf8_bin #区分大小写collation-server = utf8_unicode_ci #比 utf8_general_ci 更准确创建数据库和用户创建数据库123456CREATE DATABASE &lt;datebasename&gt; CHARACTER SET utf8;CREATE USER &apos;username&apos;@&apos;host&apos; IDENTIFIED BY &apos;password&apos;;GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos;;SHOW GRANTS FOR &apos;username&apos;@&apos;host&apos;;REVOKE privilege ON databasename.tablename FROM &apos;username&apos;@&apos;host&apos;;DROP USER &apos;username&apos;@&apos;host&apos;;其中username：你将创建的用户名host：指定该用户在哪个主机上可以登陆，如果是本地用户可用 localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符 %password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器privileges：用户的操作权限，如 SELECT，INSERT，UPDATE 等，如果要授予所的权限则使用ALLdatabasename：数据库名tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用 表示，如 .*远程访问MySQL设置允许root用户在任何地方进行远程登录，并具有所有库任何操作权限。登录MySQL并输入以下命令12mysql&gt; mysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'youpassword' WITH GRANT OPTION; #授权操作mysql&gt; flush privileges; #刷新权限允许root用户在一个特定的IP进行远程登录，并具有所有库任何操作权限。登录MySQL并输入如下命令12mysql&gt; GRANT ALL PRIVILEGES ON *.* TO root@"172.16.16.152" IDENTIFIED BY "youpassword" WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES;允许root用户在一个特定的IP进行远程登录，并具有所有库特定操作权限，具体操作如下：12mysql&gt; GRANT select，insert，update，delete ON *.* TO root@"172.16.16.152" IDENTIFIED BY "youpassword";mysql&gt; FLUSH PRIVILEGES;删除用户授权，需要使用REVOKE命令，具体命令格式为：REVOKE privileges ON 数据库[.表名] FROM user-name;123mysql&gt; GRANT select，insert，update，delete ON TEST-DB TO test-user@"172.16.16.152" IDENTIFIED BY "youpassword"; # 授权操作mysql&gt; REVOKE all on TEST-DB from test-user; # 删除授权操作mysql&gt; FLUSH PRIVILEGES;防火墙设置开启3306端口12firewall-cmd --zone=public --add-port=3306/tcp --permanentfirewall-cmd --reload补充：操作防火墙命systemctl list-unit-files #查看服务systemctl enable firewalld #允许开机启动systemctl stop firewalld #停止systemctl disable firewalld #禁用开机启动firewall-cmd –state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）远程连接测试mysql -u 用户名 -p密码 -h 服务器IP地址 -P 服务器端MySQL端口号 -D 数据库名若正常连接，会进入数据库操作命令行界面。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy从零开始到掌握]]></title>
    <url>%2Fposts%2Fc28f24c2%2F</url>
    <content type="text"><![CDATA[HAProxy是什么HAProxy是一个免费的负载均衡软件，可以运行于大部分主流的Linux操作系统上。HAProxy提供了L4(TCP)和L7(HTTP)两种负载均衡能力，具备丰富的功能。HAProxy的社区非常活跃，版本更新快速。最关键的是，HAProxy具备媲美商用负载均衡器的性能和稳定性。因为HAProxy的上述优点，它当前不仅仅是免费负载均衡软件的首选，更几乎成为了唯一选择。HAProxy的核心能力和关键特性HAProxy的核心功能负载均衡：L4和L7两种模式，支持RR/静态RR/LC/IP Hash/URI Hash/URL_PARAM Hash/HTTP_HEADER Hash等丰富的负载均衡算法健康检查：支持TCP和HTTP两种健康检查模式会话保持：对于未实现会话共享的应用集群，可通过Insert Cookie/Rewrite Cookie/Prefix Cookie，以及上述的多种Hash方式实现会话保持SSL：HAProxy可以解析HTTPS协议，并能够将请求解密为HTTP后向后端传输HTTP请求重写与重定向监控与统计：HAProxy提供了基于Web的统计信息页面，展现健康状态和流量数据。基于此功能，使用者可以开发监控程序来监控HAProxy的状态HAProxy的关键特性性能采用单线程、事件驱动、非阻塞模型，减少上下文切换的消耗，能在1ms内处理数百个请求。并且每个会话只占用数KB的内存。大量精细的性能优化，如O(1)复杂度的事件检查器、延迟更新技术、Single-buffereing、Zero-copy forwarding等等，这些技术使得HAProxy在中等负载下只占用极低的CPU资源。HAProxy大量利用操作系统本身的功能特性，使得其在处理请求时能发挥极高的性能，通常情况下，HAProxy自身只占用15%的处理时间，剩余的85%都是在系统内核层完成的。HAProxy作者在8年前（2009）年使用1.4版本进行了一次测试，单个HAProxy进程的处理能力突破了10万请求/秒，并轻松占满了10Gbps的网络带宽。稳定性作为建议以单进程模式运行的程序，HAProxy对稳定性的要求是十分严苛的。按照作者的说法，HAProxy在13年间从未出现过一个会导致其崩溃的BUG，HAProxy一旦成功启动，除非操作系统或硬件故障，否则就不会崩溃（我觉得可能多少还是有夸大的成分）。在上文中提到过，HAProxy的大部分工作都是在操作系统内核完成的，所以HAProxy的稳定性主要依赖于操作系统，作者建议使用2.6或3.x的Linux内核，对sysctls参数进行精细的优化，并且确保主机有足够的内存。这样HAProxy就能够持续满负载稳定运行数年之久。个人的建议：使用3.x内核的Linux操作系统运行HAProxy运行HAProxy的主机上不要部署其他的应用，确保HAProxy独占资源，同时避免其他应用引发操作系统或主机的故障至少为HAProxy配备一台备机，以应对主机硬件故障、断电等突发情况（搭建双活HAProxy的方法在后文中有描述）sysctl的建议配置（并不是万用配置，仍然需要针对具体情况进行更精细的调整，但可以作为首次使用HAProxy的初始配置使用）：1234567net.ipv4.tcp_tw_reuse = 1net.ipv4.ip_local_port_range = 1024 65023net.ipv4.tcp_max_syn_backlog = 10240net.ipv4.tcp_max_tw_buckets = 400000net.ipv4.tcp_max_orphans = 60000net.ipv4.tcp_synack_retries = 3net.core.somaxconn = 10000HAProxy的安装和运行下面介绍在CentOS7中安装和运行HAProxy最新稳定版(1.7.2)的方法安装为HAProxy创建用户和用户组，此例中用户和用户组都是”ha”。注意，如果想要让HAProxy监听1024以下的端口，则需要以root用户来启动下载并解压12wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.2.tar.gztar -xzf haproxy-1.7.2.tar.gz编译并安装12make PREFIX=/home/ha/haproxy TARGET=linux2628make install PREFIX=/home/ha/haproxyPREFIX为指定的安装路径，TARGET则根据当前操作系统内核版本指定：12345- linux22 for Linux 2.2- linux24 for Linux 2.4 and above (default)- linux24e for Linux 2.4 with support for a working epoll (&gt; 0.21)- linux26 for Linux 2.6 and above- linux2628 for Linux 2.6.28, 3.x, and above (enables splice and tproxy)此例中，我们的操作系统内核版本为3.10.0，所以TARGET指定为linux2628创建HAProxy配置文件12mkdir -p /home/ha/haproxy/confvi /home/ha/haproxy/conf/haproxy.cfg我们先创建一个最简单配置文件：1234567891011121314151617global #全局属性 daemon #以daemon方式在后台运行 maxconn 256 #最大同时256连接 pidfile /home/ha/haproxy/conf/haproxy.pid #指定保存HAProxy进程号的文件defaults #默认参数 mode http #http模式 timeout connect 5000ms #连接server端超时5s timeout client 50000ms #客户端响应超时50s timeout server 50000ms #server端响应超时50sfrontend http-in #前端服务http-in bind *:8080 #监听8080端口 default_backend servers #请求转发至名为"servers"的后端服务backend servers #后端服务servers server server1 127.0.0.1:8000 maxconn 32 #backend servers中只有一个后端服务，名字叫server1，起在本机的8000端口，HAProxy同时最多向这个服务发起32个连接更加详细的配置会在后面章节中进行说明注意：HAProxy要求系统的ulimit -n参数大于[maxconn*2+18]，在设置较大的maxconn时，注意检查并修改ulimit -n参数将HAProxy注册为系统服务在/etc/init.d目录下添加HAProxy服务的启停脚本：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556vi /etc/init.d/haproxy#! /bin/shset -ePATH=/sbin:/bin:/usr/sbin:/usr/bin:/home/ha/haproxy/sbinPROGDIR=/home/ha/haproxyPROGNAME=haproxyDAEMON=$PROGDIR/sbin/$PROGNAMECONFIG=$PROGDIR/conf/$PROGNAME.cfgPIDFILE=$PROGDIR/conf/$PROGNAME.pidDESC="HAProxy daemon"SCRIPTNAME=/etc/init.d/$PROGNAME# Gracefully exit if the package has been removed.test -x $DAEMON || exit 0start()&#123; echo -e "Starting $DESC: $PROGNAME\n" $DAEMON -f $CONFIG echo "."&#125;stop()&#123; echo -e "Stopping $DESC: $PROGNAME\n" haproxy_pid="$(cat $PIDFILE)" kill $haproxy_pid echo "."&#125;restart()&#123; echo -e "Restarting $DESC: $PROGNAME\n" $DAEMON -f $CONFIG -p $PIDFILE -sf $(cat $PIDFILE) echo "."&#125;case "$1" in start) start ;; stop) stop ;; restart) restart ;; *) echo "Usage: $SCRIPTNAME &#123;start|stop|restart&#125;" &gt;&amp;2 exit 1 ;;esacexit 0运行启动、停止和重启：123service haproxy startservice haproxy stopservice haproxy restart添加日志HAProxy不会直接输出文件日志，所以我们要借助Linux的rsyslog来让HAProxy输出日志修改haproxy.cfg在global域和defaults域中添加：12345678910global ... log 127.0.0.1 local0 info log 127.0.0.1 local1 warning ...defaults ... log global ...意思是将info级（及以上）的日志推送到rsyslog的local0接口，将warn级（及以上）的日志推送到rsyslog的local1接口，并且所有frontend都默认使用global中的日志配置。注：info级的日志会打印HAProxy处理的每一条请求，会占用很大的磁盘空间，在生产环境中，建议将日志级别调整为notice为rsyslog添加haproxy日志的配置1vi /etc/rsyslog.d/haproxy.conf123456$ModLoad imudp$UDPServerRun 514$FileCreateMode 0644 #日志文件的权限$FileOwner ha #日志文件的ownerlocal0.* /var/log/haproxy.log #local0接口对应的日志输出文件local1.* /var/log/haproxy_warn.log #local1接口对应的日志输出文件修改rsyslog的启动参数1vi /etc/sysconfig/rsyslog12345# Options for rsyslogd# Syslogd options are deprecated since rsyslog v3.# If you want to use them, switch to compatibility mode 2 by "-c 2"# See rsyslogd(8) for more detailsSYSLOGD_OPTIONS="-c 2 -r -m 0"重启rsyslog和HAProxy12service rsyslog restartservice haproxy restart此时就应该能在/var/log目录下看到haproxy的日志文件了用logrotate进行日志切分通过rsyslog输出的日志是不会进行切分的，所以需要依靠Linux提供的logrotate来进行切分工作使用root用户，创建haproxy日志切分配置文件：12mkdir /root/logrotatevi /root/logrotate/haproxy12345678910111213/var/log/haproxy.log /var/log/haproxy_warn.log &#123; #切分的两个文件名 daily #按天切分 rotate 7 #保留7份 create 0644 ha ha #创建新文件的权限、用户、用户组 compress #压缩旧日志 delaycompress #延迟一天压缩 missingok #忽略文件不存在的错误 dateext #旧日志加上日志后缀 sharedscripts #切分后的重启脚本只运行一次 postrotate #切分后运行脚本重载rsyslog，让rsyslog向新的日志文件中输出日志 /bin/kill -HUP $(/bin/cat /var/run/syslogd.pid 2&gt;/dev/null) &amp;&gt;/dev/null endscript&#125;并配置在crontab中运行：10 0 * * * /usr/sbin/logrotate /root/logrotate/haproxy使用HAProxy搭建L7负载均衡器总体方案本节中，我们将使用HAProxy搭建一个L7负载均衡器，应用如下功能负载均衡会话保持健康检查根据URI前缀向不同的后端集群转发监控页面架构如下：架构中共有6个后端服务，划分为3组，每组中2个服务：ms1：服务URI前缀为ms1/的请求ms2：服务URI前缀为ms2/的请求def：服务其他请求搭建搭建后端服务部署6个后端服务，可以使用任意的Web服务，如Nginx、Apache HTTPD、Tomcat、Jetty等，具体Web服务的安装过程省略。此例中，我们在192.168.8.111和192.168.8.112两台主机上分别安装了3个Nginx：ms1.srv1 - 192.168.8.111:8080ms1.srv2 - 192.168.8.112:8080ms2.srv1 - 192.168.8.111:8081ms2.srv2 - 192.168.8.112:8081def.srv1 - 192.168.8.111:8082def.srv2 - 192.168.8.112:8082在这6个Nginx服务分别部署健康检查页面healthCheck.html，页面内容任意。确保通过http://ip:port/healthCheck.html可以访问到这个页面接下来在6个Nginx服务中部署服务页面：在第一组中部署ms1/demo.html在第二组中部署ms2/demo.html在第三组中部署def/demo.htmldemo.html的内容，以部署在192.168.8.111:8080上的为例：Hello! This is ms1.srv1!部署在192.168.8.112:8080上的就应该是Hello! This is ms1.srv2!以此类推搭建HAProxy在192.168.8.110主机安装HAProxyHAProxy的安装和配置步骤如上一章中描述，此处略去HAProxy配置文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657global daemon maxconn 30000 #ulimit -n至少为60018 user ha pidfile /home/ha/haproxy/conf/haproxy.pid log 127.0.0.1 local0 info log 127.0.0.1 local1 warningdefaults mode http log global option http-keep-alive #使用keepAlive连接 option forwardfor #记录客户端IP在X-Forwarded-For头域中 option httplog #开启httplog，HAProxy会记录更丰富的请求信息 timeout connect 5000ms timeout client 10000ms timeout server 50000ms timeout http-request 20000ms #从连接创建开始到从客户端读取完整HTTP请求的超时时间，用于避免类DoS攻击 option httpchk GET /healthCheck.html #定义默认的健康检查策略frontend http-in bind *:9001 maxconn 30000 #定义此端口上的maxconn acl url_ms1 path_beg -i /ms1/ #定义ACL，当uri以/ms1/开头时，ACL[url_ms1]为true acl url_ms2 path_beg -i /ms2/ #同上，url_ms2 use_backend ms1 if url_ms1 #当[url_ms1]为true时，定向到后端服务群ms1中 use_backend ms2 if url_ms2 #当[url_ms2]为true时，定向到后端服务群ms2中 default_backend default_servers #其他情况时，定向到后端服务群default_servers中backend ms1 #定义后端服务群ms1 balance roundrobin #使用RR负载均衡算法 cookie HA_STICKY_ms1 insert indirect nocache #会话保持策略，insert名为"HA_STICKY_ms1"的cookie #定义后端server[ms1.srv1]，请求定向到该server时会在响应中写入cookie值[ms1.srv1] #针对此server的maxconn设置为300 #应用默认健康检查策略，健康检查间隔和超时时间为2000ms，两次成功视为节点UP，三次失败视为节点DOWN server ms1.srv1 192.168.8.111:8080 cookie ms1.srv1 maxconn 300 check inter 2000ms rise 2 fall 3 #同上，inter 2000ms rise 2 fall 3是默认值，可以省略 server ms1.srv2 192.168.8.112:8080 cookie ms1.srv2 maxconn 300 checkbackend ms2 #定义后端服务群ms2 balance roundrobin cookie HA_STICKY_ms2 insert indirect nocache server ms2.srv1 192.168.8.111:8081 cookie ms2.srv1 maxconn 300 check server ms2.srv2 192.168.8.112:8081 cookie ms2.srv2 maxconn 300 checkbackend default_servers #定义后端服务群default_servers balance roundrobin cookie HA_STICKY_def insert indirect nocache server def.srv1 192.168.8.111:8082 cookie def.srv1 maxconn 300 check server def.srv2 192.168.8.112:8082 cookie def.srv2 maxconn 300 checklisten stats #定义监控页面 bind *:1080 #绑定端口1080 stats refresh 30s #每30秒更新监控数据 stats uri /stats #访问监控页面的uri stats realm HAProxy\ Stats #监控页面的认证提示 stats auth admin:admin #监控页面的用户名和密码修改完成后，启动HAProxy1service haproxy start测试首先，访问一下监控页面http://192.168.8.110:1080/stats 并按提示输入用户名密码接下来就能看到监控页面：)监控页面中列出了我们配置的所有frontend和backend服务，以及它们的详细指标。如连接数，队列情况，session rate，流量，后端服务的健康状态等等接下来，我们一一测试在HAProxy中配置的功能健康检查从监控页面中就可以直接看出健康检查配置的是否正确，上图中可以看到，backend ms1、ms2、default_servers下属的6个后端服务的Status都是20h28m UP，代表健康状态已持续了20小时28分钟，而LastChk显示L7OK/200 in 1ms则代表在1ms前进行了L7的健康检查（即HTTP请求方式的健康检查），返回码为200此时我们将ms1.srv1中的healthCheck.html改名1mv healthCheck.html healthCheck.html.bak然后再去看监控页面：ms1.srv1的状态变成了2s DOWN，LastChk则是L7STS/404 in 2ms，代表上次健康检查返回了404再恢复healthCheck.html，很快就能看到ms1.srv1重新恢复到UP状态通过URI前缀转发请求访问http://192.168.8.110:9001/ms1/demo.html ：可以看到成功定向到了ms1.srv1上访问http://192.168.8.110:9001/ms2/demo.html :访问http://192.168.8.110:9001/def/demo.html :3） 负载均衡和会话保持策略在分别访问过ms1/demo.html, ms2/demo.html, m3/demo.html后，查看一下浏览器的Cookie：可以看到HAProxy已经回写了三个用于会话保持的cookie，此时反复刷新这三个页面，会发现总是被定向到*.srv1上接下来我们删除HA_STICKY_ms1这条cookie，然后再访问ms1/demo.html，会看到：同时也被新写入了一条Cookie：如果发现仍然被定位到ms1.srv1，同时也没有写入新的HA_STICKY_ms1 Cookie，那么可能是浏览器缓存了ms1/demo.html页面，请求并没有到达HAProxy。F5刷新一下应该就可以了。使用HAProxy搭建L4负载均衡器HAProxy作为L4负载均衡器工作时，不会去解析任何与HTTP协议相关的内容，只在传输层对数据包进行处理。也就是说，以L4模式运行的HAProxy，无法实现根据URL向不同后端转发、通过cookie实现会话保持等功能。同时，在L4模式下工作的HAProxy也无法提供监控页面。但作为L4负载均衡器的HAProxy能够提供更高的性能，适合于基于套接字的服务（如数据库、消息队列、RPC、邮件服务、Redis等），或不需要逻辑规则判断，并已实现了会话共享的HTTP服务。总体方案本例中，我们使用HAProxy以L4方式来代理两个HTTP服务，不提供会话保持。1234567891011121314151617181920212223242526global daemon maxconn 30000 #ulimit -n至少为60018 user ha pidfile /home/ha/haproxy/conf/haproxy.pid log 127.0.0.1 local0 info log 127.0.0.1 local1 warningdefaults mode tcp log global option tcplog #开启tcplog timeout connect 5000ms timeout client 10000ms timeout server 10000ms #TCP模式下，应将timeout client和timeout server设置为一样的值，以防止出现问题 option httpchk GET /healthCheck.html #定义默认的健康检查策略frontend http-in bind *:9002 maxconn 30000 #定义此端口上的maxconn default_backend default_servers #请求定向至后端服务群default_serversbackend default_servers #定义后端服务群default_servers balance roundrobin server def.srv1 192.168.8.111:8082 maxconn 300 check server def.srv2 192.168.8.112:8082 maxconn 300 checkL4模式下的会话保持虽然TCP模式下的HAProxy无法通过HTTP Cookie实现会话保持，但可以很方便的实现基于客户端IP的会话保持。只需将1balance roundrobin改为1balance source此外，HAProxy提供了强大的stick-table功能，HAProxy可以从传输层的数据包中采样出大量的属性，并将这些属性作为会话保持的策略写入stick-table中。本文中不对stick-table进行深入探讨，如需要了解，可参考官方文档configuration.html#4-stick-tableHAProxy关键配置详解总览HAProxy的配置文件共有5个域global：用于配置全局参数default：用于配置所有frontend和backend的默认属性frontend：用于配置前端服务（即HAProxy自身提供的服务）实例backend：用于配置后端服务（即HAProxy后面接的服务）实例组listen：frontend+backend的组合配置，可以理解成更简洁的配置方法global域的关键配置daemon：指定HAProxy以后台模式运行，通常情况下都应该使用这一配置user [username] ：指定HAProxy进程所属的用户group [groupname] ：指定HAProxy进程所属的用户组log [address] [device] [maxlevel] [minlevel]：日志输出配置，如log 127.0.0.1 local0 info warning，即向本机rsyslog或syslog的local0输出info到warning级别的日志。其中[minlevel]可以省略。HAProxy的日志共有8个级别，从高到低为emerg/alert/crit/err/warning/notice/info/debugpidfile ：指定记录HAProxy进程号的文件绝对路径。主要用于HAProxy进程的停止和重启动作。maxconn ：HAProxy进程同时处理的连接数，当连接数达到这一数值时，HAProxy将停止接收连接请求frontend域的关键配置acl [name] [criterion] [flags] [operator] [value]：定义一条ACL，ACL是根据数据包的指定属性以指定表达式计算出的true/false值。如”acl url_ms1 path_beg -i /ms1/“定义了名为url_ms1的ACL，该ACL在请求uri以/ms1/开头（忽略大小写）时为truebind [ip]:[port]：frontend服务监听的端口default_backend [name]：frontend对应的默认backenddisabled：禁用此frontendhttp-request [operation] [condition]：对所有到达此frontend的HTTP请求应用的策略，例如可以拒绝、要求认证、添加header、替换header、定义ACL等等。http-response [operation] [condition]：对所有从此frontend返回的HTTP响应应用的策略，大体同上log：同global域的log配置，仅应用于此frontend。如果要沿用global域的log配置，则此处配置为log globalmaxconn：同global域的maxconn，仅应用于此frontendmode：此frontend的工作模式，主要有http和tcp两种，对应L7和L4两种负载均衡模式option forwardfor：在请求中添加X-Forwarded-For Header，记录客户端ipoption http-keep-alive：以KeepAlive模式提供服务option httpclose：与http-keep-alive对应，关闭KeepAlive模式，如果HAProxy主要提供的是接口类型的服务，可以考虑采用httpclose模式，以节省连接数资源。但如果这样做了，接口的调用端将不能使用HTTP连接池option httplog：开启httplog，HAProxy将会以类似Apache HTTP或Nginx的格式来记录请求日志option tcplog：开启tcplog，HAProxy将会在日志中记录数据包在传输层的更多属性stats uri [uri]：在此frontend上开启监控页面，通过[uri]访问stats refresh [time]：监控数据刷新周期stats auth [user]:[password]：监控页面的认证用户名密码timeout client [time]：指连接创建后，客户端持续不发送数据的超时时间timeout http-request [time]：指连接创建后，客户端没能发送完整HTTP请求的超时时间，主要用于防止DoS类攻击，即创建连接后，以非常缓慢的速度发送请求包，导致HAProxy连接被长时间占用use_backend [backend] if|unless [acl]：与ACL搭配使用，在满足/不满足ACL时转发至指定的backendbackend域的关键配置acl：同frontend域balance [algorithm]：在此backend下所有server间的负载均衡算法，常用的有roundrobin和source，完整的算法说明见官方文档configuration.html#4.2-balancecookie：在backend server间启用基于cookie的会话保持策略，最常用的是insert方式，如cookie HA_STICKY_ms1 insert indirect nocache，指HAProxy将在响应中插入名为HA_STICKY_ms1的cookie，其值为对应的server定义中指定的值，并根据请求中此cookie的值决定转发至哪个server。indirect代表如果请求中已经带有合法的HA_STICK_ms1 cookie，则HAProxy不会在响应中再次插入此cookie，nocache则代表禁止链路上的所有网关和缓存服务器缓存带有Set-Cookie头的响应。default-server：用于指定此backend下所有server的默认设置。具体见下面的server配置。disabled：禁用此backendhttp-request/http-response：同frontend域log：同frontend域mode：同frontend域option forwardfor：同frontend域option http-keep-alive：同frontend域option httpclose：同frontend域option httpchk [METHOD] [URL] [VERSION]：定义以http方式进行的健康检查策略。如option httpchk GET /healthCheck.html HTTP/1.1option httplog：同frontend域option tcplog：同frontend域server [name] [ip]:[port] [params]：定义backend中的一个后端server，[params]用于指定这个server的参数，常用的包括有：check：指定此参数时，HAProxy将会对此server执行健康检查，检查方法在option httpchk中配置。同时还可以在check后指定inter, rise, fall三个参数，分别代表健康检查的周期、连续几次成功认为server UP，连续几次失败认为server DOWN，默认值是inter 2000ms rise 2 fall 3cookie [value]：用于配合基于cookie的会话保持，如cookie ms1.srv1代表交由此server处理的请求会在响应中写入值为ms1.srv1的cookie（具体的cookie名则在backend域中的cookie设置中指定）maxconn：指HAProxy最多同时向此server发起的连接数，当连接数到达maxconn后，向此server发起的新连接会进入等待队列。默认为0，即无限maxqueue：等待队列的长度，当队列已满后，后续请求将会发至此backend下的其他server，默认为0，即无限weight：server的权重，0-256，权重越大，分给这个server的请求就越多。weight为0的server将不会被分配任何新的连接。所有server默认weight为1timeout connect [time]：指HAProxy尝试与backend server创建连接的超时时间timeout check [time]：默认情况下，健康检查的连接+响应超时时间为server命令中指定的inter值，如果配置了timeout check，HAProxy会以inter作为健康检查请求的连接超时时间，并以timeout check的值作为健康检查请求的响应超时时间timeout server [time]：指backend server响应HAProxy请求的超时时间default域上文所属的frontend和backend域关键配置中，除acl、bind、http-request、http-response、use_backend外，其余的均可以配置在default域中。default域中配置了的项目，如果在frontend或backend域中没有配置，将会使用default域中的配置。listen域listen域是frontend域和backend域的组合，frontend域和backend域中所有的配置都可以配置在listen域下官方配置文档HAProxy的配置项非常多，支持非常丰富的功能，上文只列出了作为L7负载均衡器使用HAProxy时的一些关键参数。完整的参数说明请参见官方文档 configuration.html使用Keepalived实现HAProxy高可用尽管HAProxy非常稳定，但仍然无法规避操作系统故障、主机硬件故障、网络故障甚至断电带来的风险。所以必须对HAProxy实施高可用方案。下文将介绍利用Keepalived实现的HAProxy热备方案。即两台主机上的两个HAProxy实例同时在线，其中权重较高的实例为MASTER，MASTER出现问题时，另一台实例自动接管所有流量。原理在两台HAProxy的主机上分别运行着一个Keepalived实例，这两个Keepalived争抢同一个虚IP地址，两个HAProxy也尝试去绑定这同一个虚IP地址上的端口。显然，同时只能有一个Keepalived抢到这个虚IP，抢到了这个虚IP的Keepalived主机上的HAProxy便是当前的MASTER。Keepalived内部维护一个权重值，权重值最高的Keepalived实例能够抢到虚IP。同时Keepalived会定期check本主机上的HAProxy状态，状态OK时权重值增加。搭建HAProxy主备集群环境准备在两台物理机上安装并配置HAProxy，本例中，将在192.168.8.110和192.168.8.111两台主机上上安装两套完全一样的HAProxy，具体步骤省略，请参考“使用HAProxy搭建L7负载均衡器”一节。安装Keepalived下载，解压，编译，安装：12345wget http://www.keepalived.org/software/keepalived-1.2.19.tar.gztar -xzf keepalived-1.2.19.tar.gz./configure --prefix=/usr/local/keepalivedmakemake install注册为系统服务：1234cp /usr/local/keepalived/sbin/keepalived /usr/sbin/cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/chmod +x /etc/init.d/keepalived注意：Keepalived需要使用root用户进行安装和配置配置Keepalived创建并编辑配置文件123mkdir -p /etc/keepalived/cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/vi /etc/keepalived/keepalived.conf配置文件内容：12345678910111213141516171819202122232425global_defs &#123; router_id LVS_DEVEL #虚拟路由名称&#125;#HAProxy健康检查配置vrrp_script chk_haproxy &#123; script "killall -0 haproxy" #使用killall -0检查haproxy实例是否存在，性能高于ps命令 interval 2 #脚本运行周期 weight 2 #每次检查的加权权重值&#125;#虚拟路由配置vrrp_instance VI_1 &#123; state MASTER #本机实例状态，MASTER/BACKUP，备机配置文件中请写BACKUP interface enp0s25 #本机网卡名称，使用ifconfig命令查看 virtual_router_id 51 #虚拟路由编号，主备机保持一致 priority 101 #本机初始权重，备机请填写小于主机的值（例如100） advert_int 1 #争抢虚地址的周期，秒 virtual_ipaddress &#123; 192.168.8.201 #虚地址IP，主备机保持一致 &#125; track_script &#123; chk_haproxy #对应的健康检查配置 &#125;&#125;如果主机没有killall命令，则需要安装psmisc包：1yum intall psmisc分别启动两个Keepalived1service keepalived start验证启动后，先分别在两台主机查看虚IP 192.168.8.201由谁持有，执行命令：1ip addr sh enp0s25 （将enp0s25替换成主机的网卡名）持有虚IP的主机输出会是这样的：另一台主机输出则是这样的：如果你先启动备机的Keepalived，那么很有可能虚IP会被备机抢到，因为备机的权重配置只比主机低1，只要执行一次健康检查就能把权重提高到102，高于主机的101。此时访问http://192.168.8.201:9001/ms1/demo.html ，可以看到我们先前部署的网页。此时，检查/var/log/haproxy.log，能看到此请求落在了抢到了虚IP的主机上。接下来，我们停掉当前MASTER主机的HAProxy实例（或者Keepalive实例，效果一样）1service haproxy stop再次访问http://192.168.8.201:9001/ms1/demo.html ，并查看备机的/var/log/haproxy.log，会看到此请求落在了备机上，主备自动切换成功。也可以再次执行ip addr sh enp0s25命令，会看到虚IP被备机抢去了。在/var/log/message中，也能够看到keepalived输出的切换日志：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的itertools模块]]></title>
    <url>%2Fposts%2F4f4399bb%2F</url>
    <content type="text"><![CDATA[无限迭代器count(firstval=0, step=1)创建一个从firstval（默认值为0）开始，以step（默认值为1）为步长的无限整数迭代器。此迭代器不支持长整数，如果超出了sys.maxint，计数器将溢出并继续从-sys.maxint-1开始计算。123456for x, y in zip(count(1), ['a', 'b', 'c']): print(x, y)输出:1 a2 b3 ccycle(iterable)对iterable中的元素反复执行循环，返回生成的迭代器12345678index = 0for value in cycle('abcd'): index += 1 if index == 10: break print(value)输出：a b c d a b c d arepeat(object, [,items])返回一个迭代器，反复生成object，如果给定times，则重复次数为items，否则为无限1234for value in repeat('windylee', 5): print(value, end=' ')输出：windylee windylee windylee windylee windylee有限迭代器**chain(iterable1, iterable2, iterable3, …)chain接收多个可迭代对象作为参数，将他们连接起来，作为一个新的迭代器返回1234for value in chain([1, 2, 3], ['a', 'b', 'c']): print(value, end=' ')输出：1 2 3 a b ccompress(data, selectors)compress可用于对数据进行筛选，当selectors的元素为true时，则保留data对应位置的元素1234for value in compress([1, 2, 3, 4, 5], [True, False, False, True, True]): print(value, end=' ')输出:1 4 5dropwhile(predicate, iterable)创建一个迭代器，只要函数predicate(item)为True，就丢弃iterable中的项，如果predicate返回False，就会生成iterable中的项和所有后续项。123456789def predict(item): if item &lt; 3: return True return Falsefor value in dropwhile(predict, [1, 2, 3, 4, 5]): print(value, end=' ')输出：3 4 5takewhile(predicate, iterable)创建一个迭代器，只要函数predite(item)为True，就保留iterable中的项，如果predicate返回False，就会丢弃iterable中的项和所有的后续项。相当于dropwhile的反操作。123456789def predict(item): if item &lt; 3: return True return Falsefor value in takewhile(predict, [1, 2, 3, 4, 5]): print(value, end=' ')输出：1 2groupby(iterable[, keyfunc])返回一个产生按照keyfunc的返回值进行分组的值集合的迭代器。iterable是一个可迭代对象，keyfunc是分组函数，用于对iterable的连续项进行分组。如果不指定，则默认将iterable中连续相同的项作为一组，否则将keyfunc返回值相同的连续项作为一组。1234567891011def predict(item): if item &lt; 3 or item &gt; 7: return True return Falsefor key, value in groupby([1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10], predict): print(key, list(value))输出：True [1, 2]False [3, 4, 5, 5, 6, 7]True [8, 9, 10]starmap(function, iterable)创建一个迭代器，对于iterable中每一项item生成值func(*item)。1234for value in starmap(lambda x, y: x * y, [(0, 5), (1, 6), (2, 7), (3, 8), (4, 9)]): print(value, end=' ')输出：0 6 14 24 36tee(iterable, [, n])用于从iterable创建n个独立的迭代器，以元组的形式返回，n的默认值是2。由于生成的项会被缓存，并在所有新创建的迭代器中使用，所以一定要注意不要再调用tee()之后使用原始迭代器iterable，否则缓存机制可能无法正常工作。123456789iter1, iter2 = tee([1, 2, 3])for v1 in iter1: print(v1, end=' ')print()for v2 in iter2: print(v2, end=' ')输出：1 2 3 1 2 3zip_longest(*iterables, fillvalue=None)类似于内置函数zip，只不过迭代完最长的序列为止，短序列默认用None补齐。1234567for v1, v2 in zip_longest([1, 2, 3], ['a', 'b', 'c', 'd']): print(v1, v2)输出：1 a2 b3 cNone daccumulate(iterable, [,func])创建一个迭代器，返回从第一项到当前项的子列表执行reduce函数的值。func是一个二元函数12&gt;&gt;&gt; list(itertools.accumulate([1, 2, 3, 4], func=operator.add))[1, 3, 6, 10]组合生成器product(*iterables [,repeat=1])创建一个迭代器，生成多个可迭代对象的笛卡尔积，跟嵌套for循环等价，repeat用于指定重复生成序列的次数。123456for value in accumulate(['a', 'b', 'c']): print(value)输出：aababcpermutations(iterable, [, r]])创建一个迭代器，生成iterable中元素的排列，r用于指定生成排列的长度，如果省略r，生成的序列长度与iterable长度相同。123456789for value in permutations([1, 2, 3]): print(list(value))输出：[1, 2, 3][1, 3, 2][2, 1, 3][2, 3, 1][3, 1, 2][3, 2, 1]combinations(iterable, r)创建一个迭代器，生成iterable中所有长度为r的序列。序列中元素的排列顺序和iterable中元素顺序相同，序列中元素不重复123456for value in combinations([1, 2, 3], 2): print(list(value))输出：[1, 2][1, 3][2, 3]combinations_with_replacement(iterable, [, r])功能和combinations类似，不过该函数生成的序列中允许元素重复。123456789for value in combinations_with_replacement([1, 2, 3], 2): print(list(value))输出：[1, 1][1, 2][1, 3][2, 2][2, 3][3, 3]​]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String源码解析]]></title>
    <url>%2Fposts%2F827303fc%2F</url>
    <content type="text"><![CDATA[定义先看一下文档中的注释12345/** * Strings are constant; their values cannot be changed after they * are created. String buffers support mutable strings. * Because String objects are immutable they can be shared. */String对象是常量，创建之后就不能被修改，所以该对象可以被多线程共享。12345678910111213public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; private final char value[]; private int hash; // Default to 0 private static final long serialVersionUID = -6849794470754667710L; private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; ......&#125;从源码中可以看出，String是被final修饰的，说明该类不能被继承。并且实现了CharSequence, Comparable, Serializable接口。Serializable接口用于实现String的序列化和反序列化操作；Comparable接口用于实现字符串的比较操作；CharSequence是字符串类的父接口，StringBuffer和StringBuilder都继承自该接口。value字段是实现String类的底层数组，用于存储字符串内容。final修饰基本数据类型，那么在运行期间其内容不可变，如果修饰的是引用类型，那么引用的对象(包括数组)运行期地址不可变，但是对象的内容是可以改变的。hash字段用于缓存String对象的hash值，防止多次计算hash造成的时间损耗。因为String实现了Serializable接口，所以需要serialVersionUID字段用来在String反序列化时，通过对比字节流中的serialVersionUID和本地实体类中的serialVersionUID是否一致，如果相同就可以进行反序列化，否则就会抛出InvalidCastException异常。构造方法空参构造方法123public String() &#123; this.value = "".value;&#125;该构造方法会创建一个空的字符序列，因为字符串的不可变对象，之后对象的赋值会指向新的字符串，因此使用这种构造方法会多创建一个无用对象。使用字符串类型的对象初始化1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125;直接将源String中的value和hash两个属性直接赋值给目标String。因为String一旦定义之后就不可改变，所以也就不用担心源String的值会影响到目标String的值。使用字符数组初始化12345678910// 参数为char数组，通过java.utils包中的Arrays.copyOf复制public String(char value[]) &#123; this.value = Arrays.copyOf(value, value.length);&#125;// 使用字符数组的一部分初始化，通过Arrays.copyOfRange复制public String(char value[], int offset, int count) &#123; // 异常检测 ...... this.value = Arrays.copyOfRange(value, offset, offset+count);&#125;使用字节数组初始化在Java中，String实例保存有一个char[]字符数组，char[]字符数组是以Unicode编码方式存储的，String和char为内存形式，byte是网络传输或存储的序列化形式，所以在很多传输和存储过程中需要将byte[]数组和String进行相互转化。字节和字符自检的转化需要指定编码，不然很可能会出现乱码。String提供了多种字节数组的重载构造函数：123456public String(byte bytes[], int offset, int length, String charsetName)public String(byte bytes[], int offset, int length, Charset charset)public String(byte bytes[], String charsetName)public String(byte bytes[], Charset charset)public String(byte bytes[], int offset, int length)public String(byte bytes[])如果我们在使用 byte[] 构造 String 的时候，如果指定了charsetName或者charset参数的话，那么就会使用 StringCoding.decode 方法进行解码，使用的解码的字符集就是我们指定的 charsetName 或者 charset。如果没有指定解码使用的字符集的话，那么StringCoding的decode方法首先会使用系统的默认编码格式(ISO-8859-1)。使用StringBuffer和StringBuilder初始化123456789public String(StringBuffer buffer) &#123; synchronized(buffer) &#123; this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); &#125;&#125;public String(StringBuilder builder) &#123; this.value = Arrays.copyOf(builder.getValue(), builder.length());&#125;因为StringBuilder不是线程安全的，所以在初始化时不需要加锁；而StringBuilder则需要加锁。我们一般使用StringBuffer和StringBuilder的toString方法来获取String，而很少使用String的这两种构造方法。特殊的构造方法String除了提供了很多共有的构造方法，还提供了一个保护类型的构造方法：1234String(char[] value, boolean share) &#123; // assert share : "unshared not supported"; this.value = value;&#125;该方法和String(char[] value)有两点区别：该方法多了一个参数：boolean share，但该参数在函数中并没有使用。因此加入该参数的目的只是为了区分String(char[] value)方法，只有参数不同才能被重载。该方法直接修改了value数组的引用，也就是说共享char[] value数组。而String(char[] value)通过Arrays.copyOf将参数数组内容复制到String中。使用这种方式的的优点很明显：性能好，直接修改指针，避免了逐一拷贝。节约内存，底层共享同一字符数组。当然这种方式也存在缺点，如果外部修改了传进来的字符数组的内容，由于他们引用的是同一个数组，因此外部对数组的修改相当于修改了字符串。为了保证字符串对象的不变性，将其访问权限设置成了default，其他类无法通过该构造方法初始化字符串对象。这样一来，无论源字符串还是新字符串，其value数组本身都是String对象的私有属性，从外部无法访问，保证了String的安全性。该函数只能用在不能缩短String长度的函数中，如concat(str1, str2)，如果用在缩短String长度的函数如subString中会造成内存泄漏。经典方法技巧equals方法123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125;先判断两个对象的地址是否相等在判断是否是String类型如果都是String类型，就先比较长度是否相等，然后再逐一比较值。值的比较采取了短路操作，发现不一样的就返回falsecompareTo方法123456789101112131415161718public int compareTo(String anotherString) &#123; int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k &lt; lim) &#123; char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) &#123; return c1 - c2; &#125; k++; &#125; return len1 - len2;&#125;从0开始逐一判断字符是否相等，若不相等则做差运算，巧妙的避免了三种判断情况。若字符都相等，接直接返回长度差值。所以在判断两个字符串大小时，使用是否为正数/负数/0，而不是通过1//-1/0判断。hashCode方法123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125;若第一次调用hashCode方法且value数组长度大于0，则通过算法s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]计算hash值。hash值很多时候用来判断两个对象的值是否相等，所以需要尽可能的避免冲突。选择31是因为31是一个素数，且i * 31可以通过(i &lt;&lt; 5) - 1来提高运算速度，现在很多虚拟机都有做相关优化。 hashCode可以保证相同的字符串的hash值肯定相同，但是，hash值相同并不一定是value值就相同。返回缓存的hash值。replaceFirst、replaceAll，replace区别1234String replaceFirst(String regex, String replacement)String replaceAll(String regex, String replacement)String replace(Char Sequencetarget, Char Sequencereplacement)String replace(CharSequence target, CharSequence replacement)replace的参数是char和CharSequence，既可以支持字符的替换，也支持字符串的替换replaceFirst和replaceAll的参数是regex，基于正则表达式替换replace和replaceAll方法会替换字符串中的全部字符或字符串，replaceFirst只替换第一次出现的字符或字符串copyValueOf和valueOfString的底层是通过char[]实现的，早期的String构造器的实现并不会拷贝数组。为了防止char[]数组被外部修改，提供了copyValueOf方法，每次都拷贝成新的字符数组来构造新的String对象。但是现在的String在构造器中就通过拷贝新数组实现，所以这两个方法在本质上已经没区别了。valueOf()有很多种重载形式：12345678910111213141516171819public static String valueOf(boolean b) &#123; return b ? "true" : "false"; &#125; public static String valueOf(char c) &#123; char data[] = &#123;c&#125;; return new String(data, true); &#125; public static String valueOf(int i) &#123; return Integer.toString(i); &#125; public static String valueOf(long l) &#123; return Long.toString(l); &#125; public static String valueOf(float f) &#123; return Float.toString(f); &#125; public static String valueOf(double d) &#123; return Double.toString(d);&#125;底层调用了基本数据类型的toString()方法。intern方法1public native String intern();intern方法是Native调用，它的作用是每当定义一个字符字面量，字面量进行字符串连接或final的String字面量初始化的变量的连接，都会检查常量池中是否有对应的字符串，如果有就不创建新的字符串，而是返回指向常量池对应字符串的引用。所有通过new String(str)方式创建的对象都会保存在堆中，而不是常量区。普通变量的连接，由于不能在编译期确定下来，所以不会储存在常量区。其他方法12345678910111213141516171819202122232425262728293031323334353637383940414243int length() //返回字符串长度boolean isEmpty() //返回字符串是否为空char charAt(int index) //返回字符串中第（index+1）个字符char[] toCharArray() //转化成字符数组void trim() //去掉两端空格String toUpperCase() //转化为大写String toLowerCase() //转化为小写String concat(String str) //拼接字符串String replace(char oldChar, char newChar) //将字符串中的oldChar字符换成newChar字符//以上两个方法都使用了String(char[] value, boolean share)；boolean matches(String regex) //判断字符串是否匹配给定的regex正则表达式boolean contains(CharSequence s) //判断字符串是否包含字符序列sString[] split(String regex, int limit) //按照字符regex将字符串分成limit份。String[] split(String regex) //按照regex表达式切分字符串 boolean equals(Object anObject) //比较对象 boolean contentEquals(String Buffersb) //与字符串比较内容 boolean contentEquals(Char Sequencecs) //与字符比较内容 boolean equalsIgnoreCase(String anotherString) //忽略大小写比较字符串对象 int compareTo(String anotherString) //比较字符串 int compareToIgnoreCase(String str) //忽略大小写比较字符串 boolean regionMatches(int toffset, String other, int ooffset, int len) //局部匹配 boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len) //可忽略大小写局部匹配String对“+”的重载Java不支持运算符重载，但是String可以通过+来连接两个字符串。那么java是如何实现对+的重载的呢？123456public class Main&#123; public static void main(String[] args)&#123; String str1 = "windy"; string str2 = str1 + "lee"; &#125;&#125;反编译Main.java，执行命令javap -c Main，输出结果：我们看到了StringBuilder，还有windy和lee，以及调用了StringBuilder的append和toString方法。既然编译器已经在底层为我们进行了优化，那么为什么还要提倡我们用StringBuilder呢？我们注意到在第3行代码，new了一个StringBuilder对象，如果实在一个循环里面，我们使用”+”号就会创建多个StringBuilder的对象。但是编译器事先不知道我们StringBuilder的长度，并不能事先分配好缓冲区，会加大内存的开销，而且使用重载的时候根据java的内存分配也会创建多个对象。switch对字符串支持的实现1234567891011121314public class Main &#123; public static void main(String[] args) &#123; String str = "world"; switch (str) &#123; case "hello": System.out.println("hello"); break; case "world": System.out.println("world"); break; default: break; &#125; &#125;&#125;反编译之后得到123456789101112131415public static void main(String args[]) &#123; String str = "world"; String s; switch((s = str).hashCode()) &#123; case 99162322: if(s.equals("hello")) System.out.println("hello"); break; case 113318802: if(s.equals("world")) System.out.println("world"); break; default: break; &#125; &#125;首先调用String的hashCode方法，拿到相应的Code，通过这个code然后给每个case唯一的标识判断时先获取对象的hashCode，进入对应的case分支通过equals方法进行安全检查，这个检查是必要的，因为哈希可能会发生冲突switch只支持整型，其他数据类型都是转换成整型之后在使用switch的总结String被final修饰，一旦被创建，无法修改final保证value不会指向其他的数组，但不保证数组内容不可修改private属性保证不可在类外访问数组，也就不能改变其内容String内部没有改变value内容的函数，保证String不可变String声明为final杜绝了通过集成的方法添加新的函数基于数组的构造方法，会拷贝数组元素，避免了通过外部引用修改value的情况用String构造其他可变对象时，返回的数组的拷贝final只在编译期有效，在运行期间无效，因此可以通过反射改变value引用的对象。反射虽然改变了s的内容，并没有创建新的对象。而且由于String缓存了hash值，所以通过反射改变字符数组内容，hashCode返回值不会自动更新。String类的所有方法都没有改变字符串本身的值，都是返回了一个新的对象。如果你需要一个可修改的字符串，应该使用StringBuilder或者 StringBuffer。如果你只需要创建一个字符串，你可以使用双引号的方式，如果你需要在堆中创建一个新的对象，你可以选择构造函数的方式。]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal深度解析]]></title>
    <url>%2Fposts%2Fcadd278f%2F</url>
    <content type="text"><![CDATA[ThreadLocal解决什么问题ThreadLocal不是用来解决共享对象的多线程访问问题的，不同的Thread通过ThreadLocal获取到的是不同的副本（实际是不同的实例）。线程内部的副本是其他线程不需要访问也是访问不到的。当某一个类不是线程安全，同时该类的实例需要在多个方法中被使用且每个线程需要自己独立的实例时，可以使用ThreadLocal来解决这一问题。ThreadLocal实现原理错误方式既然每个Thread通过ThreadLocal.get()获得的都是自己的一个副本，一个通常的实现方法是ThreadLocal自己维护一个Map，key是Thread，value是该线程中的副本。线程通过get()获取实例时，可以以线程（通过Thread.currentThread()获取当前线程）为key，从Map中找出对应的实例即可。但是该实现方式存在以下问题：Map作为全局变量，增加或减少线程均需要写Map，需要通过加锁来确保Map的线程安全性线程结束时，需要从该线程访问过的所有ThreadLocal中删除副本，否则可能会引起内存泄露正确方式为了提高ThreadLocal效率，需要去掉锁机制。如果Thread维护一个自己的Map，该Map存储所有用到的本地副本，这样每个Thread只需要访问自己的Map，不存在写冲突，也就不需要锁了。该方案虽然没有锁的问题，但是在每个线程内部都保存了该线程用到的本地副本。如果不删除这些引用，会导致这些副本无法被垃圾回收，造成内存泄露。ThreadLocal在JDK8中的实现ThreadLocalMap类ThreadLocalMap是ThreadLocal的静态内部类，对ThreadLocal进行的get、set操作最后都将委托给该类。同时每个Thread内部都有一个ThreadLocalMap变量，用于保存本线程用到的副本。它的结构如下：可以看到ThreadLocalMap有一个常量和三个成员变量：1234567891011121314151617181920/** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * The number of entries in the table. */ private int size = 0; /** * The next size value at which to resize. */ private int threshold; // Default to 0其中INITIAL_CAPACITY代表了这个Map的初始容量，即table的初始大小；table是一个Entry类型的数组，用于存储数据；size代表table中的存储数目；threshold代表需要扩容是对应size的阀值，默认为容量的2/3。Entry类Entry类是ThreadLocalMap的静态内部类，是线程本地副本真正保存的位置，源码如下：123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125;可见Entry继承自WeakReference&lt;ThreadLocal&lt;?&gt;&gt;，即每个Entry对象都有一个ThreadLocal的弱引用。这样当线程结束，没有引用指向线程内部的ThreadLocalMap变量时，table数组可以被垃圾回收，如此便可以防止内存泄露。Object类型的成员变量value，指向Thread用到的ThreadLocal中的本地副本。ThreadLocal.set()方法设置实例的方法如下所示：12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;线程首先通过getMap(thread)方法获取自身的ThreadLocalMap。因为ThreadLocalMap是线程私有的，只有该线程才能访问，其他线程访问不到，所有不用考虑线程安全问题。123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;从getMap源码中可见，该ThreadLocalMap的实例是Thread类的一个字段，即由ThreadLocal对象与具体实例的映射，这一点与上文分析一致。获取到ThreadLocalMap后，若map为null，调用createMap方法来创建一个ThreadLocalMap，在createMap中调用ThreadLocalMap的构造函数，返回设置了首元素的ThreadLocalMap。1234567ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);&#125;firstKey为当前调用的ThreadLocal，firstValue为set(T value)中的value。在构造函数中注意一个细节，计算下标i的时候采用了hashcode &amp; (size - 1)的算法，这相当于取模运算hashCode % size的一个更高效的实现。同时因为采用了该算法，size必须是2的指数，这可以使得hash发生冲突的次数减小。若map不为null，则调用ThreadLocalMap的set(ThreadLocal, Ojbect)方法将实例设置到table数组中。源码如下：1234567891011121314151617181920212223242526private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;首先计算该元素的hash值，如果冲突了，通过nextIndex方法再次计算hash值。nextIndex实际上获取数组的下一个下标，若已到数组最后一个元素则返回0，即返回到数组第一个元素。因此ThreadLocalMap解决冲突的方法是线性探测法。如果table中已经存在，则仅仅是更新Entry中的value值。如果entry里对应的key为null的话，表明该entry为staled entry，则调用replaceStaleEntry函数用于替换原有的key和value并进行一些清理操作(清理其他key为null的Entry防止内存泄露)，有兴趣的同学可以查看源码具体实现。若是经历了上面步骤没有命中hash，也没有发现无用的Entry，set方法就会创建一个新的Entry，并会进行启发式的垃圾清理，用于清理无用的Entry。主要通过cleanSomeSlots方法惊醒清理（清理时机通常为添加新元素或另一个无用的元素被回收时）。只要没有清理任何的stale entries并且size达到阀值的时候，就会触发rehash：1234567private void rehash() &#123; expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis if (size &gt;= threshold - threshold / 4) resize();&#125;rehash会先调用expungeStaleEntries函数，执行一次全表扫描，用于删除无用的entry。清理之后的size仍大于等于threshold的3/4时进行resize扩容（长度增加一倍）。通过replaceStaleEntry和rehash这两个方法会即时将table中无效的entry设置为null，从而使得entry可被回收，有效的防止了内存泄露。ThreadLocal.get()方法获取实例的方法如下所示12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;同set方法，首先通过getMap方法获取线程内部的ThreadLocalMap对象。若map和entry都不为null，说明线程内部存在对应副本，直接返回即可。若不存在，调用setInitialValue方法获取该ThreadLocal变量在该线程中对应的具体实例的初始值。12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;该方法为private方法，无法被重载。但是在方法中首先调用了initialValue方法来获取初始值。123protected T initialValue() &#123; return null;&#125;initialValue方法是protected的，说明是用来被继承的。所以在使用ThreadLocal时通常会重载该方法。拿到该线程对应的ThreadLocalMap对象，如该对象不为null，则直接将该ThreadLocal对象与对应实例初始值的映射set到该map中，否则创建该map并将其添加其中。若map存在，get操作最终会调用ThreadLocalMap的getEntry方法：12345678910111213141516171819202122232425private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125;hash以后如果是ThreadLocal对应的Entry就返回，否则调用getEntryAfterMiss方法，根据线性探测法继续查找，直到找到或对应entry为null，并返回。ThreadLocal.remove()方法删除实例的方法如下所示123456public void remove()&#123; ThreadLOcalMap m = getMap(Thread.currentThread()); if (m != null)&#123; m.remove(this); &#125;&#125;同理，remove方法也是先获取Thread中的ThreadLocalMap实例。若map不为null，这调用map的remove方法，从table中将entry删除。适用场景ThreadLocal适用如下场景每个线程需要有自己单独的实例实例需要在多个方法中共享应用案例在Web中，通常使用Session在各个页面中传递信息。每个客户端对应于Web中的一个线程，需要保证线程有自己单独的Session实例；而线程内部的各方法又需要共享Session。如不使用ThreadLocal，其实现方式如下：1234567891011121314151617public class Web&#123; public static class Session&#123; private string username; private int age; .... // get/set方法 &#125; public Session createSession()&#123; return new Session(); &#125; public string getUsername(Session session)&#123; return session.getUsername(); &#125; public int getAge(Session session)&#123; return session.getAge(); &#125;&#125;总结Entry会被清理的场景：Thread结束之后被垃圾回收处理set一个变量时，发现staled entry。进行替换并清理set一个变量时，size大于阀值时，调用rehash方法清理并扩容调用remove方法时，删除该entry并清理发现的staled entry尽管采用了弱引用的ThreadLocalMap不会造成内存泄露，但是并不能保证staled entry被及时清理。因此我们在使用完ThreadLocal后最好还是remove一下（使用线程池时一定要即时remove，线程使用后归还给了线程池，并没有销毁），保证即时回收无用的Entry。]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的functools模块]]></title>
    <url>%2Fposts%2Ff6b0a560%2F</url>
    <content type="text"><![CDATA[functools.partial(func[, *args][, **keywords])该函数通过包装手法，允许我们”重新定义”函数。返回用args和keywords填充了func指定位置参数后的函数，调用该函数只需传入原函数未填充的参数。123from functools import partialbasetwo = partial(int, base=2)basetwo('10010')basetwo(‘10010’)实际上等价于调用int(‘10010’, base=2)@functools.singledispatch使用过面向对象语言的同学，肯定熟悉各种方法的重载。虽然Python不支持方法重载的，但是我们可以添加@functools.singledispatch注解来动态指定相应的方法所接收的参数类型。12345678910111213from functools import singledispatchclass TestClass(object): @singledispatch def test_method(arg, verbose=False): if verbose: print('Let me just say,', end=' ') print(arg) @test_method.register(int) def _(arg): print('Strength in numbers, eh?', end=' ') @test_method.register(list) def _(arg): print('Enumerate this:')通过@test_method.register(int)和@test_method.register(list)指定当test_method的第一个参数为int或者list的时候，分别调用不同的方法来进行处理。functools.update_wrapper(**wrapper, wrapped)默认partial对象没有__name__和__doc__，这种情况下，对于装饰器函数非常难以debug。使用该函数可以将被封装函数的这些属性复制到封装函数中。12345678def my_decorator(f): def wrapper(*args, **kwds): print('print in wrapper') return f(*args, **kwds) return update_wrapper(wrapper, f)@my_decoratordef example(): print('print in example')@functools.wraps该注释内部调用了functools.update_wrapper()函数，简化编码复杂度。12345678910from functools import warpsdef my_decorator(f): @warps(f) def wrapper(*args, **kwds): print 'print in wrapper' return f(*args, **kwds) return wrapper@my_decoratordef example(): print 'print in example'@functools.lru_cache(maxsize=None, typed=False)@lru_cache用于缓存函数返回的结果，对于重复的调用直接从缓存中获取返回值。如果maxsize设置为None，则缓存没有上界。如果typed设置为true，则对于不同的参数类型会区别缓存。12345678from functools import lru_cache@luc_cache(None)def add(x, y): print('calculating: %s + %s' % (x, y)) return x + yprint(add(1, 2))print(add(1, 2))print(add(2, 3))输出结果：12345calculating: 1 + 233calculating: 2 + 35@functools.total_ordering这是一个类装饰器，用于自动实现类的比较运算。若自定义类中实现了__eq__和__lt__、__gt__、__ne__、__le__、__ge__中的一个，带有@total_ordering装饰的类会自动实现剩下的函数 。functools.cmp_to_key(func)该函数用于将旧式的比较函数转化为key(关键值)函数并应用于接受key function的工具类中(sorted(), min(), max(), heapq.nsamllest(), heapq.nlargest(), itertools,groupby())12from functools import cmp_to_keysorted(iterable, key=cmp_to_key(cmp_func))functools.reduce(func, iterable, [, initializer])与python2中的内建函数reduce等价]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git简明教程]]></title>
    <url>%2Fposts%2F6326f1e4%2F</url>
    <content type="text"><![CDATA[Git简介Git是目前世界上最先进的分布式版本控制系统。在Git出现之前，版本控制系统主要是集中式占据着绝对的统治地位，以CVS和SVN为代表。集中式版本控制系统中版本库集中存放在中央服务器，写代码的时候我们要先从中央服务器拉取最新版本，开发完成之后再讲版本推送到中央服务器，这就意味着必须联网才能工作，也存在代码丢失的风险。分布式版本控制系统去掉了中央服务器的概念，每个开发人员本地都有一份完整的版本库，在没有网络时也能进行开发工作。虽然分布式版本控制系统中去掉了中央服务器，但是为了协同开发人员之间的工作，通常会有一台充当“中央服务器”的电脑。如果不想搭建自己的gitlab服务器，可以选择第三方代码仓库，如github、coding.net、git.oschina等。配置因为Git是分布式版本控制系统，在将代码push到远程仓库时，需要告诉仓库提交者的身份。所以在安装完Git之后需要进一步配置，在命令行输入：12$ git config --global user.name "Your Name"$ git config --global user.email "email@example.com"注意git config命令的--global参数表示本机中的所有Git仓库都会使用这个配置，若想只针对当前仓库进行配置可以去掉--global参数。版本库创建版本库版本库又叫仓库，可以简单的理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除Git都能跟踪，以便在将来的某个时候将文件还原回之前的版本。创建版本库时，首先将路径切换到目标目录，执行：12$ git initInitialized empty Git repository in C:/Users/windylee/Desktop/repository/.git/这时该目录就会成为Git的一个本地仓库。这是在当前目录下就会多一个.git的目录，这个目录就是Git用来跟踪管理版本库的，千万不要手动修改这个目录里面的文件。将文件添加到版本库Git只能跟踪文本文件的改动，比如txt、网页、程序代码等等，二进制文件虽然也能有Git管理，但是不能跟踪文件的变化。进入我们的本地仓库，创建一个readme.txt文件，在里面随便写点内容保存。第一步，用命令git add告诉Git，把文件添加到仓库：1$ git add readme.txt第二步，用命令git commit告诉Git，把文件提交到仓库:1234$ git commit -m "write a readme.txt file"[master (root-commit) 096895b] write a readme.txt file 1 file changed, 1 insertion(+) create mode 100644 readme.txt-m后面输入的是本次提交的说明，可以输入任意内容，但最好可以描述本次修改的内容，引文输入说明对自己对别人阅读都很重要。commit命令输出：第一行给出了本次commit的hash值，剩下的内容描述本次修改的内容（修改了1个文件，在该文件中插入了两行）。如果本次修改文件过多，不想一个个add文件，可以通过命令：1$ git add --all这条命令会将所有修改的文件一次全部添加到仓库。版本控制查看状态123456789$ git statusOn branch masterChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txtno changes added to commit (use "git add" and/or "git commit -a")通过git status命令我们可以时刻掌握仓库的当前状态，上面的命令告诉我们readme.txt文件被修改过了，但是还没有添加到仓库。在每次执行Git命令前运行该命令是一个较好的习惯。如果修改内容过多，时间长了我们就不知道修改了文件的哪些内容。这是可以通过git diff命令来查看文件修改的内容12345678$ git diff readme.txtdiff --git a/readme.txt b/readme.txtindex 8f6e0fc..9468d46 100644--- a/readme.txt+++ b/readme.txt@@ -1 +1,2 @@ Git is a version control system+happy coding.显示的内容是本地文件与版本库中文件的difference，显示的格式正是Unix通用的diff格式。版本回退123456789101112$ git logcommit 3703210c919521c63f457341419b6daa3f38083fAuthor: windylee &lt;liwangadd@gmail.com&gt;Date: Fri Jan 12 13:52:29 2018 +0800 add happy coding linecommit 096895bbf40546221e12c16a4ea1a77d6565b16eAuthor: windylee &lt;liwangadd@gmail.com&gt;Date: Fri Jan 12 13:32:28 2018 +0800 write a readme.txt filegit log命令显示从最近到最远的提交日志，可以看到我们总共有两次提交。如果嫌输出信息太多，可以加上--pretty=oneline参数，一次提交日志就会在一行显示：123$ git log --pretty=oneline3703210c919521c63f457341419b6daa3f38083f add happy coding line096895bbf40546221e12c16a4ea1a77d6565b16e write a readme.txt file如果我们想返回上一个版本，可以使用如下命令：1$ git reset --hard HEAD^若要返回上一个版本，首先要先知道当前版本是哪个版本。在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上个版本就是HEAD^^。如果要返回上100各版本怎么办，由于每次commit都会产生一个hash值作为本次提交的唯一标识，可以将HEAD^换成会返回版本的hash值(取前7位即可)。1git reset --hard 3703210暂存区创建仓库之后，目录中会多出.git目录。该目录就是Git的版本库，其中包括成为stage的暂存区，还有自动创建的master分支以及指向master的HEAD指针。在执行git add命令时，是将文件修改添加到暂存区，执行git commit命令则是将暂存区中的内容提交到当前分支并将暂存区清空。撤销修改1$ git checkout --readme.txt命令git checkout -- filename会把文件在工作区的修改全部撤销，若文件修改后还没有添加到暂存区，撤销修改就回到和版本库一样的状态；若文件已经添加到暂存区，之后又做了修改，撤销修改就回到添加到暂存区后的状态。若文件修改已添加到暂存区，而要删除暂存区中的文件修改内容。可以使用如下命令：1$ git reset HEAD readme.txt该命令可以把暂存区的修改撤销掉，重新放回工作区。删除文件在Git中，删除也是一种修改操作。可以直接在文件管理器中将文件删除，这时工作区和版本库就不一致了。可以选择从版本库中删除该文件，使用git rm将文件从版本库删除掉，并且git commit。或者是误删，这是可以将文件从版本库中回复到最新版本：1git checkout -- readme.txtgit checkout是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。远程仓库添加远程仓库在我们开发时，通常将代码托管到github上。这样，github上的仓库既可以作为备份，又可以让其他人通过该仓库来协作。在github上创建一个新仓库之后，在本地仓库下运行如下命令：1$ git remote add origin git@github.com:liwangadd/repository.git这是本地仓库就将github上的相应仓库作为托管平台。下一步就可以把本地库的所有内容推送到远程库上：1$ git push -u origin master由于远程仓库是空的，我们第一次推送master分支时，加上-u参数。Git不但会把本地的master分支内容推送到远程新的master分支，还会把本地的master分支和远程的master分支关联起来。从远程库克隆进入到我们想要克隆到本地的项目主页，获取到仓库地址。使用如下命令将远程仓库clone到本地：1$ git clone https://github.com/yaochenkun/aiop-notice.git如果有多个人协作开发，那么每个人各自从远程clone一份就可以了。分支管理创建与合并分支创建dev分支，然后切换到dev分支：12$ git checkout -b devSwitched to a new branch 'dev'git checkout命令加上-b参数表示创建并切换分支，相当于以下两条命令：123$ git branch dev$ git checkout devSwitched to a new branch 'dev'然后就可以用git branch命令查看当前分支123$ git branch* dev mastergit branch命令会列出所有分支，当前分支前面会标一个*号git merge命令用于合并指定分支到当前分支：12345$ git merge devUpdating d17efd8..fec145aFast-forward readme.txt | 1 + 1 file changed, 1 insertion(+)注意到上面的Fast-forward信息，Git告诉我们，这次合并是”快进模式”，也就是直接把master指向dev的当前提交。但是在这种模式下，删除分之后，会丢掉分支信息。如果强制禁用Fast-forward模式，Git就会在merge时生成一个新的commit，这样从分支历史上就可以看出分支信息。强制禁用Fast-forward模式，可以使用--no-off参数，因为合并会创建一个新的commit，所有加上-m参数，把commit描述写进去。1$ git merge --no-ff -m "merge with no-ff" dev分支合并完成后，如果dev分支不需要了，可以将该分支删除:1git branch -d dev因为创建、合并和删除分支非常快，所以当我们要完成某个任务时，可以先创建分支，在新的分支上开发完成再合并到主分支。Bug分支若当前正在dev分支上进行工作，需要切换到其他分支工作，而dev分支上的任务还没有完成，不能提交到暂存区。这时可以使用stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作。123$ git stashSaved working directory and index state WIP on dev: 3703210 add happy coding lineHEAD is now at 3703210 add happy coding line这是就可以切换到其他分支进行工作了，工作完成回到该分支，可以使用git stash list命令查看工作现场。12$ git stash liststash@&#123;0&#125;: WIP on dev: 3703210 add happy coding line可以看到，工作现场还在。Git把stash内容存在了某个地方了，若要将stash的内容恢复到工作区，有两个办法：用git stash apply恢复，但是恢复后，stash内容并不删除，需要用git stash drop来删除用git stash pop，恢复的同时把stash内容删了若执行了多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令：1$ git stash apply stash@&#123;0&#125;强行删除分支如分支没有合并，使用git branch -d dev命令会提示分支没有合并，删除失败。如果要强行删除，需要使用命令git branch -D dev。12$ git branch -D devDeleted branch dev (was 3703210).多人协作标签管理发布一个版本时，我们通常现在版本库中打一个标签，这样唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以标签也是版本库的一个快照，其实就是指向某个commit的指针。由于commit给出的是一个hash值，不好记忆，所以才引入了标签这个概念。创建标签使用git tag &lt;name&gt;命令可以打一个标签：1$ git tag v1.0可以用命令git tag查看所有标签。默认标签是打在最新提交的commit上的，若想打在之前某个commit上面，就需要根据历史提交的commit id打标签：]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门教程]]></title>
    <url>%2Fposts%2F750751bd%2F</url>
    <content type="text"><![CDATA[介绍Nginx是一个开源、高性能的HTTP服务器和反向代理服务器，还可以用来作为IMAP/POP3的代理服务器，其处理静态文件、索引文件的效率非常高。相比于apache的多进程多线程的并发模型，Nginx是基于事件的异步IO的并发模型，支持epoll/kqueue等网络IO模型。安装安装Nginx主要有两种方式，通过仓库中的二级制包安装和源码安装。在Ubuntu系统中可以通过sudo apt-get install nginx从官方仓库中安装，这种安装方式可以满足用户的基本需求。但如果对Nginx的精简度和性能有非常高的要求，就需要通过源码的方式安装，分为以下三步：123./configuremakesudo make install如果要对Nginx进行定制，就需要在第一步制定需求，主要参数如下：–conf-path 指定配置文件的位置，默认为/etc/nginx/nginx.conf–error-log-path 指定错误日志文件所在位置，默认为/var/log/nginx/error.log,安装完成后可在配置文件中进行配置–http-log-path 指定http连接日志文件所在位置，默认为/var/log/nginx/access.log–with-模块名称 该模块会被编译–without-模块名称 编译时将该模块排除在外源码安装完成之后，默认Nginx服务已经启动。若想手动启动Nginx服务可以通过sudo service nginx start,同理关闭或者重启可以通过sudo service nginx stop/restart。 虽然Nginx重启速度很快，但是每次修改配置文件后，仅仅想让配置文件生效可以通过sudo nginx -s reload 命令，而不用重启服务配置文件详解Nginx是模块化的系统，整个系统被分成一个个的模块，每个模块负责不同的功能。例如http_gzip_static_module是负责压缩的，http_ssl_module是负责加密的。如果想使用某个模块需要在编译时将其加入其中，使用被编译的模块需要通过指令，整个配置文件就是通过指令组成的。默认的配置文件位于/etc/nginx/nginx.conf，内容如下12345678910111213141516171819202122232425262728user nginx;worker_processes 1;pid /run/nginx.pid;events &#123; worker_connections 768;&#125;http &#123; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; gzip on; gzip_disable "msie6"; include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125;可以看到，配置文件主要由两个block组成。Nginx是存在三个顶级block的，分别是123456events &#123;&#125;http &#123;&#125;mail&#123;&#125;从配置文件中可以看出：events模块中包含nginx中所有处理连接的设置，可以通过worker_connections指定每个工作进程可以同时接受的最大连接数；http模块主要是用来配置web服务，可以用于指定是否启用压缩，是否支持发送文件等；mail模块用来配置IMAP/POP3代理。我们主要关注http模块，如果Nginx的配置文件过大，将全部配置写在同一文件中将难以维护，此时可以将不同用途的配置写在不同的配置文件中，通过include指令加载进来。如果想要部署一个网站，就需要在http模块中添加一个server块。下面看一个例子。12345678910111213141516171819server &#123; listen 80; server_name example.org www.example.org; root /usr/nginx/www; location / &#123; index index.html index.php; &#125; location ^~ /images/ &#123; index icon.html; &#125; location ~* \.(gif|jpg|png)$ &#123; expires 30d; &#125; error_page 500 502 503 /50x.html;&#125;在电脑中的hosts文件中，加入一行127.0.0.1 www.example.org，在浏览器中输入www.example.org就可以访问了。该配置中通过listen表明监听80端口，通过server_name指定网站的域名，通过root指定网站的根目录，最下面的error_page说明当服务器发生500、502、503错误时，将网站根目录下的50x.html返回给用户。下面我们主要关注location指令，location用于URL模式设置，可以看到在匹配的URL开头有一些特殊符号，不同的符号用于限定在匹配时采用的特殊规则：=开头表示精确匹配，与指定字符串有任何区别将不能匹配成功^~开头表示匹配以指定字符串开头的URL，不适用正则~开头表示区分大小写的正则匹配~*开头表示不区分大小写的正则匹配/通用匹配，如果所有匹配都失败，则返回该默认匹配各种匹配的优先级为：(=) &gt; (完整路径) &gt; (^~) &gt; (~, ~*) &gt; (location 部分起始路径) &gt; (/)。在上面的配置文件中的$符号是正则表达式中的结束标志。在最后一个location中有expires指令，该指令的作用是让Nginx缓存请求返回的信息(这里是图片静态文件)，缓存的有效期的30天。反向代理代理可以分问正向代理和反向代理。正向代理的步骤是：用户要访问服务器C，而用户的请求会先到达代理服务器B，然后B再将用户请求转发到服务器C，此时代理服务器B才是真正访问服务器C的，代理服务器B再将得到的结果转发给用户。在这个过程中用户就像直接访问服务器C一样，过程中不知道代理服务器的存在。而反响代理的步骤是：用户只知道代理服务器的地址，通过该地址直接访问代理服务器B，代理服务器B将请求转发给真正的服务提供者C，得到结果后再返回给用户。用户根本不知道服务提供者的地址或者完全不能访问到，整个过程用户是直接与代理服务器B交互的。反向代理可以用来隐藏和保护原始服务器，实现负载均衡，加密和SSL加速等。Nginx的反向代理是通过ngx_http_proxy_module这个模块实现的，nginx可以代理的协议有http(s)、fastcgi、uswgi、memcached等。下面是实现的一个简单代理服务器的配置文件。123456789101112131415161718192021....http&#123; .... upstream java_demo&#123; # 实际服务器的地址 server 127.0.0.1:8080; &#125; server &#123; server_name www.example.com; listen 443; proxy_connect_timeout 180; # nginx跟后端服务器连接超时时间(代理连接超时) proxy_send_timeout 180; proxy_read_timeout 180; # 连接成功后，后端服务器响应时间(代理接收超时) proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; location / &#123; # 将请求转发到实际服务提供者 proxy_pass http://java_demo; &#125; &#125;gzip压缩当css文件和js文件过大时，可以通过压缩的机制提高网站的加载速度。Nginx通过ngx_http_gzip_module模块实现对文件的压缩操作，启用压缩要在配置文件中指定。123456789101112131415161718....http &#123; gzip on; gzip_disable "msie6"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; server &#123; location ~ ^/assets/ &#123; gzip_static on; expires max; add_header Cache-Control public; &#125; &#125;&#125;使用gzip指令来启用gzip压缩功能，使用gzip_types限制了要压缩的文件类型。这两个属性时必须配置的，其他属性根据需要进行配置。同时需要在要启用压缩的location块中加入配置文件中的那三行。负载均衡听说过nginx的人肯定都知道其在负载均衡中的重要角色，几乎成熟的网站都会使用nginx作为负载均衡服务器。同时nginx也在不断发展，在1.9版本之前其只能作为http的负载均衡，而在1.9之后其也实现了对tcp进行负载均衡。nginx负载均衡模块实现了如下4种调度方式：round-robin：Nginx默认的轮询算法，每个请求按时间顺序逐一分配到不同的后端服务器。可以通过weight指定轮询权值，权值越大表明被访问到的可能性越大。1234upstream java_demo &#123; server 127.0.0.1:8080 weight=2; server 127.0.0.1:8081 weight=1;&#125;​least_conn：请求会被发送到活跃连接数最少的服务器上。12345upstream java_demo &#123; least_conn; server 127.0.0.1:8080; server 127.0.0.1:8081;&#125;​ip_hash：根据访问用户ip的hash结果分配请求，相同的ip总是会被分配到同一台应用服务器。12345upstream java_demo &#123; ip_hash; server 127.0.0.1:8080; server 127.0.0.1:8081;&#125;​hash：相比于ip_hash方式，这是一个粒度更小的控制，ip_hash默认是用户ip的hash值。而该方式根据指定字段的hash值进行分配。12345upstream java_demo &#123; hash $request_uri; # 根据请求地址分配 server 127.0.0.1:8080; server 127.0.0.1:8081;&#125;nginx对负载均衡提供了很好的支持，相对于反向代理，我们只需在upstream块中添加多个server地址和指定负载均衡算法，nginx就可以根据我们指定的负载均衡算法分发用户请求。在配置负载均衡时，upstream块中的server可以有如下配置参数down。加入该字段的server将暂时不参与负载均衡，对该服务器的请求会自动发送到下一个服务器。backup。预留的备份服务器，当其他所有的非backup都出现故障或者忙的时候，才会将请求发送到该服务器。weight。指定该服务器被访问到的概率，值越大被访问到的概率越高，默认weight的权值为1。max_fails。表示请求失败的次数，若某一服务器对同一请求失败超过max_fails次，则将该请求发送到下一服务器。max_timeout。表示请求失败的超时时间，在设定的时间内没有成功，就作为失败处理。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring定时任务]]></title>
    <url>%2Fposts%2F4016a806%2F</url>
    <content type="text"><![CDATA[关于spring的定时任务，我们在spring3.0之前一般会使用Quartz，这是一个功能相当强大的调度器，可以让你的程序在指定时间执行，也可以按照某个频度执行，但是配置起来稍显复杂。Spring3.0以后自带task，可以将它看成一个轻量级的Quartz，使用起来比Quartz简单许多，不需要额外的包，而且支持注解和配置文件两种形式。基本使用配置文件方式首先需要在配置文件中引入task命名空间12345&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:task="http://www.springframework.org/schema/task" ... http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd"&gt;然后配置需要定时执行的任务12345678&lt;!--Spring定时器注解开关，注册之后可以再java类中使用task命名空间的注解--&gt;&lt;task:annotation-driven scheduler="myScheduler"/&gt; &lt;!--内部使用的线程池，配置线程池，指定线程池的大小--&gt; &lt;task:scheduler id="myScheduler" pool-size="10&gt; &lt;!--配置定时任务，指定需要定时执行的类和方法，并配置调度方式--&gt; &lt;task:scheduled-task scheduler="myScheduler"&gt; &lt;task:scheduled ref="scheduledTaskManager" method="autoCardCalculate" cron="0 5 * * * *"/&gt; &lt;/task:scheduled-task&gt;注解形式首先我们看一下源码中注解的定义123456789101112131415161718192021@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(Schedules.class)public @interface Scheduled &#123; String cron() default ""; String zone() default ""; long fixedDelay() default -1L; String fixedDelayString() default ""; long fixedRate() default -1L; String fixedRateString() default ""; long initialDelay() default -1L; String initialDelayString() default "";&#125;我们可以看到该注解有八个参数，分别表示的意思是：cron：指定cron表达式zone：指定时区fixedRate：从上一个任务开始到下一个任务开始的间隔，单位是毫秒fixedDelay：从上一个任务完成到下一个任务开始的间隔，单位是毫秒initialDelay：任务第一次执行前需要延迟的毫秒数这些配置参数都可以在xml配置文件中使用，效果是一样的执行任务的POJO类1234567891011121314151617181920212223242526public class ScheduledTaskManager&#123; /** * 每日凌晨2点执行一次 */ @Scheduled(cron = "0 0 2 * * *") public void autoCardCalculate() &#123; System.out.println("hello world" + new Date()); &#125; /** * 心跳更新，启动时执行一次，之后每隔一分钟执行一次 */ @Scheduled(fixedRate = 1000 * 60) public void heartbeat() &#123; System.out.println("hello world" + new Date()); &#125; /** * 启动后一秒钟之后执行一次，之后每次执行完间隔2分钟执行一次 */ @Scheduled(fixedDelay = 1000 * 60 * 2, initialDelay = 1000) public void persistRecord() &#123; System.out.println("hello world" + new Date()); &#125;&#125;组合多个Scheduled@Scheduled可以让我们很方便的配置定时任务，但是有的定时任务不是一个表达式就能表达完全的，比如说我既想在周三10:10又想在周四17:40执行某项任务。这时候我们很难用一个表示式，或者根本行不通，这时候我们就要组合多个@Scheduled表达式。@Schedules注解里面只有一个参数Scheduled数组，意味着我们可以将多个@Scheduled压入数组，组合使用12//每隔18秒执行一次，并且每天的4:00执行一次@Schedules(&#123;@Scheduled(cron = "* * 4 * * *"),@Scheduled(fixedRate = 1000*18)&#125;)cronExpression的配置说明各字段意义字段允许值允许的特殊字符秒0-59, - * /分0-59, - * /小时0-23, - * /日期1-31, - * /月份1-12或JAN-DEC, - * /星期1-7或SUN-SAT, - * /年（可选）留空，1970-2099, - * /- 指定区间* 通配符? 你不想设置那个值/ 没多少执行一次例子CRON表达式含义0 0 12 * * ?每天中午12点触发0 15 10 ? * *每天上午10:15触发0 15 10 * * ?每天上午10:15触发0 15 10 * * ? *每天上午10:15触发0 15 10 * * ? 20152015年的每天上午10:15触发0 * 14 * * ?每天下午14:00到14：59每分钟触发一次0 0/5 14 * * ?每天下午14:00到14:55没5分钟触发一次0 0/5 14,18 * * ?每天14:00到14:55和18:00到18:55每5分钟触发一次0 0-5 14 * * ?每天14:00前五分钟每分钟触发一次0 10,44 14 ? 3 WED3月每周三14:10和14:44触发0 15 10 ? * MON-FRI周一到周五的10:15触发]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring异步任务]]></title>
    <url>%2Fposts%2Fc0ceddf6%2F</url>
    <content type="text"><![CDATA[在Spring3.0之前如果我们想要异步执行某项任务，需要我们自己编写线程池来实现。在Spring3.X新增了注解@Async，可以标记方法或者类中的所有方法都可以异步执行，而调用他的方法会在原来的线程中执行。这样可以避免阻塞，保证任务的实时性。适用于处理log，发送邮件等#### 配置##### 配置文件同Spring自己实现的定时任务一样，我们需要在配置文件中引入task命名空间123456789101112&lt;beans xmlns="http://www.springframework.org/schema/beans"​ xmlns:task="http://www.springframework.org/schema/task"​ ...​ http://www.springframework.org/schema/task​ http://www.springframework.org/schema/task/spring-task.xsd"&gt;\然后配置相关的线程池和缺省的异步调度器\123456789101112&lt;!--配置executor，一个应用中可以有多个executor--&gt;&lt;task:executor id="mailExecutor" pool-size="10" keep-alive="100" queue-capacity="5" rejection-policy="ABORT"/&gt;&lt;task:executor id="logExecutor" pool-size="10"/&gt;&lt;!--指定一个缺省的executor给@Async使用，当@Async没有指定使用哪个executor将默认使用该executor--&gt;&lt;task:annotation-driven executor="mailExecutor"/&gt;\##### 配置参数- id: 当配置多个executor时，被@Async(“id”)指定使用，也可以作为线程名的前缀- pool-size 指定线程池的大小- queue-capacity：当最小的线程数已经被占用满后，新的任务会被放进queue里面，当这个queue的capacity也被占满之后，pool里面会创建新线程处理这个任务，直到总线程数达到了max size，这是系统会拒绝这个任务并抛出TaskRejectedException异常(可以通过rejection-policy来决定如何处理这种情况)，缺省值为Integer.MAX_VALUE- keey-alive：超过core size的那些线程，任务完成后，经过这个时长就会被结束掉- rejection-policy：当pool已经达到max size的时候，如何处理新任务ABORT（缺省）：抛出TaskRejectedException异常，然后不执行DISCARD：不执行，也不抛出异常DISCARD_OLDEST：丢弃queue中最旧的那个任务CALLER_RUNS：不在新线程中执行任务，而是有调用者所在的线程来执行#### 注解##### 注解源码\1234567891011121314@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Async &#123;​ String value() default "";&#125;\通过@Async的源码我们可以知道，该注解可以用在方法上也可以用在类上，注解在方法上表明该方法是一部执行的，注解在类上表明该类中的所有方法都是一步执行的##### 方法返回值如果我们不想从异步线程中获取返回值，那么我们可以将返回值声明为void。如果我们想要从线程中获取数据，可以使用Future作为返回值。通过future.get()得到需要返回的对象，也可以使用future,get(time,unit)，在制定时间内获取返回值，如果超过设置的时间则抛出异常\1234567891011121314151617181920212223242526272829303132333435363738@Async("logExecutor")​ public void business() throws InterruptedException &#123;​ System.out.println("异步任务开始执行");​ Thread.sleep(2000);​ System.out.println("异步任务执行结束");​ &#125;​ /**​ \* 没有指定调度器将使用缺省值​ \* @return​ \* @throws InterruptedException​ */[^]​ @Async​ public Future&lt;String&gt; business2() throws InterruptedException &#123;​ System.out.println("异步任务开始执行");​ Thread.sleep(2000);​ System.out.println("异步任务执行结束");​ return new AsyncResult&lt;String&gt;("hello world");​ &#125;\`]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring拦截器]]></title>
    <url>%2Fposts%2F2b6e765e%2F</url>
    <content type="text"><![CDATA[处理器拦截器简介Spring MVC的处理器拦截器类型于Servlet开发中的Filter，用于对处理器进行预处理和后处理常见应用场景日志记录：记录请求信息的日志，以便进行信息监控、信息统计、计算PV（Page View）等权限检查：如登录检测，进入处理器检测检测是否登录，如果没有直接返回到登录页面性能监控：通过拦截器在进入处理器之前记录开始时间，在处理完后记录结束时间，从而得到该请求的处理时间通用行为：读取cookie得到用户信息并将用户对象放入请求，从而方便后续流程使用，还有如提取Locale、Theme信息等，只要是多个处理器都需要的即可使用拦截器实现。OpenSessionInView：如Hibernate，在进入处理器打开Session，在完成后关闭Session。本质也是AOP（面向切面编程），也就是说符合横切关注点的所有功能都可以放入拦截器实现。拦截器实现SpringMVC 中的Interceptor拦截请求是通过HandlerInterceptor来实现的。在SpringMVC中定义一个Interceptor非常简单，主要有两种方式，第一种方式是要定义的Interceptor类要实现了Spring 的HandlerInterceptor接口，或者是这个类继承实现了HandlerInterceptor接口的类，比如Spring 已经提供的实现了HandlerInterceptor接口的抽象类HandlerInterceptorAdapte；第二种方式是实现Spring的WebRequestInterceptor接口，或者是继承实现了WebRequestInterceptor的类。HandlerInterceptor接口12345678910111213141516public interface HandlerInterceptor &#123; boolean preHandle( HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; void postHandle( HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception; void afterCompletion( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception; &#125;有接口的定义我们可以看出HandlerInterceptor中定义了三个方法，我们就是通过这三个方法来对用户的请求进行拦截处理的。preHandle实现处理器的预处理，第三个参数为响应处理器（一般为Controller）。返回true表示继续流程；返回false表示中断流程，不会继续调用其他的拦截器和处理器，这时候我们需要通过response来产生响应。我们可以在该方法中进行一些前置初始化操作或者是对当前请求的一个预处理。postHandle实现处理器的后处理，但是在DispatcherServlet渲染页面之前调用，我们可以调用modelAndView进行模型数据进行处理或对视图进行处理afterCompleting视图渲染完毕后回调该方法，该方法主要用于数据清理如果我们继承自HandlerInterceptor接口，那么我们每次都需要重写三个方法。但是大多数时候我们只需要重写其中一两个方法，这时候我们可以继承HandlerInterceptorAdapter类，选择性的重写其中的方法。下面给出一个计算请求处理时间的例子123456789101112131415161718192021public class StopWatchHandlerInterceptor extends HandlerInterceptorAdapter &#123; private NamedThreadLocal&lt;Clock&gt; startTimeThreadLocal = new NamedThreadLocal&lt;Clock&gt;("StopWatch-StartTime"); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response,Object handler) throws Exception &#123; Cloxk start = Clock.now()//1、开始时间 startTimeThreadLocal.set(beginTime);//线程绑定变量（该数据只有当前请求的线程可见） return true;//继续流程 &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; Clock end = Clock.now();//2、结束时间 Clock start = startTimeThreadLocal.get();//得到线程绑定的局部变量（开始时间） long consumeTime = Duration.betwen(start, end).toMillis()//3、消耗的时间 System.out.println(String.format("%s consume %d millis", request.getRequestURI(), consumeTime)); &#125;&#125;WebRequestInterceptor接口该接口中也定义了三个方法，我们也可以通过这三个方法来实现拦截，这三个方法都传递了同一个参数WebRequest，三个方法的调用时机同HanlderInterceptor。WebRequest是Spring中定义的一个接口，方法基本和HttpServletRequest一样，对WebRequest做的任何操作都会同步到HttpServletRequest，然后在当前请求中一直传递preHandle(WebRequest request)由于没有返回值，无法控制请求流程。我们一般在该方法中进行资源的准备工作。比如我们在使用Hibernate的时候可以在这个方法中准备一个Hibernate的Session对象，然后利用WebRequest的setAttribute(name, value, scope)把它放到WebRequest 的属性中。这里可以说说这个setAttribute 方法的第三个参数scope：SCOPE_REQUEST ：它的值是0 ，代表只有在request 中可以访问。SCOPE_SESSION ：它的值是1 ，如果环境允许的话它代表的是一个局部的隔离的session，否则就代表普通的session，并且在该session范围内可以访问。SCOPE_GLOBAL_SESSION ：它的值是2 ，如果环境允许的话，它代表的是一个全局共享的session，否则就代表普通的session，并且在该session 范围内可以访问。postHandle(WebRequest request, ModelMap model)ModelMap 就是Controller 处理之后返回的Model 对象，我们可以通过改变它的属性来改变返回的Model 模型。afterCompletion(WebRequest request, Exception ex)可以在该方法中进行资源的释放操作，Exception 参数表示的是当前请求的异常对象，如果在Controller 中抛出的异常已经被Spring 的异常处理器给处理了的话，那么这个异常对象就是是null 。配置拦截器123456789&lt;mvc:interceptors&gt; &lt;bean class="com.windylee.interceptor.AllInterceptor"/&gt; &lt;mvc:interceptor&gt; &lt;!--指定拦截器的拦截路径--&gt; &lt;mvc:mapping path="/interceptor/**"/&gt; &lt;!--指定拦截器的实现类--&gt; &lt;bean class="com.windylee.interceptor.StopWatchHandlerInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;mvc:interceptors标签声明一系列的拦截器，然后它们就可以形成一个拦截器链，拦截器的执行顺序是按声明的先后顺序执行的，在mvc:interceptors标签下声明interceptor主要有两种方式：直接定义一个Interceptor实现类的bean对象。使用这种方式声明的Interceptor拦截器将会对所有的请求进行拦截。例子中的AllInterceptor会拦截所有请求使用mvc:interceptor标签进行声明。使用这种方式进行声明的Interceptor可以通过mvc:mapping子标签来定义需要进行拦截的请求路径。推荐推荐能使用servlet规范中的过滤器Filter实现的功能就用Filter实现，因为HandlerInteceptor只有在Spring Web MVC环境下才能使用，因此Filter是最通用的、最先应该使用的。如登录这种拦截器最好使用Filter来实现。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新的时间日期库]]></title>
    <url>%2Fposts%2Fb5a2dc36%2F</url>
    <content type="text"><![CDATA[综述时间API分类概述新的API： java.time，由5个包组成java.time- 包含值对象的基础包java.time.chrono - 提供对不同的日历系统的访问java.time.format - 格式化和解析时间和日期java.time.temporal - 包括底层框架和扩展特性java.time.zone - 包含市区支持的类我们平时只会用到基础和format包，也可能用到temporal包，因此虽然新的API提供了多达68个新的公开类型，但是我们一般只会用到其中的三分之一关键日期/时间概述不可变性。借鉴于java.util.Calendar的前车之鉴，设计这个API的时候着重考虑了原有方法的不可变性，不允许任何更改，如果必须改变的话就会返回一个新的实例，所以我们必须捕获该方法的返回值瞬间性。表示时间上的某个精确的时刻，使用从epoch开始计算的毫秒表示关键API使用Clock他可以通过时区来获取当前的instant，日期和时间。Clock类可以用来代替System.currentTimeMillis()和TimeZone.getDefault()123Clock clock=Clock.systemUTC();//获取格林尼治时间System.out.println(clock.instant());//获取Instant类型数据，后面会讲到System.out.println(clock.millis());//获取标准毫秒数Instant所谓的Instant累代表的是某个时间（有点类似与java.util.Date），他是精确到纳秒的，而Date是精确到毫秒的。instant表示的是时间线上的一点，而不需要任何上下文信息，例如：时区。概念上讲他只是简单的表示自1970年1月1日0是0分0秒开始的秒数。下面给去确定一个方法的运行时间长度的代码1234567Instant start = Instant.now();doSomeThing();Instant end = Instant.now();Duration duration = Duration.between(start, end);long seconds = duration.getSeconds();//秒表示long millis = duration.toMillis();//毫秒表示boolean isAfter = end.isAfter(start);//时间点end是否在start之后[^]常用函数now() 静态函数，获取当前时间戳isAfter()/isBefore() 判断两个时间点的先后顺序plusXXX() 在该时间点加上某段时间minusXXX() 在该时间点上减去某段时间Instant用在当你需要记录事件的发生时间，额如需要记录任何有关时区信息时。Instant只能包含秒数和毫秒数，例如如下代码就会抛出异常12instant.get(ChronoField.MONTH_OF_YEAR);instant.plus(6, ChronoUnit.YEARS);LocalDateLocalDate表示日期的不可变类型，不包含时间和时区。LocalDate和下面要讲的LocalTime都被设计成值类型的，这意味着我们不能用==来判断两个LocalDate是不是相等而是应该通过equals()。下面给出一个获取当前年月日的例子12345LocalDate today = LocalDate.now(); int year = today.getYear(); int month = today.getMonthValue(); int day = today.getDayOfMonth(); System.out.printf("Year : %d Month : %d day : %d \t %n", year, month, day);常用函数now()根据当前时间戳创建LocalDateof()根据制定的年月日创建LocalDateparse(charqueue, DateTimeFormatter)根据传入的format将字符串转化为LocalDate对象ofYearDay()根据指定的年和一年中的第几天创建LocalDategetXXX()获取当前LocalDate中关于日期的信息，年月日等等plusXXX()在当前的LocalDate的基础上增加指定时间类型来创建一个新的LocalDateminusXXX()在当前的LocalDate的基础上减去指定时间类型来创建一个新的LocalDatewithXXX()在当前的LocalDate的基础上指定某个时间类型的值来创建一个新的LocalDateisXXX()判断两个LocalDate的大小关系，特别（isLeepYear()判断是否为闰年）lengthOfXXX()获取LocalDate代表的年或月的天数with(TemporalAdjuster)TemporalAdjusters提供了几个用来获取TemporalAdjuster的方法，用来处理比较复杂的逻辑，比如获取当月的最后一天lastDayOfMonth()atTime()将LocalDate转化为LocalDateTimeLocalTimeLocalTime是值类型，且和日期，时区没有关联。当我们对时间进行加减操作时，以午夜为基准，24小时一个周期。因此，20:00加上6小时，结果是02:00。LocalTime用法和LocalDate类似12345LocalTime time = LocalTime.of(20, 30);int hour = date.getHour(); // 20int minute = date.getMinute(); // 30time = time.withSecond(6); // 20:30:06time = time.plusMinutes(3); // 20:33:06常用函数和LocalDate基本类似，只是将对年月日的操作转换为时分秒toSecondOfDay()获取该时间点距离0:00的秒数LocalDateTime这个值类型只是LocalDate和LocalTime的简单组合。他表示一个和时区无关的日期和时间。LocalDateTime可以直接创建或者组合时间和日期1234LocalDateTime dt1 = LocalDateTime.of(2014, Month.JUNE, 10, 20, 30);LocalDateTime dt2 = LocalDateTime.of(date, time);Month month = dt1.getMonth();int minute = dt1.getMinute();常用函数将LocalDate和LocalTime两个类的plusXXX(), minusXXX(), withXXX(),getXXX()简单相加与LocalDate对象其他函数完全类似isXXX()与LocalDate完全一样toLocalDate()/toLocalTime()将LocalDateTime转换为LocalTime或者LocalDate时间长度Duration表示以秒和纳秒位基准的时长；Period表示以年，月，日衡量的时长。他们可以作为参数，传给主要的时间/日期类的增加或减少的方法，也可以计算两个时间点之间的间隔12345Duration duration = Duration.ofDays(10);LocalTime start = LocalTime.now();doSoneThing();LocalTime end = LocalTime.now();Duration spend = Duration.between(start, end);常用函数ofXXX()根据参数指定的大小计算以XXX个单位的时间间隔between(arg1, arg2)计算两个参数时间点的时间间隔plusXXX()/minuxXXX()在当前时间间隔的基础上加上或减去指定个单位的时间toXXX()将时间间隔格式化位指定单位的时间，Duration一般使用该类型函数，Period一般使用getXXX()abs()求时间间隔的绝对值，保证时间间隔不为负数isZero()/isNegative()判断时间间隔是否为0或负withXXX()直接指定某个单位的值格式化java.time.format包是专门用来格式化输出输入时间/日期的。这个包围绕DateTimeFormatter类和它的辅助创建类DateTimeFormatterBuilder展开。静态方法ofPattern(Charqueue)和DateTimeFormatter中的常量是最通用的创建格式化器的方式常用ISO格式常量，如ISO_LOCAL_DATE字母模式，如ofPattern(“dd/MM/uuuu”)本地化样式，如ofLocalizedDate(FormatStyle.MEDIUM)有了格式化器，我们就可以将该实例传递给parse()或者format()作为参数，用来将字符串格式化为对象或者将对象格式化位字符串12345678910111213141516171819//按照内置的不同方式格式化String format = DateTimeFormatter.ISO_LOCAL_DATE.format(LocalDate.now());String format2 = DateTimeFormatter.ISO_LOCAL_TIME.format(LocalTime.now());String format3 = DateTimeFormatter.ISO_DATE.format(LocalDateTime.now());String format4 = DateTimeFormatter.ISO_INSTANT.format(Instant.now());System.out.println(format);System.out.println(format2);System.out.println(format3);System.out.println(format4); //按照标准格式格式化DateTimeFormatter formatter = DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL);String format5 = formatter.format(LocalDateTime.now());System.out.println(format5); //按照指定方式格式化DateTimeFormatter pattern = DateTimeFormatter.ofPattern("yyyy-MM-dd E HH:mm:ss");String format6 = pattern.format(LocalDateTime.now());System.out.println(format6);其他YearMonth仅仅包含年和月字段，操作也LocalDate类似MonthDay仅仅包含月和日字段，操作与LocalDate类似]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effictive-java读书笔记]]></title>
    <url>%2Fposts%2F636894a%2F</url>
    <content type="text"><![CDATA[Effective Java一书笔记对象的创建与销毁Item 1: 使用static工厂方法，而不是构造函数创建对象仅仅是创建对象的方法，并非Factory Pattern优点命名、接口理解更高效，通过工厂方法的函数名，而不是参数列表来表达其语义Instance control，并非每次调用都会创建新对象，可以使用预先创建好的对象，或者做对象缓存；便于实现单例；或不可实例化的类；对于immutable的对象来说，使得用==判等符合语义，且更高效；工厂方法能够返回任何返回类型的子类对象，甚至是私有实现；使得开发模块之间通过接口耦合，降低耦合度；而接口的实现也将更加灵活；接口不能有static方法，通常做法是为其再创建一个工厂方法类，如Collection与Collections；Read More: Service Provider Framework缺点仅有static工厂方法，没有public/protected构造函数的类将无法被继承；见仁见智，这一方面也迫使开发者倾向于组合而非继承；Javadoc中不能和其他static方法区分开，没有构造函数的集中显示优点；但可以通过公约的命名规则来改善；小结static工厂方法和public构造函数均有其优缺点，在编码过程中，可以先考虑一下工厂方法是否合适，再进行选择。Item 2: 使用当构造函数的参数较多，尤其是其中还有部分是可选参数时，使用Builder模式以往的方法Telescoping constructor：针对可选参数，从0个到最多个，依次编写一个构造函数，它们按照参数数量由少到多逐层调用，最终调用到完整参数的构造函数；代码冗余，有时还得传递无意义参数，而且容易导致使用过程中出隐蔽的bug；JavaBeans Pattern：灵活，但是缺乏安全性，有状态不一致问题，线程安全问题；Builder Pattern代码灵活简洁；具备安全性；immutable参数检查：最好放在要build的对象的构造函数中，而非builder的构建过程中支持多个field以varargs的方式设置（每个函数只能有一个varargs）一个builder可以build多个对象Builder结合泛型，实现Abstract Factory Pattern传统的抽象工厂模式，是用Class类实现的，然而其有缺点：newInstance调用总是去调用无参数构造函数，不能保证存在；newInstance方法会抛出所有无参数构造函数中的异常，而且不会被编译期的异常检查机制覆盖；可能会导致运行时异常，而非编译期错误；小结Builder模式在简单地类（参数较少，例如4个以下）中，优势并不明显，但是需要予以考虑，尤其是当参数可能会变多时，有可选参数时更是如此。Item 3: 单例模式！不管以哪种形式实现单例模式，它们的核心原理都是将构造函数私有化，并且通过静态方法获取一个唯一的实例，在这个获取的过程中你必须保证线程安全、反序列化导致重新生成实例对象等问题，该模式简单，但使用率较高。double-check-locking123456789101112private static volatile RestAdapter sRestAdapter = null;public static RestAdapter provideRestAdapter() &#123; if (sRestAdapter == null) &#123; synchronized (RestProvider.class) &#123; if (sRestAdapter == null) &#123; sRestAdapter = new RestAdapter(); &#125; &#125; &#125; return sRestAdapter;&#125;DCL可能会失效，因为指令重排可能导致同步解除后，对象初始化不完全就被其他线程获取；使用volatile关键字修饰对象，或者使用static SingletonHolder来避免该问题（后者JLS推荐）；class的static代码：一个类只有在被使用时才会初始化，而类初始化过程是非并行的，这些都由JLS能保证用enum实现单例还存在反射安全性问题：利用反射，可以访问私有方法，可通过加一个控制变量，该变量在getInstance函数中设置，如果不是从getInstance调用构造函数，则抛出异常；Item 4: 将构造函数私有化，使得不能从类外创建实例，同时也能禁止类被继承util类可能不希望被实例化，有其需求Item 5: 避免创建不必要的对象提高性能：创建对象需要时间、空间，“重量级”对象尤甚；immutable的对象也应该避免重复创建，例如String；避免auto-boxing但是因此而故意不创建必要的对象是错误的，使用object pool通常也是没必要的lazy initialize也不是特别必要，除非使用场景很少且很重量级Map#keySet方法，每次调用返回的是同一个Set对象，如果修改了返回的set，其他使用的代码可能会产生bug需要defensive copying的时候，如果没有创建一个新对象，将导致很隐藏的BugItem 6: 不再使用的对象一定要解除引用，避免memory leak例如，用数组实现一个栈，pop的时候，如果仅仅是移动下标，没有把pop出栈的数组位置引用解除，将发生内存泄漏程序发生错误之后，应该尽快把错误抛出，而不是以错误的状态继续运行，否则可能导致更大的问题通过把变量（引用）置为null不是最好的实现方式，只有在极端情况下才需要这样；好的办法是通过作用域来使得变量的引用过期，所以尽量缩小变量的作用域是很好的实践；注意，在Dalvik虚拟机中，存在一个细微的bug，可能会导致内存泄漏，详见当一个类管理了一块内存，用于保存其他对象（数据）时，例如用数组实现的栈，底层通过一个数组来管理数据，但是数组的大小不等于有效数据的大小，GC器却并不知道这件事，所以这时候，需要对其管理的数据对象进行null解引用当一个类管理了一块内存，用于保存其他对象（数据）时，程序员应该保持高度警惕，避免出现内存泄漏，一旦数据无效之后，需要立即解除引用实现缓存的时候也很容易导致内存泄漏，放进缓存的对象一定要有换出机制，或者通过弱引用来进行引用listner和callback也有可能导致内存泄漏，最好使用弱引用来进行引用，使得其可以被GCItem 7: 不要使用finalize方法finalize方法不同于C++的析构函数，不是用来释放资源的好地方finalize方法执行并不及时，其执行线程优先级很低，而当对象unreachable之后，需要执行finalize方法之后才能释放，所以会导致对象生存周期变长，甚至根本不会释放finalize方法的执行并不保证执行成功/完成使用finalize时，性能会严重下降finalize存在的意义充当“safety net”的角色，避免对象的使用者忘记调用显式termination方法，尽管finalize方法的执行时间没有保证，但是晚释放资源好过不释放资源；此处输出log警告有利于排查bug用于释放native peer，但是当native peer持有必须要释放的资源时，应该定义显式termination方法子类finalize方法并不会自动调用父类finalize方法（和构造函数不同），为了避免子类不手动调用父类的finalize方法导致父类的资源未被释放，当需要使用finalize时，使用finalizer guardian比较好：定义一个私有的匿名Object子类对象，重写其finalize方法，在其中进行父类要做的工作因为当父类对象被回收时，finalizer guardian也会被回收，它的finalize方法就一定会被触发##Object的方法尽管Object不是抽象类，但是其定义的非final方法设计的时候都是希望被重写的，finalize除外。Item 8: 当重写equals方法时，遵循其语义能不重写equals时就不要重写当对象表达的不是值，而是可变的状态时对象不需要使用判等时父类已重写，且满足子类语义当需要判等，且继承实现无法满足语义时，需要重写（通常是“value class”，或immutable对象）当用作map的key时重写equals时需要遵循的语义Reflexive（自反性）: x.equals(x)必须返回true（x不为null）Symmetric（对称性）: x.equals(y) == y.equals(x)Transitive（传递性）: x.equals(y) &amp;&amp; y.equals(z) ==&gt; x.equals(z)Consistent（一致性）: 当对象未发生改变时，多次调用应该返回同一结果x.equals(null)必须返回false实现建议先用==检查是否引用同一对象，提高性能用instanceof再检查是否同一类型再强制转换为正确的类型再对各个域进行equals检查，遵循同样的规则确认其语义正确，编写测例重写equals时，同时也重写hashCode！重写equals方法，传入的参数是ObjectItem 9: 重写equals时也重写hashCode函数避免在基于hash的集合中使用时出错语义一致性当两个对象equals返回true时，hashCode方法的返回值也要相同hashCode的计算方式要求：equals的两个对象hashCode一样，但是不equals的对象hashCode不一样取一个素数，例如17，result = 17对每一个关心的field（在equals中参与判断的field），记为f，将其转换为一个int，记为cboolean: f ? 1 : 0byte/char/short/int: (int) flong: (int) (f ^ (f &gt;&gt; 32))float: Float.floatToIntBits(f)double: Double.doubleToLongBits(f)，再按照long处理Object: f == null ? 0 : f.hashCode()array: 先计算每个元素的hashCode，再按照int处理对每个field计算的c，result = 31 * result + c返回result编写测例计算hashCode时，不重要的field（未参与equals判断）不要参与计算Item 10: 重写toString()方法增加可读性，简洁、可读、具有信息量Item 11: 慎重重写clone方法Cloneable接口是一个mixin interface，用于表明一个对象可以被cloneContractx.clone() != xx.clone().getClass() == x.getClass()：要求太弱，当一个非final类重写clone方法的时候，创建的对象一定要通过super.clone()来获得，所有父类都遵循同样的原则，如此最终通过Object.clone()创建对象，能保证创建的是正确的类实例。而这一点很难保证。x.clone().equals(x)不调用构造函数：要求太强，一般都会在clone函数里面调用对于成员变量都是primitive type的类，直接调用super.clone()，然后cast为自己的类型即可（重写时允许返回被重写类返回类型的子类，便于使用方，不必每次cast）成员变量包含对象（包括primitive type数组），可以通过递归调用成员的clone方法并赋值来实现然而上述方式违背了final的使用协议，final成员不允许再次赋值，然而clone方法里面必须要对其赋值，则无法使用final保证不可变性了递归调用成员的clone方法也会存在性能问题，对HashTable递归调用深拷贝也可能导致StackOverFlow（可以通过遍历添加来避免）优雅的方式是通过super.clone()创建对象，然后为成员变量设置相同的值，而不是简单地递归调用成员的clone方法和构造函数一样，在clone的过程中，不能调用non final的方法，如果调用虚函数，那么该函数会优先执行，而此时被clone的对象状态还未完成clone/construct，会导致corruption。因此上一条中提及的“设置相同的值”所调用的方法，要是final或者private。重载类的clone方法可以省略异常表的定义，如果重写时把可见性改为public，则应该省略，便于使用；如果设计为应该被继承，则应该重写得和Object的一样，且不应该实现Cloneable接口；多线程问题也需要考虑；要实现clone方法的类，都应该实现Cloneable接口，同时把clone方法可见性设为public，返回类型为自己，应该调用super.clone()来创建对象，然后手动设置每个域的值clone方法太过复杂，如果不实现Cloneable接口，也可以通过别的方式实现copy功能，或者不提供copy功能，immutable提供copy功能是无意义的提供拷贝构造函数，或者拷贝工厂方法，而且此种方法更加推荐，但也有其不足设计用来被继承的类时，如果不实现一个正确高效的clone重写，那么其子类也将无法实现正确高效的clone功能Item 12: 当对象自然有序时，实现Comparable接口实现Comparable接口可以利用其有序性特点，提高集合使用/搜索/排序的性能Contactsgn(x.compareTo(y)) == - sgn(y.compareTo(x))，当类型不对时，应该抛出ClassCastException，抛出异常的行为应该是一致的transitive: x.compareTo(y) &gt; 0 &amp;&amp; y.compareTo(z) &gt; 0 ==&gt; x.compareTo(z) &gt; 0x.compareTo(y) == 0 ==&gt; sgn(x.compareTo(z)) == sgn(y.compareTo(z))建议，但非必须：与equals保持一致，即 x.compareTo(y) == 0 ==&gt; x.equals(y)，如果不一致，需要在文档中明确指出TreeSet, TreeMap等使用的就是有序保存，而HashSet, HashMap则是通过equals + hashCode保存当要为一个实现了Comparable接口的类增加成员变量时，不要通过继承来实现，而是使用组合，并提供原有对象的访问方法，以保持对Contract的遵循实现细节优先比较重要的域谨慎使用返回差值的方式，有可能会溢出##Classes and InterfacesItem 13: 最小化类、成员的可见性封装（隐藏）：公开的接口需要暴露，而接口的实现则需要隐藏，使得接口与实现解耦，降低模块耦合度，增加可测试性、稳定性、可维护性、可优化性、可修改性如果一个类只对一个类可见，则应该将其定义为私有的内部类，而没必要public的类都应该定义为package private为了便于测试，可以适当放松可见性，但也只应该改为package private，不能更高成员不能是非private的，尤其是可变的对象。一旦外部可访问，将失去对其内容的控制能力，而且会有多线程问题暴露的常量也不能是可变的对象，否则public static final也将失去其意义，final成员无法改变其指向，但其指向的对象却是可变的（immutable的对象除外），长度非0的数组同样也是有问题的，可以考虑每次访问时创建拷贝，或者使用Collections.unmodifiableList(Arrays.asList(arr))Item 14: public class中，使用accessor method而非public field后者外部可以直接访问，失去了安全性package private或者private则可以不必这样把immutable的field置为public勉强可以接受，mutable的成员一定不能置为publicItem 15: 最小化可变性不提供可以改变本对象状态的方法保证类不可被继承使用final field使用private field在构造函数、accessor中，对mutable field使用defensive copy实现建议操作函数，例如BigInteger的add方法，不是static的，但也不能改变本对象的状态，则使用functional的方式，返回一个新的对象，其状态是本对象修改之后的状态如此实现的immutable对象生来就是线程安全的，无需同步操作，但应该鼓励共用实例，避免创建过多重复的对象正确实现的immutable对象也不需要clone, copy方法；可以适当引入Object cache；劣势每一个值都需要一个对象，调用改变状态的方法而创建一个新的对象，尤其是它是重量级的，开销会变大；连续调用这样的方法，影响更大；为常用的多次操作组合提供一个方法其他保证class无法被继承，除了声明为final外，还可以将默认构造函数声明为private或package private，然后提供public static工厂方法使用public static工厂方法，具体实现类可以有多个，还能进行object cache当实现Serializable接口是，一定要实现readObject/readResolve方法，或者使用ObjectOutputStream.writeUnshared/ObjectInputStream.readUnshared小结除非有很好的理由让一个Class mutable，否则应该使其immutable如果非要mutable，也应尽可能限制其可变性Item 16: Favor composition (and forwarding) over inheritance跨包继承、继承不是被设计为应该被继承的实现类，是一件很危险的事情，继承接口、继承抽象类，当然是没问题的如果子类的功能依赖于父类的实现细节，那么一旦父类发生变化，子类将有可能出现Bug，即便代码都没有修改；而设计为应被继承的类，在修改后，是应该有文档说明的，子类开发者既可以得知，也可以知道如何修改例子：统计HashSet添加元素的次数用继承方式，重写add，addAll，在其中计数，这就不对，因为HashSet内部的addAll是通过调用add实现的但是通过不重写addAll也只不对的，以后有可能HashSet的实现就变了在重写中重新实现一遍父类的逻辑也是行不通的，因为这可能会导致性能问题、bug等，而且有些功能不访问私有成员也是无法实现的还有一个原因就是父类的实现中，可能会增加方法，改变其行为，而这一点，在子类中是无法控制的而通过组合的方式，将不会有这些问题，把另一个类的对象声明为私有成员，外部将无法访问它，自己也能在转发（forwarding）过程中执行拦截操作，也不必依赖其实现细节，这种组合、转发的实现被称为wrapper，或者Decorator pattern，或者delegation（严格来说不是代理，代理一般wrapper对象都需要把自己传入到被wrap的对象方法中？）缺点不适用于callback frameworks？继承应该在is-a的场景中使用继承除了会继承父类的API功能，也会继承父类的设计缺陷，而组合则可以隐藏成员类的设计缺陷Item 17: Design and document for inheritance or else prohibit it一个类必须在文档中说明，每个可重写的方法，在该类的实现中的哪些地方会被调用（the class must document its self-use of overridable methods）。调用时机、顺序、结果产生的影响，包括多线程、初始化等情况。被继承类应该通过谨慎选择protected的方法或成员，来提供一些hook，用于改变其内部的行为，例如java.util.AbstractList::removeRange。The only way to test a class designed for inheritance is to write subclasses. 用于判断是否需要增加或者减少protected成员/方法，通常写3个子类就差不多了。You must test your class by writing subclasses before you release it.Constructors must not invoke overridable methods. 父类的构造函数比子类的构造函数先执行，而如果父类构造函数中调用了可重写的方法，那么就会导致子类的重写方法比子类的构造函数先执行，会导致corruption。如果实现了Serializable/Cloneable接口，neither clone nor readObject may invoke an overridable method, directly or indirectly. 重写方法会在deserialized/fix the clone’s state之前执行。如果实现了Serializable接口，readResolve/writeReplace必须是protected，而非privatedesigning a class for inheritance places substantial limitations on the class.The best solution to this problem is to prohibit subclassing in classes that are not designed and documented to be safely subclassed. 声明为final class或者把构造函数私有化（提供public static工厂方法）。如果确实想要允许继承，就应该为每个被自己使用的可重写方法都写好文档Item 18: Prefer interfaces to abstract classesJava类只允许单继承，接口可以多继承，使用接口定义类型，使得class hierarchy更加灵活定义mixin（optional functionality to be “mixed in”）时使用interface是很方便的，需要增加此功能的类只需要implement该接口即可，而如果使用抽象类，则无法增加一个extends语句接口允许构建没有hierarchy的类型系统使用接口定义类型，可以使得item 16中提到的wrapper模式更加安全、强大，skeletal implementation：该类为abstract，把必须由client实现的方法设为abstract，可以有默认实现的则提供默认实现simulated multiple inheritance：通过实现定义的接口，同时在内部实现一个匿名的skeletal implementation，将对对该接口的调用转发到匿名类中，起到“多继承”的效果simple implementation：提供一个非抽象的接口实现类，提供一个最简单、能work的实现，也允许被继承使用接口定义类型的缺点：不便于演进，一旦接口发布，如果想要增加功能（增加方法），则client将无法编译；而使用abstract class，则没有此问题，只需要提供默认实现即可小结通过接口定义类型，可以允许多实现（多继承）但是演进需求大于灵活性、功能性时，抽象类更合适提供接口时，提供一个skeletal implementation，同时审慎考虑接口设计Item 19: 仅仅用interface去定义一个类型，该接口应该有实现类，使用者通过接口引用，去调用接口的方法避免用接口去定义常量，应该用noninstantiable utility class去定义常量相关常量的命名，通过公共前缀来实现分组Item 20: Prefer class hierarchies to tagged classestagged class: 在内部定义一个tag变量，由其控制功能的转换tag classes are verbose, error-prone, and inefficient而class hierarchy，不同功能由不同子类实现，公共部分抽象为一个基类，也能反映出各个子类之间的关系Item 21: Use function objects to represent strategies只提供一个功能函数的类实例，没有成员变量，只需一个对象（单例），为其功能定义一个接口，则可以实现策略模式，把具体策略传入相应函数中，使用策略具体的策略实例通常使用匿名类定义，调用使用该策略的方法时才予以创建/预先创建好之后每次将其传入Item 22: Favor static member classes over nonstatic有4种nested class：non-static member class; static member class(inner class); anonymous class; local classstatic member class经常作为helper class，和外部类一起使用如果nested class的生命周期独立于外部类存在，则必须定义为static member class，否则可能造成内存泄漏private static member class用处一：表示（封装）外部类的一些成员，例如Map的Entry内部类。non-static member class将持有外部类实例的强引用，可以直接引用外部类的成员和方法用处一：定义一个Adapter，使得外部内的实例，可以作为和外部类语义不同的实例来查看（访问），例如Collection的Iterator。如果nested class不需要引用外部类的成员和方法，则一定要将其定义为static，避免空间/时间开销，避免内存泄漏anonymous class当在非static代码块内定义时，会持有外部类的引用，否则不会持有限制只能在被声明的地方进行实例化无法进行instanceof测试不能用匿名类实现多个接口不能用匿名类继承一个类的同时实现接口匿名类中新添加的方法无法在匿名类外部访问不能有static成员应该尽量保持简短用处一：创建function object用处二：创建process object，例如：Runnable, Thread, TimberTask用处三：用于public static工厂方法，例如Collections类里面的一些工厂方法，很多是返回一个匿名的内部实现local class比较少用是否static取决于其定义的上下文可以在作用域内重复使用不能有static成员也应尽量保持简短小结四种nested class如果nested class在整个外部类内都需要可见，或者定义代码太长，应使用member class能static就一定要static，即便需要对外部类进行引用，对于生命周期独立于外部类的，也应该通过WeakReference进行引用，避免内存泄漏；至于生命周期和外部类一致的，则不必这样GenericsItem 23: Don’t use raw types in new codeJava泛型，例如List&lt;E&gt;，真正使用的时候都是List&lt;String&gt;等，把E替换为实际的类型Java泛型从1.5引入，为了保持兼容性，实现的是伪泛型，类型参数信息在编译完成之后都会被擦除，其在运行时的类型都是raw type，类型参数保存的都是Object类型，List&lt;E&gt;的raw type就是List编译器在编译期通过类型参数，为读操作自动进行了类型强制转换，同时在写操作时自动进行了类型检查如果使用raw type，那编译器就不会在写操作时进行类型检查了，写入错误的类型也不会报编译错误，那么在后续读操作进行强制类型转换时，将会导致转换失败，抛出异常一旦错误发生，应该让它尽早被知道（抛出/捕获），编译期显然优于运行期List与List&lt;Object&gt;的区别前者不具备类型安全性，后者具备，例如以下代码12345678910// Uses raw type (List) - fails at runtime!public static void main(String[] args) &#123; List&lt;String&gt; strings = new ArrayList&lt;String&gt;(); unsafeAdd(strings, new Integer(42)); String s = strings.get(0); // Compiler-generated cast&#125;private static void unsafeAdd(List list, Object o) &#123; list.add(o);&#125;不会报编译错误，但会给一个编译警告：Test.java:10: warning: unchecked call to add(E) in raw type List list.add(o);，而运行时则会发生错误。但如果使用List&lt;Object&gt;，即unsageAdd参数改为List&lt;Object&gt; list, Object o，则会报编译错误：Test.java:5: unsafeAdd(List&lt;Object&gt;,Object) cannot be applied to (List&lt;String&gt;,Integer) unsafeAdd(strings, new Integer(42));因为List&lt;String&gt;是List的子类，但却不是List&lt;Object&gt;的子类。并不是说这个场景应该使用List&lt;Object&gt;，这个场景应该使用List&lt;String&gt;，这里只是为了说明List和List&lt;Object&gt;是有区别的。List v.s. List&lt;?&gt;（unbounded wildcard types），当不确定类型参数，或者说类型参数不重要时，也不应该使用raw type，而应该使用List&lt;?&gt;任何参数化的List均是List&lt;?&gt;的子类，可以作为参数传入接受List&lt;?&gt;的函数，例如以下代码均是合法的：1234567void func(List&lt;?&gt; list) &#123; ...&#125;func(new List&lt;Object&gt;());func(new List&lt;Integer&gt;());func(new List&lt;String&gt;());持有List&lt;?&gt;的引用后，并不能向其中加入任何元素，读取出来的元素也是Object类型，而不会被自动强转为任何类型。如果List&lt;?&gt;的行为不能满足需求，可以考虑使用模板方法，或者List&lt;E extends XXX&gt;（bounded wildcard types）You must use raw types in class literals.List.class, String[].class, and int.class are all legal, but List&lt;String&gt;.class and List&lt;?&gt;.class are not.instanceof不支持泛型，以下用法是推荐的，但不应该将o强转为List12345// Legitimate use of raw type - instanceof operatorif (o instanceof Set) &#123; // Raw type Set&lt;?&gt; m = (Set&lt;?&gt;) o; // Wildcard type ...&#125;相关术语汇总Item 24: Eliminate unchecked warnings当出现类型不安全的强制转换时（一般都是涉及泛型，raw type），编译器会给出警告，首先要做的是尽量消除不安全的转换，消除警告实在无法消除/确定不会导致运行时的ClassCastException，可以通过@SuppressWarnings(&quot;unchecked&quot;)消除警告，但不要直接忽略该警告使用@SuppressWarnings(&quot;unchecked&quot;)时，应该在注视内证明确实不存在运行时的ClassCastException；同时应该尽量减小其作用的范围，通常是应该为一个赋值语句添加注解Item 25: Prefer lists to arraysarrays are covariant(协变): 如果Sub是Super的子类，那么Sub[]也是Super[]的子类generics are invariant(不变): 任意两个不同的类Type1和Type2，List&lt;Type1&gt;和List&lt;Type2&gt;之间没有任何继承关系考虑以下代码1234567// Fails at runtime!Object[] objectArray = new Long[1];objectArray[0] = "I don't fit in"; // Throws ArrayStoreException// Won't compile!List&lt;Object&gt; ol = new ArrayList&lt;Long&gt;(); // Incompatible typesol.add("I don't fit in");arrays are reified(具体化): array在运行时能知道且强制要求元素的类型generics are implemented by erasure(non-reifiable): 仅仅在编译时知道元素的类型数组和泛型同时使用时会受到很大限制以下语句均不能通过编译：new List&lt;E&gt;[], new List&lt;String&gt;[], new E[]；但是声明是可以的，例如List&lt;String&gt;[] stringListsnon-reifiable type: 例如E, List&lt;E&gt;, List&lt;String&gt;，这些类型在运行时的信息比编译时的信息更少只有unbounded wildcard type才是reifiable的，如：List&lt;?&gt;, Map&lt;?, ?&gt;常规来说，不能返回泛型元素的数组，因为会报编译错误：generic array creation errors当泛型和varargs一起使用时，也会导致编译警告有时为了类型安全，不得不做些妥协，牺牲性能和简洁，使用List而不是数组把数组强转为non-reifiable类型是非常危险的，仅应在非常确定类型安全的情况下使用Item 26: Favor generic types当需要一个类成员的数据类型具备一般性时，应该用泛型，这也正是泛型的设计场景之一，不应该用Object类但使用泛型有时也不得不进行cast，例如当泛型遇上数组总的来说把suppress数组类型强转的unchecked warning比suppress一个标量类型强转的unchecked warning风险更大，但有时出于代码简洁性考虑，也不得不做出妥协有时看似与item 25矛盾，实属无奈，Java原生没有List，ArrayList不得不基于数组实现，HashMap也是基于数组实现的泛型比使用者进行cast更加安全，而且由于Java泛型的擦除实现，也可以和未做泛型的老代码无缝兼容Item 27: Favor generic methods泛型方法的类型参数在函数修饰符（可见性/static/final等）和返回值之间，例子：123456// Generic methodpublic static &lt;E&gt; Set&lt;E&gt; union(Set&lt;E&gt; s1, Set&lt;E&gt; s2) &#123; Set&lt;E&gt; result = new HashSet&lt;&gt;(s1); result.addAll(s2); return result;&#125;recursive type bound12// Using a recursive type bound to express mutual comparabilitypublic static &lt;T extends Comparable&lt;T&gt;&gt; T max(List&lt;T&gt; list) &#123;...&#125;泛型方法要比方法使用者进行cast更加安全Item 28: Use bounded wildcards to increase API flexibility考虑以下代码1234567891011121314151617public class Stack&lt;E&gt; &#123; public Stack(); public void push(E e); public E pop(); public boolean isEmpty(); public void pushAll(Iterable&lt;E&gt; src); public void popAll(Collection&lt;E&gt; dst);&#125;Stack&lt;Number&gt; numberStack = new Stack&lt;Number&gt;();Iterable&lt;Integer&gt; integers = ... ;numberStack.pushAll(integers);Stack&lt;Number&gt; numberStack = new Stack&lt;Number&gt;();Collection&lt;Object&gt; objects = ... ;numberStack.popAll(objects);pushAll和popAll的调用均无法通过编译，因为尽管Integer是Number的子类，但Iterable&lt;Integer&gt;不是Iterable&lt;Number&gt;的子类，这是由泛型的invariant特性导致的，所以Iterable&lt;Integer&gt;不能传入接受Iterable&lt;Number&gt;参数的函数，popAll的使用同理bounded wildcards: &lt;? extends E&gt;, &lt;? super E&gt;, PECS stands for producer-extends, consumer-super. 如果传入的参数是要输入给该类型数据的，则应该使用extends，如果是要容纳该类型数据的输出，则应该使用super这很好理解，作为输入是要赋值给E类型的，当然应该是E的子类（这里的extends包括E类型本身）；而容纳输出是要把E赋值给传入参数的，当然应该是E的父类（同样包括E本身）返回值类型不要使用bounded wildcards，否则使用者也需要使用，这将会给使用者造成麻烦代码对于bounded wildcards的使用在使用者那边应该是透明的，即他们不会感知到bounded wildcards的存在，如果他们也需要考虑bounded wildcards的问题，则说明对bounded wildcards的使用有问题了有时候编译器的类型推导在遇到bounded wildcards会无法完成，这时就需要显示指定类型信息，例如：123456public static &lt;E&gt; Set&lt;E&gt; union(Set&lt;? extends E&gt; s1, Set&lt;? extends E&gt; s2);Set&lt;Integer&gt; integers = ... ;Set&lt;Double&gt; doubles = ... ;//Set&lt;Number&gt; numbers = union(integers, doubles); //compile errorSet&lt;Number&gt; numbers = Union.&lt;Number&gt;union(integers, doubles); //compile passComparables are always consumers, so you should always use Comparable&lt;? super T&gt; in preference to Comparable&lt;T&gt;. The same is true of comparators, so you should always use Comparator&lt;? super T&gt; in preference to Comparator&lt;T&gt;.unbounded type parameter(&lt;E&gt; ... List&lt;E&gt;) v.s. unbounded wildcard(List&lt;?&gt;)：if a type parameter appears only once in a method declaration, replace it with a wildcard.Item 29: Consider typesafe heterogeneous containers使用泛型时，类型参数是有限个的，例如List&lt;T&gt;，Map&lt;K, V&gt;，但有时可能需要一个容器，能放入任意类型的对象，但需要具备类型安全性，例如数据库的一行，它的每一列都可能是任意类型的数据由于Class类从1.5就被泛型化了，所以使得这种需求可以实现，例如：12345// Typesafe heterogeneous container pattern - APIpublic class Favorites &#123; public &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance); public &lt;T&gt; T getFavorite(Class&lt;T&gt; type);&#125;通常这样使用的Class对象被称为type token，它传入函数，用来表述编译时和运行时的类型信息Favorites的实现也是很简单的：1234567891011121314// Typesafe heterogeneous container pattern - implementationpublic class Favorites &#123; private Map&lt;Class&lt;?&gt;, Object&gt; favorites = new HashMap&lt;Class&lt;?&gt;, Object&gt;(); public &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance) &#123; if (type == null) throw new NullPointerException("Type is null"); favorites.put(type, instance); &#125; public &lt;T&gt; T getFavorite(Class&lt;T&gt; type) &#123; return type.cast(favorites.get(type)); &#125;&#125;注意，这里的unbound wildcard并不是应用于Map的，而是应用于Class的类型参数，因此Map可以put key进去，而且key可以是任意类型参数的Class对象另外，Map的value类型是Object，一旦put到Map中去，其编译期类型信息就丢失了，将通过get方法的动态类型转换（cast）来重新获得其类型信息cast方法将检查类型信息，如果是该类型（或其子类），转换将成功，并返回引用，否则将抛出ClassCastException这一heterogeneous container实现有两个不足通过为put方法传入Class的raw type，使用者可以很轻易地破坏类型安全性，解决方案也很简单，在put时也进行一下cast：1234// Achieving runtime type safety with a dynamic castpublic &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance) &#123; favorites.put(type, type.cast(instance));&#125;这样做的效果是使得想要破坏类型安全性的put使用者产生异常，而使用get的使用者则不会因为恶意put使用者产生异常。这种做法也被java.util.Collections包中的一些方法使用，例如命名为checkedSet, checkedList, checkedMap的类。这个容器内不能放入non-reifiable的类型，例如List&lt;String&gt;，因为List&lt;String&gt;.class是有语法错误的，List&lt;String&gt;, List&lt;Integer&gt;都只有同一个class对象：List.class；另外String[].class是合法的。Favorites使用的类型参数是unbounded的，可以put任意类型，也可以使用bounded type token，使用bounded时可能需要把Class&lt;?&gt;转换为Class&lt;? extends Annotation&gt;，直接用class.cast将会导致unchecked warning，可以通过class.asSubclass来进行转换，例子：12345678910// Use of asSubclass to safely cast to a bounded type tokenstatic Annotation getAnnotation(AnnotatedElement element, String annotationTypeName) &#123; Class&lt;?&gt; annotationType = null; // Unbounded type token try &#123; annotationType = Class.forName(annotationTypeName); &#125; catch (Exception ex) &#123; throw new IllegalArgumentException(ex); &#125; return element.getAnnotation(annotationType.asSubclass(Annotation.class));&#125;##Enums and AnnotationsItem 30: Use enums instead of int constants类型安全可以为常量提供数据和方法的绑定可以遍历实现建议如果是通用的，应该定义为top level enum，否则应定义为内部类constant-specific method implementations12345678// Enum type with constant-specific method implementationspublic enum Operation &#123; PLUS &#123; double apply(double x, double y)&#123;return x + y;&#125; &#125;, MINUS &#123; double apply(double x, double y)&#123;return x - y;&#125; &#125;, TIMES &#123; double apply(double x, double y)&#123;return x * y;&#125; &#125;, DIVIDE &#123; double apply(double x, double y)&#123;return x / y;&#125; &#125;; abstract double apply(double x, double y);&#125;结合constant-specific data123456789101112131415161718192021// Enum type with constant-specific class bodies and datapublic enum Operation &#123; PLUS("+") &#123; double apply(double x, double y) &#123; return x + y; &#125; &#125;, MINUS("-") &#123; double apply(double x, double y) &#123; return x - y; &#125; &#125;, TIMES("*") &#123; double apply(double x, double y) &#123; return x * y; &#125; &#125;, DIVIDE("/") &#123; double apply(double x, double y) &#123; return x / y; &#125; &#125;; private final String symbol; Operation(String symbol) &#123; this.symbol = symbol; &#125; @Override public String toString() &#123; return symbol; &#125; abstract double apply(double x, double y);&#125;If switch statements on enums are not a good choice for implementing con- stant-specific behavior on enums, what are they good for? Switches on enums are good for augmenting external enum types with constant-specific behavior.A minor performance disadvantage of enums over int constants is that there is a space and time cost to load and initialize enum types.所以，在安卓设备（手机、平板）上，应该避免使用enum，减小空间和时间的开销Item 31: Use instance fields instead of ordinals每个enum的常量都有一个ordinal()方法获取其在该enum类型中的位置，但该方法只应该在实现EnumSet, EnumMap等类型的时候被使用，其他情形都不应该被使用如果需要为每一个常量绑定一个数据，可以使用instance field实现，如果需要绑定方法，则可以用constant-specific method implementations，参考上一个itemItem 32: Use EnumSet instead of bit fieldsbit fields的方式不优雅、容易出错、没有类型安全性EnumSet则没有这些缺点，而且对于大多数enum类型来说，其性能都和bit field相当通用建议：声明变量时，不要用实现类型，应该用接口类型，例如，应该用List&lt;Integer&gt;而不是ArrayList&lt;Integer&gt;EnumSet并非immutable的，可以通过Conllections.unmodifiableSet来封装为immutable，但是代码简洁性与性能都将受到影响]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb索引]]></title>
    <url>%2Fposts%2Fc2f6f9e3%2F</url>
    <content type="text"><![CDATA[索引简介索引是用来加速查询的，类似于数的目录一样。我们要查找某些内容不需要查遍整个数据库，只需要先在索引中查找，找到相应索引之后根据索引找到指向的文档。创建索引使用ensureIndex函数，db.people.ensureIndex({&#39;username&#39;:1}),1代表对索引内容进行正向排序，-1代表对索引内容逆向排序。对某个键创建的索引会加速以该键为查询条件的查询，对其他查询没有帮助。索引创建既可以针对单个键创建也可以针对多个键创建，例如db.people.ensureIndex({&#39;name&#39;:1,age:-1,&#39;sex&#39;:1})其作用原理与sort相同(由前到后逐个匹配)。如果创建了我们上面所看到的索引实际上是有了{name:1},{name:1,age:-1},{name:1,age:-1,sex:1}三个索引，使用{age:-1}等索引的查询不会得到优化。创建索引并不是只有优点的，他的缺点就是每次插入，更新，删除都会产生额外的开销用来更新索引。所以我们要根据实际情况合理的创建索引，通常我们要考虑实际情况中都需要经常对哪些键查询，然后对该查询字段创建索引，每个集合的最大索引个数为64个注意索引顺序当我们创建多键索引时要分清主次，一般我们可以这样认为，当根据我们创建的多键索引进行查询时会先根据前面的条件筛选，将结果用于下一次筛选。所以创建多键索引时我们要将主要索引条件放在前面，建立索引时要考虑如下问题：会做什么样的查询，其中哪些键需要索引每个键的索引方向是怎样的如何应对拓展，有没有种不同的键的排列可以是常用数据更多地保存在内存中索引内嵌文档为内嵌文档建立索引和为普通的键创建索引没有什么区别，只是在索引内嵌文档的字段的时候使用点表达式，也可以和普通键索引组成复合索引为排序创建索引随着集合的增长，需要针对大量的排序做索引。因为如果排序实在内存中完成的，如果数据量特别大超出内存的限制就是报错。如果没有对数据进行sort，默认就是查询出来的顺序，所以创建索引之后查询出来的顺序就是排序之后的结果索引名称每一个索引都有一个字符串类型的名字用来唯一标示，数据库通过这个名字来删除或操作索引。默认情况索引名类似keyname1_dir1_keyname2_dir2…形式（keynameX代表索引的键，dirX代表索引的方向）。我们可以通过ensureIndex的第二个参数来指定索引的名字1db.people.ensureIndex(&#123;'name':1,'age':-1&#125;,&#123;'name':'index1'&#125;)唯一索引唯一所以可以确保集合的每一个文档的指定键都有唯一的值，相当于关系型数据库中的unique键。要创建唯一索引需要在ensureIndex的第二个参数中指定unique为true。在创建集合是自动给我们创建了_id唯一索引，与普通唯一索引的区别是不能被删除1db.people.ensureIndex(&#123;'username':1&#125;,&#123;'unique':true&#125;)可能当我们创建唯一索引的时候，有些值已经有重复了，这时候索引的创建就会失败。但是我们可以使用dropDups选项，这样可以保留发现的第一个文档，将其他重复文档删除1db.people.ensureIndex(&#123;'username':1&#125;,&#123;'unique':true, 'dropDups':true&#125;)创建符合唯一索引的时候，单个键的值可以相同，只要所有键的值组合起来不同就好强制使用索引如果发现MongoDb没有使用预期的索引，可以用hint强制使用某个索引。例如希望使用{&#39;username&#39;:1,&#39;age&#39;:1}索引1db.people.find(&#123;'age':14,'username':'nicolas'&#125;).hint(&#123;'username':1,'age':1&#125;)多数情况下并没有这么做的必要，MongoDb会非常智能的选择使用哪个索引。在初次查询时会尝试各种查询方案，最优方案会被记录下来，还会定期重试其他方案，防止建立新的索引之后方案不再是最优索引管理索引的原信息存储在每个数据库的system.indexes集合中，不能对该集合插入或删除文档，操作只能通过ensureIndex和dropIndex进行建立索引既耗时有费力，还需要消耗很多资源，可以使用{&#39;background&#39;:true}选项是这个过程在后台完成，同时正常处理请求。一般来说为已有文档创建索引比先创建索引再插入所有文档要稍快一些。不管怎么说在无关紧要的时刻创建索引是最好的选择当索引没用的时候可以通过dropIndex选项删除索引,删除依据是创建索引的条件1db.people.dropIndex(&#123;'username':1,'age':-1&#125;)地理空间索引MongoDb为坐标平面提供了专门的索引成为地理空间索引，可以找出离某一坐标平面最近的点。创建地理空间索引同样适用ensureIndex选项，只不过参数不是1或-1而是2d。建立索引的键的值必须是包含两个元素的数组或包含两个键的内嵌文档(键名可以随意)。地理空间索引默认的范围是180·-180，如果想要指定大小可以使用第二个参数1db.start.insureIndex(&#123;'light-year':'2d'&#125;,&#123;'min':-1000,'max':1000&#125;)地理空间索引的查询和普通的find查询差别不大，只不过使用了$near，需要两个目标值的数组作为参数，默认返回100个距离给点坐标最近的文档，可以使用limit进行限制。还可以使用$maxDistance限定查询的最大距离1db.map.find(&#123;'gps':&#123;$near:[40,-73], $maxDistance:40&#125;&#125;).limit(10)MongoDb不仅可以根据距离查询，还可以根据形状查询，目前支持矩形,圆形查询和多边形查询，需要用到$within123456//要给出矩形左上角和右下角坐标db.map.find(&#123;'gps':&#123;$within:&#123;$box:&#123;[10,30],[15,40]&#125;&#125;&#125;&#125;)//需要圆的原点坐标和半径db.map.find(&#123;'gps':&#123;$within:&#123;$circle:&#123;[10,20],40&#125;&#125;&#125;&#125;)//多边形各个点的坐标db.map.find(&#123;'gps':&#123;$within:&#123;$polygon:[[1,2],[1,4],[6,3]]&#125;&#125;&#125;)我们可以组合地理空间索引和普通索引，这样可以满足继续要地里空间限制条件组合普通限制条件的查找1db.ensureIndex(&#123;'location':'2d','desc':1&#125;)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb查询]]></title>
    <url>%2Fposts%2Ff3e67b24%2F</url>
    <content type="text"><![CDATA[简介使用find或者findOne对数据库执行查询使用$条件实现范围，集合包含，不等式和其他查询使用$where子句用户复杂查询查询会返回一个数据库游标，只有在需要数据的时候才会惰性的返回文档针对游标执行的元操作，比如忽略一定数量的结果，限定返回结果的数量，对结果进行排序find简介db.users.find()db.users.find({‘name’:’nicolas’,’age’:20})不带参数的find会返回全部文档。find可以指定查询文档，只返回匹配查询条件的文档，当查询文档含有多个K-V时连接条件为AND,第二个查询语句会返回name为nicolas并且age为20的文档指定返回的键db.users.find({},{‘name’:1,’age’:0})有时我们并不需要将文档中的所有K-V都返回，这种情况我们可以使用find函数的第二个参数指定要返回的键。其中1代表将返回的文档按照该字段正向排序，0代表将返回的文档按照该字段逆向排序限制db.stock.find({‘in_stock’:’this.num_sold’})查询文档必须是常量（在自己代码里可以使正常的变量），但是不能引用文档中其他键的值。故上面的这个查询是错误的查询条件比较操作符$gt,$gte,$gt,gte是全部的比较操作符，分别对应&lt;,&lt;=,&gt;,&gt;=，可以将其组合起来查找一个范围的值。其中对于日期查询尤为有用，因为对日期的精确匹配终究是徒劳的。db.users.find({‘age’:{$lt:30,$gt:20}) 查找年龄大于20小于30的人start = new Date(“01/01/2007”)db.users.find(‘registered’:{$lt:start}) 查找注册日期在2007年1月1日之前的用户OR查询$in可以用来查询键值在给定数组中的文档，与之相反的是$nin。这两者用来对单个键做OR查询db.users.find({‘name’:{$in:[‘nicolas’,’windylee’]}) 返回name为nicolas或windylee的文档$or可以对多个键做OR查询，$or接受一个包含所有可能条件的数组作为参数，只要符合数组中任何一个元素的条件就会被查询出来，$or可以包含其他条件。普通的and兴的查询，总是尽可能的用最少的条件来限定结果的范围，or型的查询真好相反，第一个条件尽可能地匹配更多的文档db.users.find({$or:[{‘name’:{$in:[‘nicolas’,’windylee’]}},’age’:20]}) 查询name为nicolas或windylee或age为20的用户$not查询$not是元条件句，可以用在任何其他条件之上，表示对其他条件的结果取反。经常与正则表达式联合使用，用来查询不匹配正则表达式的文档db.users.find({‘age’:{$not:{$mod:[5,1]}}) 查询age值模5余数不为1的文档条件句的规则条件句是内层文档的键，修改器是外层文档的键，可对一个键应用多个条件，但是一个键不能对应多个更新修改器。例如{$inc:{&#39;age&#39;:20},$set:{&#39;age&#39;:40}}修改了age两次特定于类型的查询空值查询nullnull不仅能够匹配到键值为null的文档，他还能匹配缺少这个键的所有文档$exists如果仅仅想匹配键值为null的文档，就需要使用到该关键字db.users.find({‘name’:{$exists:true}}) 返回name值不为空的文档查询数组$ll返回含有$all指向数组所有元素的文档db.users.find(‘course’:{$all:[‘english’,’chinese’]}) 返回课程含有english和chinese的用户$size返回数组长度为指定大小的文档，$size不能与其他查询子句组合(比如$gt)db.users.find({‘course’:{$size:3}}) 返回选了3门课的文档$slice返回一个数组的子集合。可以接受一个整型n，整数表示返回数组的前n条数据，负数表示返回数组的后n条数据；可以接受一个数组，数组的第一个元素表示偏移量，第二个元素表示获取的元素数量。除非特别声明，$slice返回文档中的所有键db.blog.posts.findOne(criteria,{‘comments’:{$slice,[1,2]}}) 默认会返回posts中的所有字段查询内嵌文档如果存在如下文档1234567&#123; 'name':&#123; 'first':'Jone' 'last':'Schmoe' &#125; 'age':45&#125;要查询姓名为Jon Schmoe的人可以这样db.people.find({&#39;name&#39;:{&#39;first&#39;:&#39;Jon&#39;,&#39;last&#39;:&#39;Schmoe&#39;}})这种方式采用全部匹配的规则，即查询条件中要包含内嵌文档的所有键，如果name内嵌文档中增加middle字段则上述查询条件就不起作用了。如果只想根据部分字段进行查询则需要点表达式db.people.find({&#39;name.first&#39;:&#39;Joe&#39;,&#39;name.last&#39;:&#39;Schmoe&#39;})，这也是带插入的文档不能包含’.’的原因当文档变负责以后，即内嵌文档为数组时，如果有如下文档123456789101112131415&#123; 'content':'...' 'comments':[ &#123; 'author':'joe', 'score':3, 'comment':'nice post' &#125;, &#123; 'author':'mary', 'score':6, 'comment':'terrible post' &#125; ]&#125;如果继续使用点表达式db.blog.find({&#39;comments.author&#39;:&#39;jone&#39;,&#39;score&#39;:6})则第一个条件会在comments1中找到，第二个条件会在comments2中找到，所以会返回我们上面看到的文档。若要正确指定一组条件我们需要$elemMatch，这种模糊的命名条件句能用来部分指定匹配数组中的单个嵌入文档的限定条件，所以正确的写法应该是这样的db.blog.find({&#39;comments&#39;:{$eleMatch:{&#39;author:&#39;Jone&#39;,&#39;score&#39;:&#39;6}}})$where查询我们上面说过find的查询条件只能是常量，不能是文档中的值，如果我们查询条件为文档中的数据，那这时候我们就需要$where子句了，例如db.foo.find({$where:&#39;this.x+this.y=10&#39;})。$where速度要慢很多，除非必要不要使用该条件。游标数据库使用游标来返回find的执行结果，客户端队游标的实现通常能够对最终结果进行有效的控制，可以限制结果的数量，略过部分结果，根据任意方向任意键的组合对结果进行各种排序，或者执行其他一些功能强大的操作。当调用find的时候并不立即查询数据库，而是等待真正开始要求获得结果的时候才发送查询，这样我们就可以在执行之前给查询附加额外的选项limit, skip, sortlimit限定返回结果的上限，skip跳过前n个匹配的文档；sort指定排序的键和排序条件，1为正序排序，-1为降序排序，如果指定了多个键，则按照多个键的顺序逐个排序，例如要按照username升序和age降序排序db.c.find().sort({&#39;username&#39;:1,&#39;age&#39;:-1})。find函数返回游标，这三个函数都可以组成链式操作。如果一个键对应不同的类型，则规定的类型顺序：最小值 &lt; null &lt; 数字（整形，长整形，双精度）&lt; 字符串 &lt; 对象/文旦 &lt; 数组 &lt; 二进制数据 &lt; 对象ID &lt; 布尔型 &lt; 日期型 &lt; 时间戳 &lt; 正则表达式 &lt; 最大值避免使用skip略过大量结果使用skip略过大量结果就会使操作变得非常缓慢，几乎所有的数据库都有这个问题，所以我们应尽量避免使用skip不用skip对结果分页分页最简单的方式就是结合使用limit和skip两个函数，但我们可以有更好的解决方案。例如我们最获取文档时一般按照时间顺序进行排序，我们可以获取第一次获取的文档最后一个的时间，然后可以利用该时间值最为查询条件来获取下一页123456var latest=nullwhile(page1.hasNext())&#123; latest=page1.next(); display(latest)&#125;var page2=db.foo.find(&#123;'date':&#123;$gt:latest.date&#125;).sort('date':-1).limit(10)随机选取文档一般做法是要查询文档总数，然后在0~n中选择一个随机数，使用skip跳过这些随机数来获取随机的一个文档。这样查询总数和使用skip略过文档都需要花费大量时间。我们可以再一开始就在文档中插入一个随机数的键，然后根据该随机数获取随机文档12db.people.insert(&#123;'name':'nicolas','random':Math.random()&#125;)db.people.findOne(&#123;random:&#123;$lt:Math.random()&#125;&#125;)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDb创建，删除，更改]]></title>
    <url>%2Fposts%2F9aa16efd%2F</url>
    <content type="text"><![CDATA[插入并保存文档db.foo.insert({‘bar’:baz”})会自动给文档增加一个”_id”键(如果原来没有的话)。驱动程序会将数据转换成BSON形式，数据库解析BSON，检验是否包含’_id’键，并且文档长度不能超过4MB删除文档db.users.remove()会删除users集合中的所有文档，但是不会删除集合本身，原来的索引也会保留。remove函数可以接受一个查询文档作为可选参数，只有符合条件的文档才会被删除，例如 &gt;db.mailing.list.remove({‘opt-out’:true})删除集合db.users.drop()会删除users集合，所有的索引也会被删除，速度要比remove()快很多更新文档文档存入数据库以后，可以使用update方法来修改他，update有两个参数，一个是查询文档，用来找出要更新的文档，另一个是修改器文档，描述对找到的文档做哪些更改文档替换db.users.update({‘name’:’nicolas’},{‘age’:20})完全用一个文档去替换另一个文档，不使用任何关键字，默认文档会变成和第二个参数文档完全一样的形式，例子中更新之后文档中就只有age字段使用修改器对字段值修改不需要改变文档的大小，修改速度非常快。对数组修改可能需要改变文档的大小，修改速度回慢一下$incdb.users.update({‘name’:’nicolas’},{$age:{‘age’,1}})更新之后age字段会增加1，当为负数时自减。当键不存在时创建一个键。只能用于整数，长整数和说京都浮点数$setdb.user.update({‘name’:’nicolas’},{$set:{‘age’:20}})$set用来指定一个键的值，如果这个键不存在就创建他。$set甚至可以修改键的数据类型。$set可以修改内嵌文档，只要将内嵌字段用”.”连接即可，类似于引用对象变量`$unset·db.users.update({‘name’:’nicolas’},{$unset:{‘age’:1}})会将age的键删除$push如果指定的键已经存在，会向已有的数组末尾加入一个元素，要是没有就会创建一个新的数组$nedb.users.update({‘course’:{$ne:’english’}},{$push:{‘course’:’english’}})当course字段中不存在english值时，会向course字段数组中放入english$addToSetdb.users.update({‘name’:’nicolas’},{$addToSet:{‘courses’:’english’}})当name为nicolas中的course字段数组中不包括english是向其中添加english$eachdb.users.update({‘name’:’nicolas’},{$addToSet:{‘course’:{$each:[‘english’,’chinese’,’math’]}}})如果不存在这像个课程就像course字段中一次添加这些课程$popdb.users.update({‘name’:’nicolas’},{$pop:{‘course’:1}})可以冲数组的任何一段删除元素，1从数组末尾删除一个元素，-1从数组头部删除$pulldb.users.update({‘name’:’nicolas’},{$pull:{‘course’:’english’}})根据特定条件删除元素，例子中删除course数组中值为english的元素$db.blog.update({‘post’:1},{$inc,{‘comments.0.votes’:1}})使comments数组下标为0的元素中votes字段的值自增1db.blog.update({‘comments.author’:’nicolas’},{$inc,{‘comments.$.votes’:1}})首先会查找comments数组中author为nicolas的元素，记录下其下标。并改变该下标中元素的votes值为1upsertdb.person.update({‘name’:’windylee’},{$set:{‘age’:21,’sex’:’man’}},true)upsert是一种特殊的更新，要是没有文档符合更新调价，就会以这个条件和更新文档为基础创建一个新的文档，如果匹配则正常更新。将update的第三个参数设置为true即可开启此功能。例子中将会插入name，age，sex三个字段更新多个文档默认情况下，更新只能对符合匹配条件的第一个文档执行操作，要使所有匹配到的文档都得到更新，可以设置update的第四个参数为true]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown新手指南]]></title>
    <url>%2Fposts%2Fbc135409%2F</url>
    <content type="text"><![CDATA[Markdown简介Markdown是什么Markdown是一种极简的标记语言，可以轻易的将文本转化为HTML。语法非常容易学习，简单到每个人都可以在5分钟之内学会。Markdown之所以越来越流行，不是因为它复杂，而是因为他足够简单。Markdown优点纯文本编写，兼容性很强，可以使用所有文本编辑器打开让写作者专注与文字而不是排版格式转换方便，可以将MarkDown文本轻易转换为HTML，电子书等与word对比使用word写文档需要浪费大量时间在word本身上，特别是那80%我们用不到的功能浪费时间在排版上，需要花费大量时间用在调整粗体或者斜体，黑体还是宋体上Markdown语法标题标题有两种方式：Setext方式和Atx方式12345Setext方式，三个或更多的=或者-大标题===小标题---大标题小标题1234567Atx方式，在标题前面加上#号，总共分为6个等级，#号越多，标题字号越小# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题一级标题二级标题三级标题四级标题五级标题六级标题列表无序列表，只需要在文字前面加上-,+或者×123- 文本1- 文本2- 文本3文本1文本2文本3有序列表，只需要在文字前面加上1.， 2.， 3.等。前面序号只是代表语法标记，真正序号与我们所写的内容并无实际关系，例如：我将文本3的序号标记为4，但效果仍然显示为3。1231. 文本12. 文本24. 文本3文本1文本2文本3嵌套列表，-，+，*可循环使用，但符号之后的空格不能少，符号之前的空格也不能少1234567- 一级列表 + 二级列表 + 二级列表 × 三级列表 - 四级列表- 一级列表​```language一级列表二级列表二级列表三级列表四级列表一级列表链接和图片链接，插入链接只需要使用[显示文本](连接地址 Tooltips)这样的语法实现，Tooltips可以省略，Tooltips表示鼠标悬浮时候的文本提示1[百度](http://www.baidu.com)百度图片，插入图片只需要使用![](图片链接 Tooptips)这样的语法实现，Tooltips可以省略1![](http://ww4.sinaimg.cn/bmiddle/aa397b7fjw1dzplsgpdw5j.jpg "埃菲尔铁塔")自动链接，直接显示链接网址，点击可以跳转1&lt;http://www.sina.com&gt;http://www.sina.com引用在我们写作的时候经常需要引用他人的文字，这时候就需要用到引用这个格式。这时候我们就需要在文字前面加上&gt;来表示引用内容。可以嵌套使用表示多级引用1&gt; 以眼看世界，即使站的最高，世界还是很小；以心看世界，即使身处局限，世界依然很大以眼看世界，即使站的最高，世界还是很小；以心看世界，即使身处局限，世界依然很大强调被**包含的表示斜体，被****包含的表示粗体，其中的*也可以换成_12345**一个人来到田纳西**__毫无疑问__*我做的馅饼是全天下*_最好吃的_一个人来到田纳西毫无疑问我做的馅饼是全天下最好吃的分隔符***表示page break；---表示section break；___表示sentence break；123456789page break***section break---sentence break___page breaksection breaksentence break代码使用`&#123;codeblock&#125;``` `表示代码块，language表示代码块中代码的语言类型，在&#123;codeblock&#125;中插入要写的代码123456```java ```java public static void main(String[] args)&#123; &#125; ``` `123public static void main(String[] args)&#123;&#125;特殊表示123~~删除元素~~++下划线++==高亮显示==删除元素++下划线++==高亮显示==]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
