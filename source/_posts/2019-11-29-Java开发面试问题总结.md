---
title: Java开发面试问题总结
tags:
  - Java
  - 面试
categories:
  - 面试
abbrlink: '15e10432'
date: 2019-11-29 22:23:27
---

### 集合
#### ArrayList与LinkedList的异同

- 是否保证线程安全：两个集合都是不同步的，不是线程安全的
- 底层数据结构：ArrayList底层使用的是Object数组；LinkedList底层使用的是双向链表数据结构（Jdk1.6之前为循环链表，Jdk1.7取消了循环）
- 插入和删除是否受元素为止的影响：ArrayList采用数组存储，所以是受元素位置影响的；LinkedList采用链表存储，所以不受元素位置影响
- 是否支持快速随机访问：LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index) 方法)。
- 内存占用：ArrayList的空间浪费主要体现在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（需要存放直接后继和前驱）

> ArrayList继承了RandomAccess接口，这是一个标记接口，没有定义任何方法，其作用是用于标识这个类具有随机访问功能。例如`binarySearch()`方法中会先判断传入的list是否是RandomAccess实例，如果是调用`indexBinarySearch()`方法，如果不是调用`iteratorBinarySearch()`方法

#### ArrayList源码分析

1. 初始化：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，**数组容量扩为10**

2. 扩容。添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 `oldCapacity + (oldCapacity >> 1)`，也就是旧容量的 1.5 倍。

3. 序列化。ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用。该数组成员变量使用transient修饰，并自己实现了writeObject()和readObject()方法控制只序列化数组中有元素填充的那部分内容。

<!-- more -->

#### HashMap的底层实现

Jdk1.8之前底层是**数组+链表**实现的，HashMap通过key的hashcode经过扰动函数（采用高16位于低16位进行异或运算，用于减少hash碰撞）处理过后得到hash值，然后通过`(n-1)&hash（优化后的取模运算）`判断当前元素存放的位置，如果当前位置存在元素的话，判断该元素与要存入元素的hash值和key是否相同，相同的话直接覆盖，否则通过拉链法解决冲突（jdk1.8之前使用头插法，之后使用尾插法）。
Jdk1.8之后，当链表长度大于阀值（默认位8）时，将链表转化为红黑树，用于优化搜索时间。

Jdk1.8中对hashmap扩容不是重新计算所有元素在数组的位置，因为采用的是2次幂的拓展，所以元素的位置要么是在原位置，要么是在原位置在移动2次幂的位置。所以在移动的时候没有重新计算hash值，而是通过判断最后一个bit是1还是0，如果是0说明索引没变，是1的话索引变为“原索引+oldCap”

#### HashMap多线程导致死循环

在多线程下，进行 put 操作会导致 HashMap 死循环，原因在于 HashMap 的扩容 resize()方法。由于扩容是新建一个数组，复制原数据到数组。由于数组下标挂有链表，所以需要复制链表，但是多线程操作有可能导致环形链表。复制链表过程如下:
以下模拟2个线程同时扩容。假设，当前 HashMap 的空间为2（临界值为1），hashcode 分别为 0 和 1，在散列地址 0 处有元素 A 和 B，这时候要添加元素 C，C 经过 hash 运算，得到散列地址为 1，这时候由于超过了临界值，空间不够，需要调用 resize 方法进行扩容，那么在多线程条件下，会出现条件竞争，模拟过程如下：
线程一：读取到当前的 HashMap 情况，在准备扩容时，线程二介入
![e2f99d006fbe9d2afcfa62c12551f030.jpeg](http://windylee-blog.oss-cn-beijing.aliyuncs.com/interview1.jpg)
线程二：读取 HashMap，进行扩容
![b0722b2c5f8f67a2ee39ee29607f5461.jpeg](http://windylee-blog.oss-cn-beijing.aliyuncs.com/interview2.jpg)
线程一：继续执行
![44a3ffd65c56319fd3a5e4be3bcf5c40.jpeg](http://windylee-blog.oss-cn-beijing.aliyuncs.com/interview3.jpg)
这个过程为，先将 A 复制到新的 hash 表中，然后接着复制 B 到链头（A 的前边：B.next=A），本来 B.next=null，到此也就结束了（跟线程二一样的过程），但是，由于线程二扩容的原因，将 B.next=A，所以，这里继续复制A，让 A.next=B，由此，环形链表出现：B.next=A; A.next=B
**在JDK1.8中已经解决了死循环的问题**

#### HashMap和HashTable的区别

- 是否线程安全：HashMap不是线程安全的，HashTable是线程安全的
- 效率：由于HashTable的每个方法都是用synchronized关键字修饰，所有方法都必须同步调用，所以效率要慢一些
- 是否支持key为null的情况：HashMap中，null可以作为键，这样的键只能有一个，可以有一个或多个值为null。在HashTable中put进的键值只要有一个为null，直接抛出`NullPointerException`
- 初始容量大小和每次扩容大小的不同：①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小（使用2的幂次方是一位进行模运算时可以使用与运算提高速度`(n-1) & hash`）

#### ConcurrentHashMap线程安全的具体实现方式/底层具体实现

JDK1.7首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。**ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成**。Segment 继承自 ReentrantLock，所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。

一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。因此并发度等于Segment的数量，默认为16。

JDK1.8 中ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized(CAS失败后采用加锁的方式)来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生冲突。

#### ConcurrenthashMap和HashTable的区别

- 底层数据结构：JDK1.7的ConcurrentHashMap底层采用**分段数组+链表**实现，JDK1.8采用**数组+链表/红黑树**；HashTable一直使用**数组+链表**的形式
- 实现线程安全的方式：① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。
  ② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

### Java基础
#### 面向过程和面向对象的区别

- 面向过程：性能比面向对象高，没有面向对象易维护、易复用、易拓展
- 面向对象：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护，性能比面向过程低

#### 自动装箱与拆箱

- 装箱：将基本类型（boolean、byte、char、short、int、float、long、double）用它们对应的引用类型包装起来
- 拆箱：将包装类型转换为基本数据类型

#### 接口和抽象类的区别

- 接口的方法默认是 public，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），抽象类可以有非抽象的方法
- 接口中的实例变量默认是 final 和static类型的，而抽象类中则不一定
- 一个类可以实现多个接口，但最多只能实现一个抽象类
- 接口不能用 new 实例化，但可以声明，但是必须引用一个实现该接口的对象 从设计层面来说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。

#### 成员变量和局部变量的区别

- 从语法形式上，看成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；成员变量可以被 public,private,static 等修饰符所修饰，而局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰；
- 从变量在内存中的存储方式来看，成员变量是对象的一部分，而对象存在于堆，局部变量存在于栈
- 从变量在内存中的生存时间上看，成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。
- 成员变量如果没有被赋初值，则会自动以类型的默认值而赋值（一种情况例外被 final 修饰的成员变量也必须显示地赋值）；而局部变量则不会自动赋值

#### String Pool

字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程中将字符串添加到 String Pool 中。

当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。

在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。

- `String s1 = "aaa"`，会自动将字符串字面量放入到String Pool中
- `new String("aaa")`，会创建两个字符串对象（String Pool中没有的情况下）:"aaa"属于字面量，编译期会在String Pool中创建一个字符串对象，并指向该字符串字面量；使用new方式会在堆中创建一个字符串对象

#### Java中的异常

在Java中Throwable是所有异常类的祖先，有两个重要的子类：Exception（程序本身可以处理的异常）和Error（程序无法处理的异常）。Exception又分为检查异常和非受检查异常，前者可以在编译期检查到，需要在代码中对异常进行捕获或者向外层抛出；后者需要在运行时才能发现，抛出后将导致程序崩溃(编译期不要求对该类异常进行捕获)。

#### BIO、NIO和AIO的区别

- BIO
  - 同步阻塞，面向流，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不作任何我事情就会造成不必要的线程开销
  - BIO适用于连接数目比较小且固定的架构
- NIO
  - 同步非阻塞，面向缓冲区，服务器实现为一个请求一个线程，即客户端连接的请求都会注册到多路复用器上，多路复用器轮询到连接有IO请求时才启动一个线程进行处理。
  - 适用于连接数目多且连接时间短的架构
- AIO
  - 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的IO请求都是由OS先完成在通知服务器应用去启动线程处理
  - 适用于连接数目多且比较长的架构

#### 迭代器的fail-fast机制

在构造迭代器时，通过expectedModCount记录了当前的修改次数，在调用`next`和`remove`方法时会调用`checkForComodification`方法，检查迭代器中的记录和集合中的`modCount`变量（该变量在调用对集合进行修改的函数时会进行自增操作，例如：`add`, `remove`, `clear`, `ensureCapacity`）是否相等，如果不相等说明在迭代器遍历过程中有其他线程对集合做出了修改，会抛出`ConcurrentModificationException`异常。
迭代器的快速失败行为不能得到保证（尽最大努力抛出），如果存在非同步的并发修改时，有可能不会抛出异常

#### 泛型

##### 优点

- 自动执行类型检查，可以避免运行期抛出`ClassCastException`异常
- 自动执行类型推断，减少编写强制类型转换的代码

##### 泛型的实现原理

Java泛型是在编译器这个层次实现的，编译时会擦除类型参数，在生成的Java字节码中是不包含泛型中的类型信息的，这个过程称为类型擦除。在字节码中类型的真正类型被称为原始类型，如果在使用泛型是指定了限定类型，则原始类型为限定类型，否则为Object。

#### Object有哪些方法

```java
 public final Class<T> getClass();
 public int hashCode();
 public boolean equals(Object obj); //自反、对称、传递、一致
 protected Object clone()  throw CloneNotSupportedException;
 public String toString();
 public final void notify();
 public final void notifyAll();
 public final void wait(long timeout) throws InterruptedException;
 public final void wait(long timeout, int nanos) throws InterruptedException;
 public final void wait() throwsInterruptedException;
 protected void finalize() throwsThrowable;
```

#### 反射机制

在程序运行时，对于任意一个类都能够依赖字节码文件获取到他的所有属性和方法（属性是什么类型的，方法的返回值是什么类型，有哪些参数），更重要的是可以动态生成对象，并调用他的方法和属性。在具体编程上，就是通过字符串的形式，比如用类的全限定名获取想要的Class的字节码对象，然后同样以字符串形式执行方法名、属性名，最后这个类的各个组成部分都可以拆解为一个对象去操作。

这样减轻了JVM的内存负担，使得操作更加灵活。特别是对于一些框架，比如Spring，他提供的框架是一个黑盒，已经打包成jar包，开发者是不能任意修改的，它让用户自己去定义用户需要的类，然后他通过XML或者注解的方式获取到配置的类名，然后使用注解去动态创建这些类。

#### Java多态的实现方式

**方法表是实现动态调用的核心**。为了优化对象调用方法的速度，方法区的类型信息会增加一个指针，该指针指向记录该类方法的方法表，方法表中的每一个项都是对应方法的指针。这些方法中包括从父类继承的所有方法以及自身重写（override）的方法。JVM 的方法调用指令有四个，分别是 `invokestatic`，`invokespecial`，`invokesvirtual` 和 `invokeinterface`。前两个是静态绑定，后两个是动态绑定的。类调用 (invokestatic) 是在编译时就已经确定好具体调用方法的情况。实例调用 (invokevirtual)则是在调用的时候才确定具体的调用方法，这就是动态绑定，多态要解决的核心问题

**继承**：在执行某个方法时，在方法区中找到该类的方法表，再确认该方法在方法表中的偏移量，找到该方法后如果被重写则直接调用，否则认为没有重写父类该方法，这时会按照继承关系搜索父类的方法表中该偏移量对应的方法。 

**接口**：Java 允许一个类实现多个接口，从某种意义上来说相当于多继承，这样同一个接口的的方法在不同类方法表中的位置就可能不一样了。所以不能通过偏移量的方法，而是通过搜索完整的方法表。

#### Java注解的实现方式

类、字段、方法，在class结构中都有自己特定的表结构，而且各自都有自己的属性。于注解，作用的范围也可以不同，可以作用在类上，也可以作用在字段或方法上。编译器会对应将注解信息存放到类、字段、方法自己的属性(attributes)上当JVM加载class文件字节码时，就会根据注解的位置，将RuntimeVisibleAnnotations属性值保存到Class对象的对应的属性表中，就可以通过java的反射机制获得注解对象，进而拿到注解的属性值。

注解被编译后的本质就是一个继承Annotation接口的接口，当通过反射方式获取注解对象时，JDK会通过动态代理生成一个实现了相应接口的对象，并将RuntimeVisibleAnnotations属性值设置进此对象中，通过它的value()方法就可以获取到注解值。
### JVM

#### 运行时区域有哪些，分别存什么

- 程序计数器，用于保存当前线程所执行的字节码的行号指示器。在JVM的概念模型中，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。**为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储**
- 虚拟机栈，保存局部变量表、操作数栈等
- 本地方法栈，为虚拟机使用到的Native方法服务，本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。
- 堆，存放对象实例
- 方法区，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。运行时常量池也在这个区域内，用于存放编译期生成的各种字面量，符号引用和翻译出来的直接引用。**JDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。**
- 直接内存，Java NIO中的缓冲区使用的内存，不是虚拟机运行时数据区的一部分

#### 什么时候进行GC

- Minor GC触发条件

  Eden区空间不足时触发

- Full GC触发条件
  - 调用System.gc时，系统建议执行Full GC，但是不必然执行
  - 老年代空间不足
  - 方法区空间不足
  - 通过Minor GC后进入老年代的平均大小大于老年代的可用内存
  - 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小

#### GC Roots有哪些

- 虚拟机栈(栈帧中的本地变量表)中引用的对象
- 方法区域中的类静态属性引用的对象
- 方法区域中常量引用的对象
- 本地方法栈中JNI(Native方法)中引用的对象

#### 存在哪几种垃圾收集器

- Serial收集器（Serial Old），只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束。

- ParNew收集器，**ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。**

- Parallel Scavenge收集器（Parallel Old），重点关注吞吐量

- CMS收集器

  - 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。
  - 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。
  - 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。
  - 并发清除：不需要停顿。

  由于 CMS 收集器不是独占式的回收器，在 CMS 回收过程中，应用程序仍然在不停地工作。在应用程序工作过程中，又会不断地产生垃圾。这些新生成的垃圾在当前 CMS 回收过程中是无法清除的。同时，因为应用程序没有中断，所以在 CMS 回收过程中，还应该确保应用程序有足够的内存可用。因此，CMS 收集器不会等待堆内存饱和时才进行垃圾回收，而是当前堆内存使用率达到某一阈值时，便开始进行回收，以确保应用程序在 CMS 工作过程中依然有足够的空间支持应用程序运行。

  这个回收阈值可以使用-XX:CMSInitiatingOccupancyFraction 来指定，默认是 68。即当老年代的空间使用率达到 68%时，会执行一次 CMS 回收。如果应用程序的内存使用率增长很快，在 CMS 的执行过程中，已经出现了内存不足的情况，此时，CMS 回收将会失败，JVM 将启动老年代串行收集器进行垃圾回收。如果这样，应用程序将完全中断，直到垃圾收集完成，这时，应用程序的停顿时间可能很长。

  标记-清除算法将会造成大量内存碎片，离散的可用空间无法分配较大的对象。在这种情况下，即使堆内存仍然有较大的剩余空间，也可能会被迫进行一次垃圾回收，以换取一块可用的连续内存，这种现象对系统性能是相当不利的，为了解决这个问题，CMS 收集器还提供了几个用于内存压缩整理的算法。

- **G1收集器**

  G1收集器和之前垃圾收集器拥有完全不同的内存结构，虽然从逻辑上也存在年轻代、老年代，但是物理空间上不再连续而是散列在内存中的一个个`regions`。内存空间分割成很多个相互独立的空间，被称作`regions`。通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。

  G1中提供了三种垃圾回收模式，young gc、mixed gc和full gc，在不同条件下被触发。

  1. young gc

     发生在年轻代的GC算法，一般对象（除了巨型对象）都是在eden region中分配内存，当所有eden region被耗尽无法申请内存时，就会触发一次young gc，这种触发机制和之前的young gc差不多，执行完一次young gc，活跃对象会被拷贝到survivor region或者晋升到old region中，空闲的region会被放入空闲列表中，等待下次被使用。

  2. mixed gc

     当越来越多的对象晋升到老年代old region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即mixed gc，该算法并不是一个old gc，除了回收整个young region，还会回收一部分的old region，这里需要注意：是一部分老年代，而不是全部老年代，可以选择哪些old region进行收集，从而可以对垃圾回收的耗时时间进行控制。在mixed gc中有一个阀值参数：-XX:InitiatingHeapOccupancyPercent，当老年代大小占整个堆大小百分比达到该阀值时会触发一个mixed gc。

     如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤：

     - 初始标记
     - 并发标记
     - 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。
     - 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。

  3. full gc

     如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间。

  与 CMS 收集器相比，G1 收集器是基于标记-压缩算法的。因此，它不会产生空间碎片，也没有必要在收集完成后，进行一次独占式的碎片整理工作。G1 收集器还可以进行非常精确的停顿控制。

#### OOM排查

1. 通过`jmap -dump`查看出现OOM时的堆转储快照，查看是否存在代码泄露。如果没有看看是否可以增加堆内存的大小或者查看代码中有没有对象生命周期过长，进行修改。
2. 如果是因为虚拟机栈或者本地方法栈导致的OOM，可以尝试通过调整-Xss参数减小分配给每个栈帧的内存大小
3. 如果是方法区导致的OOM，可能是运行过程中产生了大量的动态代理类（CGLIB or Java动态代理）或者jsp页面太大，可以通过-XX:PermSize参数调整永久代的大小

#### 类加载过程

java类加载需要经历一下7个过程：
**加载**
1. 通过一个类的全限定名获取该类的二进制流。

2. 将该二进制流中的静态存储结构转化为方法区运行时数据结构。 

3. 在内存中生成该类的Class对象，作为该类的数据访问入口。

**验证**
  验证的目的是为了确保Class文件的字节流中的信息不回危害到虚拟机.
1. 文件格式验证：验证字节流是否符合Class文件的规范，如主次版本号是否在当前虚拟机范围内，常量池中的常量是否有不被支持的类型.
2. 元数据验证:对字节码描述的信息进行语义分析，如这个类是否有父类，是否集成了不被继承的类等。
3. 字节码验证：是整个验证过程中最复杂的一个阶段，通过验证数据流和控制流的分析，确定程序语义是否正确，主要针对方法体的验证。如：方法中的类型转换是否正确，跳转指令是否正确等。
4. 符号引用验证：这个动作在后面的解析过程中发生，主要是为了确保解析动作能正确执行。

**准备**
  准备阶段是为类的静态变量分配内存并将其初始化为默认值，这些内存都将在方法区中进行分配。准备阶段不分配类中的实例变量的内存，实例变量将会在对象实例化时随着对象一起分配在Java堆中。

**解析**
该阶段主要完成符号引用到直接引用的转换动作。解析动作并不一定在初始化动作完成之前，也有可能在初始化之后。

**初始化** 

初始化时类加载的最后一步，前面的类加载过程，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。

#### 如何判断一个类是无用的类

- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
- 加载该类的 ClassLoader 已经被回收。
- 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

#### 类的加载时机

- 使用`new`关键字实例化对象，读取或设置一个类的静态字段(被`final`修饰、已在编译期把结果放入常量池的静态字段除外)以及调用一个类的静态方法的时候
- 反射（如 `Class.forName(“com.shengsiyuan.Test”)`）调用时，如果类没有经过初始化，需先进行初始化操作
- 初始化某个类的子类，则其父类也会被初始化
- 虚拟机启动时，用户需要制定一个要执行的主类(包含`main()`方法的那个类)，虚拟机会先初始化这个主类
- 使用动态语言支持时，如果动态语言需要调用类的静态方法或者对静态变量进行操作，需要初始化对应的类

#### 双亲委派模型

该模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。这里类加载器之间的父子关系一般通过组合（Composition）关系来实现，而不是通过继承（Inheritance）的关系实现。
一个类加载器首先将类加载请求传送到父类加载器，只有当父类加载器无法完成类加载请求时才尝试加载。
使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。例如 `java.lang.Object` 存放在 `rt.jar` 中，如果编写另外一个 `java.lang.Object` 的类并放到 ClassPath 中，程序可以编译通过。由于双亲委派模型的存在，所以在 rt.jar 中的 `Object` 比在 ClassPath 中的 `Object` 优先级更高，这是因为 rt.jar 中的 `Object` 使用的是启动类加载器，而 ClassPath 中的 `Object` 使用的是应用程序类加载器。rt.jar 中的 `Object` 优先级更高，那么程序中所有的 `Object` 都是这个 `Object`。

#### 对象初始化过程

1. 首先查看类的符号引用，看是否已经在常量池中，在说明已经加载过了，不在的话需要进行类的加载，验证，准备，解析，初始化的过程。
2. 上诉过程执行完毕以后，又将 Student 加载进内存，也就是存储 Student.class的字段信息和方法信息，存储到方法区中
   字段信息：存放类中声明的每一个字段的信息，包括字段的名、类型、修饰符。
   方法信息：类中声明的每一个方法的信息，包括方法名、返回值类型、参数类型、修饰符、异常、方法的字节码。
3. 然后在自己的线程私有的虚拟机栈中，存储该引用，然后在每个线程的私有空间里面去分配空间存储 new Student(),如果空间不足在 eden 区域进行分配空间
4. 对类中的成员变量进行默认初始化
5. 对类中的成员变量进行显示初始化
6. 有构造代码块就先执行构造代码块，如果没有，则省略(此步上文未体现)
7. 执行构造方法，通过构造方法对对对象数据进行初始化
8. 堆内存中的数据初始化完毕，把内存值复制给 s 变量

#### JVM内存模型

- 主内存与工作内存 

Java内存模型规定了**所有的变量都存储在主内存中，每条线程还有自己的工作内存**，线程的工作内存中保存了被该线程使用到的变量的主内存的副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。**不同的线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递需要在主内存中完成**。 

- 内存间交互操作 

一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，JMM定义了一下八种操作来完成： 

\- lock（锁定）：作用域主内存的变量，它把一个变量标识为一条线程独占的状态； 

\- unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定； 

\- read（读取）：作用于主内存变量，它变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用 

\- load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中； 

\- use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 

\- assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 

\- store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。 

\- write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。 

### 并发

#### ThreadLocal的原理，是如何解决内存泄露的风险的

如果某个类不是线程安全的，并且还要在多线程下共享就需要使用到ThreaLocal类，ThreadLocal保证了每个线程获取到的都是对象的一个本地线程副本。ThreadLocal只是一个包装类，本身并不持有数据，每个Thread类内部都有一个threadLocals对象，该对象的结构类似于HashMap，Key是ThreadLocal类型，Value为Object类型，该对象内部真正保存了线程的本地变量副本，对ThreadLocal进行的操作都会委托给该对象进行处理。

threadLocals是ThreadLocalMap类型，继承自WeakReference类，所以当创建ThreadLocal对象的线程被销毁之后，下一次GC就会将其进行回收，然后以后调用get的时候会寻找key为null的键值对，将其对应的value删除掉。但是依然存在无法及时清理的问题。所以当我们使用完ThreadLocal之后最好手动remove一下，这样当容量不足时已启动启发式的垃圾清理，代码会自动回收value值为null的slot。

#### 线程的三种写法

- 继承自Thread类，重写run方法（单继承，无法使用线程池，继承Thread无法复用、创建成本高）
- 继承自Runnable接口，重写run方法（无法获取返回值和捕获线程中抛出的异常）
- 继承自Callable接口，重写call方法

#### Java中线程同步的方式

- 同步方法，使用synchronized关键字修饰方法
- 同步代码块，使用synchronized关键字修饰的代码块
- 使用volatile修饰的变量实现线程同步
- 使用ReentranLock实现线程同步
- 使用ThreadLocal管理变量，通过变量的线程副本实现同步
- 通过阻塞队列实现同步
- 通过原子变量实现同步

#### 线程池

- 创建线程池时每个参数的作用

  - **corePoolSize**：核心池的大小，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务。
  - **maximumPoolSize**：线程池最大线程数，它表示在线程池中最多能创建多少个线程；
  - **keepAliveTime**：表示超出corePoolSize数量的线程在空闲多长时间后终止
  - **unit**：参数keepAliveTime的时间单位
  - **workQueue**：一个阻塞队列，用来存储等待执行的任务
  - **threadFactory**：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程做些更有意义的事情，比如设置daemon和优先级等等
  - **handler**：表示当拒绝处理任务时的策略，

- 线程创建规则

  - 线程数量小于 corePoolSize，直接创建新线程处理新的任务
  - 线程数量大于等于 corePoolSize，workQueue 未满，则缓存新任务
  - 线程数量大于等于 corePoolSize，但小于 maximumPoolSize，且 workQueue 已满。则创建新线程处理新任务
  - 线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务

- 线程池大小估计

  计算密集型：CPU核心数+1，IO密集型：CUP核心数 * 2 + 1

#### synchronized关键字的原理

**synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。** 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1（持有锁的线程再次获取时继续加1，从而实现可重入特性）。相应的在执行 monitorexit 指令后，将锁计数器减1，如果计数器变为0表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

synchronized 修饰的方法使用`ACC_SYNCHRONIZED `标识，该标识指明了该方法是一个同步方法。调用方法时，会首先检查该标志是否被设置，如果设置了，就会执行上述的monitor操作流程

#### synchronized的优化

Java的线程模型是通过将其映射到操作系统原生线程上的，所以在进行线程切换时需要有用户态切换到内核态，需要较长时间，时间效率较低。所以JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

- **自旋锁与自适应自旋**，如果有多个线程同时执行，可以让后面请求锁的线程执行一段"盲等"的循环操作，不放弃处理器时间，看持有锁的线程是否很快就会释放锁。但是如果锁被占用很长时间，自旋的线程就会白白消耗处理器资源，反而会带来性能伤的浪费，默认的自旋次数时10。在JDK1.6中，引入了适应性自旋，意味着自旋的时间不再固定，可以根据历史自旋的统计结果自动调整自旋次数

- **锁消除**，虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的硕进行消除。是否消除主要的判断依据来源于逃逸分析，如果判断在一段代码中，堆伤所有数据都不会逃逸出去从而被其它线程访问到，就可以把它们当做栈上数据对待，认为它们是线程私有的

- **锁粗化**，如果一系列的连续操作都对同一个对象反复加锁和解锁（例如加锁操作出现在循环体中），虚拟机会把加锁同步的范围拓展到整个操作序列的外部

- **轻量级锁**，在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为"01"状态），虚拟机首先在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝。然后虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位转变为"00"，表示该对象处于轻量级锁定状态。如果更新操作失败，虚拟机首先检查对象的Mark Word是否指向当前线程的栈帧，如果是说明当前线程已经拥有了这个对象的锁，直接进入同步块继续执行，否则说明这个锁对象已经被其它线程抢占了。解锁过程也是通过CAS操作实现的，如果对象的Mark Word仍然指向当前线程的锁记录，就是用CAS操作吧对象当前的Mark Word和线程中复制的Mark Word替换回来，如果替换成功，整个同步过程完成。否则，说明有其他线程尝试过获取该锁，就要在释放锁的过程中，唤醒被挂起的线程

- **偏向锁**，当锁对象第一次被线程获取时，虚拟机将对象头中的标志位置为"01"，同时使用CAS操作吧获取到这个锁的线程的ID记录在对象的Mark Word中，如果cas成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，不需要进行同步操作。当有另一个线程尝试获取该锁时，偏向模式失败。

  ![](http://windylee-blog.oss-cn-beijing.aliyuncs.com/Snipaste_2019-03-08_11-34-32.png)

#### AQS原理

在AQS中有一个int类型的state变量，若state变量为没有锁定状态（由子类自己确定语义），则将当前请求资源的线程设置为有效的工作线程，并将state设置为锁定状态；否则将请求资源的线程加入CLH等待队列中，并使用`LockSupport.park()`函数将线程置为阻塞状态，等待当资源可用时被唤醒。

> CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。

AQS使用了模板方法的设计模式，子类继承`AbstractQueuedSynchronized`时只需要选择性重写以下方法

```java
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

#### CyclicBarrier和CountDownLatch的区别

- CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用
- CountDownLatch: 一个或者多个线程，等待其他多个线程完成某件事情之后才能执行
  CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行。

#### volatitle关键字

当一个变量被声明成volatile后，就具备了一下两种特性。

1. 内存可见性，即当一条线程修改了这个变量的值，新值对于其他线程来说是立即得知的。由于只能保证可见性，在不符合以下两条规则的运算场景中，仍要通过加锁来保证原子性：

- 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值
- 变量不需要与其他状态变量共同参与不变约束

2. 禁止指令重排序优化，普通的变量只能保证在该方法的执行过程中所有依赖赋值结果的地方都能得到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。

#### 如何尽量减少上下文切换

- 无锁编程：用多线程处理数据时，尽量避免使用锁，防止多线程竞争锁的时候引起的上下文切换
- CAS算法：使用硬件同步原语，不需要加锁
- 根据任务类型选择线程数量：cpu密集型不需要线程数量过多（与处理器内核保持一致），io密集型可以适量加大线程数量
- 使用协程：在单线程里面实现多任务的调度，并在单线程里维持多个任务之间的切换

### 操作系统

#### 进程、线程、程序

- **线程**与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。(共享：堆，静态变量，文件描述符；独占：栈，寄存器值，线程id)
- **程序**是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码
- **进程**是程序的一次执行过程，是资源分配的基本单位

#### 线程有哪些状态

- 新建(new)：新创建了一个线程对象
- 就绪（runnable）：线程已经获得了除CPU之外的所有资源，等待被线程调度选中，获取CPU的使用权
- 运行（running）：线程获取到了CPU资源，正在运行中
- 阻塞（block）：线程因为需要等待除CPU之外的其他资源满足后才能继续运行，所以主动放弃了CPU的使用权
- 终止（terminated）：线程结束生命周期

#### 如何创建进程，fork函数的返回值

- system函数，运行义字符传参数的形式传递给它的命令，他会在一个进程的内部启动另一个进程，并等待命令的完成
- exec系列函数，可以把当前进程替换为一个新进程，新进程的PID、PPID和nice都和原来的一样，只是用另一个新进程替换了当前进程的征文、数据、堆和栈
- fork函数，返回的是新子进程的PID，子进程从fork调用处执行，在子进程中fork调用返回的是0。fork函数得到的子进程从父进程继承了整个进程空间。fork系统调用之后，父子进程交替执行，如果父进程先退出，子进程还没退出--**孤儿进程**，子进程的父进程将变为**init进程**；如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为**僵尸进程**

#### 僵尸进程和孤儿进程

- 僵尸进程放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，直到父进程通过wait/waitpid才释放。如果父进程接收到系统发出的SIGCHLD信号但没有调用wait/waitpid或者显式忽略该信号，将一直保持僵尸状态，如果父进程结束，init进程会接手并清理这个子进程，如果父进程不会结束，子进程将一直保持僵尸状态。如果存**在大量的僵尸进程，将因为没有可用的进程号而导致不能产生新的进程**
- 一个父进程退出，而它的子进程还在运行，这些子进程将成为孤儿进程，孤儿进程将被init进程接管，由其完成对他们的状态收集工作

#### COW（copy-on-write）

传统的fork调用直接把所有的资源复制给新创建的进程，但是子进程可能并不需要这些资源导致效率低下。LInux采用了写时复制优化，可以退出甚至免除拷贝数据，创建子进程时并不复制整个父进程空间，而是让子进程共享父进程的数据，只有在需要写入的时候，数据才会被复制，从而使各个进程拥有自己的拷贝。也就是说，**资源的复制只有在需要写入的时候才进行，在此之前，只是以只读方式共享。这种技术使地址空间上的页的拷贝被推迟到实际发生写入的时候**

#### init进程

init进程由idle进程即0进程创建，Linux中的所有进程都是由init进程创建并运行的，是所有其他用户进程的祖先进程。首先Linux内核启动，然后在用户空间中启动init进程，再启动其他系统进程。在系统启动完成后，init进程将变为守护进程监视系统其他进程。

init进程启动后，通过执行一些管理任务结束引导进程，该进程会检查文件系统，清理/tmp，启动各种服务以及为每个终端和虚拟控制台启动getty。init同样也会收集孤儿进程。

#### Linux同步机制

所有的futex同步操作都应该从用户空间开始，首先创建一个futex同步变量，也就是位于共享内存的一个整型计数器。
当进程尝试持有锁或者要进入互斥区的时候，对futex执行"down"操作，即原子性的给futex同步变量减1。如果同步变量变为0，则没有竞争发生， 进程照常执行。如果同步变量是个负数，则意味着有竞争发生，需要**调用futex系统调用的futex_wait操作休眠当前进程（进入内核态）**。
当进程释放锁或 者要离开互斥区的时候，对futex进行"up"操作，即原子性的给futex同步变量加1。如果同步变量由0变成1，则没有竞争发生，进程照常执行。如 果加之前同步变量是负数，则意味着有竞争发生，需要**调用futex系统调用的futex_wake操作唤醒一个或者多个等待进程（进入内核态）**。

#### 进程间通信方式

- **管道/匿名管道(pipe)**：提供面向字节流的通信，管道内部提供了同步机制，但有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系（具有亲缘关系的进程才能访问到管道文件）。命名管道:name_pipe克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信（不具有亲缘关系的进程可以根据管道的全路径名获取到管道文件）。管道的实质是一个内核环形缓冲队列（缓冲区的容量是有限制的），进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据

> 如果所有指向管道写端的文件描述符都关闭了,而仍然有进程从管道的读端读数据,那么管道中剩余的数据都被读取后,再次read会返回0,就像读到文件末尾一样
>
> 如果有指向管道写端的文件描述符没关闭，而持有管道写端的进程也没有向管道中写数据,这时有进程从管道读端读数据,那么管道中剩余的数据都被读取后,再次read会阻塞,直到管道中有数据可读了才读取数据并返回。
>
> 如果所有指向管道读端的文件描述符都关闭了,这时有进程指向管道的写端write,那么该进程会收到信号SIGPIPE,通常会导致进程异常终止。
>
> 如果有指向管道读端的文件描述符没关闭,而持有管道写端的进程也没有从管道中读数据,这时有进程向管道写端写数据,那么在管道被写满时再write会阻塞,直到管道中有空位置了才写入数据并返回。

   - **信号量**：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
   - **消息队列**：由消息组成的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
   - **信号**：信号可以在任何时候发给某一进程，而无需知道该进程的状态。如果该进程当前并未处于执行状态，则该信号就有内核保存起来，直到该进程回复执行并传递给它为止。
   - **共享内存**：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
   - **套接字**：更为一般的进程间通信机制，可用于不同机器之间的进程间通信

#### 同步/非同步、阻塞/非阻塞

同步指的是用户进程触发 IO 操作并等待或者轮询的去查看 IO 操作是否就绪，而异步是指用户进程触发 IO 操作以后便开始做自己的事情，而当 IO 操作已经完成的时候会得到 IO 完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据 IO 操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。

- 同步阻塞 IO：在此种方式下，用户进程在发起一个 IO 操作以后，必须等待 IO 操作的完成，只有当真正完成了 IO 操作以后，用户进程才能运行。JAVA 传统的 IO 模型属于此种方式！
- 同步非阻塞 IO:在此种方式下，用户进程发起一个 IO 操作以后边可返回做其它事情，但是用户进程需要时不时的询问 IO 操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的 CPU 资源浪费。其中目前 JAVA 的 NIO 就属于同步非阻塞 IO。
- 异步阻塞 IO：此种方式下是指应用发起一个 IO 操作以后，不等待内核 IO 操作的完成，等内核完成 IO 操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问 IO 是否完成，那么为什么说是阻塞的呢？因为此时是通过 select 系统调用来完成的，而 select 函数本身的实现方式是阻塞的，而采用 select 函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！
- 异步非阻塞 IO:在此种模式下，用户进程只需要发起一个 IO 操作然后立即返回，等 IO 操作真正的完成以后，应用程序会得到 IO 操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的 IO 读写操作，因为真正的 IO 读取或者写入操作已经由内核完成了。

#### select、poll、epoll

I/O多路复用就是`通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作`。`但select，pselect，poll，epoll本质上都是同步I/O`，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

  - select：调用后select函数会阻塞，同时将fd集合从用户态拷贝到内核态，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。**单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低**
  - poll：`将用户传入的数组拷贝到内核空间`，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。**基于链表存储，没有最大连接数的限制**
 这两种方式都需要再返回后，通过遍历文件描述符来获取已经就绪的socket，因此随着监视的描述符数量的增长，效率会线性下降
  - `epoll`支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，`epoll`使用“事件”的就绪通知方式`，通过epoll_ctl注册fd，`一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。

 在select/poll中，`进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描`，而epoll事先通过epoll_ctl()来注册一个文件描述符，`一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制`，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。(`此处去掉了遍历文件描述符，而是通过监听回调的的机制`)

 **三者之间的区别**

 - 支持一个进程所能打开的最大连接数

   | 方式   | 描述                                                         |
   | ------ | ------------------------------------------------------------ |
   | select | 单个进程所能打开的最大连接数FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32\*32，同理64位机器上FD_SETSIZE为32\*64），我们可以对其进行修改，然后重新编译内核，但是性能会受到影响 |
   | poll   | poll本质上和select没有区别，但是因为是基于链表存储的，没有最大连接数的限制 |
   | epoll  | 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右 |

 - FD剧增后带来的IO效率问题

   | 方式   | 描述                                                         |
   | ------ | ------------------------------------------------------------ |
   | select | 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题” |
   | poll   | 同上                                                         |
   | epoll  | epoll内核中实现是根据每个fd上的callback函数实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题 |

 - 消息传递方式

   | 方式   | 描述                                             |
   | ------ | ------------------------------------------------ |
   | select | 内核需要将消息传递到用户空间，都需要内核拷贝动作 |
   | poll   | 同上                                             |
   | epoll  | epoll通过内核和用户空间共享一块内存来实现的      |

#### Linux根目录下个文件夹的作用

- /boot 默认存放Linux的启动文件和内核
- /bin 存放Linux的常用命令
- /sbin 存放系统管理员使用的管理程序
- /var 存放经常被修改的文件，包括各种日志、数据文件
- /etc 存放系统管理时用到的各种配置文件和子目录
- /dev 包含了Linux系统中使用的所有外部设备，实际上是这些外部设备的端口，访问这些外部设备和访问文件没有区别
- /mnt 临时将别的文件系统挂载到该目录下
- /root 如果是以超级用户的身份登录的，这个是超级用户的主目录
- /home 用户存放其他用户的主目录
- /usr 存放用户的应用程序和文件
- /lib 存放系统的动态链接库
- /tmp 存放不同程序执行时产生的临时文件，被自动被系统清理

#### inode

用于存储文件的元信息，包括：文件的字节数、文件拥有者的User ID、文件的Group ID、文件权限、文件的时间戳、链接数、文件的block的位置。每个文件都必须有一个inode，如果inode用光，硬盘上就无法创建新文件。每个inode有一个号码，操作系统用inode号码来标识不同的文件。inode包含了除文件名之外的所有信息，有目录维护文件名和inode号码之间的对应关系

用户通过文件名，打开文件的过程：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。

#### 硬链接和软链接

硬链接：多个文件名指向同一个inode号码，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为"硬链接"（hard link）。inode中有一项链接数，表明指向当前inode的文件名的数量。

软链接：文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的"软链接"（soft link）或者"符号链接（symbolic link）。如果删除了文件B，打开文件A就会报错："No such file or directory"。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode"链接数"不会因此发生变化。

#### nohup机制

普通进程运行时默认会绑定TTY(虚拟终端)，关闭终端后系统会给上面所有进程发送TERM信号，这时普通进程也就退出了。`Nohup`的原理也很简单，终端关闭后会给此终端下的每一个进程发送TERM信号，而使用`nohup`运行的进程则会忽略这个信号，因此终端关闭后进程也不会退出。

#### 分段和分页的区别

- 对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

#### 产生死锁的条件和解决办法

原因：系统资源不足、线程运行推进的顺序不对、资源分配不当

4个条件：互斥、非抢占、持有并等待、循环等待
解决方法：鸵鸟策略、死锁检测和死锁恢复、死锁预防（破坏4个条件中的一个）、死锁避免（银行家算法）

#### 局部性原理

因为CPU寄存器与内存的速度不匹配问题，所以需要在他们之间加入L1、L2、L3三级缓存。内存里面的数据不能全部放到缓存中区，所以利用局部性原理存放一些最有希望被访问到的，

- 时间局部性：类似于LRU算法，越是最近一段时间被访问的数据，之后就越可能再次访问
- 空间局部性：越是与当前访问数据在空间地址上临近的，之后越可能再次访问

#### 伪共享问题

CPU读取数据的时候先从CPU缓存上读取，如果不命中才访问内存。CPU缓存是以Cache Line为单位（一般为64字节）存放的，所以就出现一个问题，如果成员变量X和y都背缓存在同一个Cache LIne中，那么多线程虽然表面上访问的是不同变量，应该不存在并发访问问题，但在内核看来确实是并发访问的。解决方案有如下两种：

- JDK6：字节填充，一般对象头占8字节，实体占X字节，填充就占64-8-X字节
- JDK8：对于共享变量加上@Contended注解

#### Linux 五种方式IO方式

- 阻塞IO

  在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，直到数据准备好(等待接收到完整的数据包)，并且将数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。不能处理别的网络IO。

- 非阻塞IO

  调用非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。`这个过程通常被称之为轮询`。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。**需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态**。

- IO多路复用

  `I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作`。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用I/O操作函数。**IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数获取数据就绪状态消息，并且其进程状态为阻塞，所以，`把IO多路复用归为同步阻塞模式`。**

  I/O多路复用技术`通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求`。与传统的多线程/多进程模型比，`I/O多路复用的最大优势是系统开销小`，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降底了系统的维护工作量，节省了系统资源

- 信号驱动IO

  首先需要允许Socket进行信号驱动IO，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，**可以在信号处理函数中调用I/O操作函数处理数据(将数据从内核拷贝到用户空间，这个过程是阻塞的)**。

- 异步IO

  用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，**内核直接复制数据给进程，然后从内核向进程发送通知(kernel会给用户进程发送一个signal或执行一个基于线程的回调函数来完成这次 IO 处理过程。IO两个阶段，进程都是非阻塞的**。

### 计算机网络

#### 七层协议 and 五层协议

**OSI体系结构**：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层

**TCP/IP体系结构**：应用层、传输层、网际层、网络接口层

**五层协议体系结构**：应用层、传输层、网络层、数据链路层、物理层

**应用层**：通过应用程序间的交互来实现特定网络应用。应用层协议定义的是应用程序进程间的通信和交互规则。对于不同的网络应用需要不同的应用层协议，如DNS协议、HTTP协议、SMTP协议等
**~~表示层~~**：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。
**~~会话层~~**：建立及管理会话。

**传输层**：负责为两台主机进程之间的通信提供通用的数据传输服务

**网络层**：为主机提供数据传输服务，负责在多个数据链路中选择合适的网间路由和交换节点，确保数据及时传送

**数据链路层**：链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧（封装成帧，透明传输，差错校验CRC）

**物理层**：实现相邻计算机结点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异

#### TCP状态转移

![1551083858141](http://windylee-blog.oss-cn-beijing.aliyuncs.com/interview6.png)

#### 三次握手 and 四次挥手

三次握手的过程如下：

- 客户端A 发送SYN（seq = x）报文给服务器B，然后进入SYN_SENT状态；
- B收到SYN报文，回应一个SYN（seq = y） ACK （ack = x + 1）报文，进入SYN_RCVD状态；

- A收到SYN报文后，回应一个ACK（ACK = y + 1），进入ESTABLISHED状态；B收到ACK报文后，进入ESTABLISHED状态

四次挥手的过程如下：

- 客户端A上的某个进程，主动关闭连接，发送FIN（seq = u）报文给B，然后进入FIN_WAIT_1状态；
- B收到FIN报文，回应一个ACK （ACK = u + 1）报文，进入CLOSED_WAIT状态；A收到FIN报文，进入FIN_WAIT_2状态；
- B向A发送FIN（seq = v）报文，进入LAST_ACK状态；
- A收到FIN报文后，向B发送ACK(ACK = v + 1)报文，进入TIME_WAIT状态

#### 为什么采用三次握手

如果A发出的第一个连接请求报文段并没有丢失，而是在某个网络节点长时间滞留了，以致延误到连接释放后的某个时间才到达B，B接收到该失效的连接请求报文段后，误认为是A发出的一次新的连接请求，就向A发出确认报文段，同意建立连接。如果不采用三次握手，只要B发出确认，新的连接就建立了，但是A并没有发出建立连接的请求，不会像B发送数据，而B却一直等待A发送数据，白白浪费了资源

#### TIME_WAIT的作用，为什么要是2MSL

- 保证A发送的最后一个ACK报文段能够到达B。A发送的报文段有可能丢失，因而使处于LAST-ACK状态的B不能正常关闭连接。B会超时重传这个FIN报文段，A就能在2MSL时间内收到这个重传的FIN报文段。接着A重传一次确认，重新启动2MSL计时器，最后A和B都能正常进入到CLOSED状态。如果A在TIME_WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，导致无法接收到B重传的FIN字段，因为也不会在发送一次确认报文段。这样B就无法按照正常步骤进入CLOSED状态
- 经过2MLS之后，可以使A和B之间的传输报文在网络中消失，防止两台机器重建连接后接收到上次断开的连接传输的报文

#### TIME_WAIT状态过多的原因和解决方案

在**高并发短连接(业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间)**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态，可以通过修改linux的配置文件，允许重用处于TIME_WAIT状态的socket

```bash
net.ipv4.tcp_syncookies = 1 #表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1 #表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_recycle = 1 #表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_fin_timeout #修改系默认的 TIMEOUT 时间
```

#### UDP和TCP的区别

**UDP 的主要特点**

1. UDP 是无连接的；
2. UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；
3. UDP 是面向报文的；
4. UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）；
5. UDP 支持一对一、一对多、多对一和多对多的交互通信；
6. UDP 的首部开销小，只有8个字节，比TCP的20个字节的首部要短。

**TCP 的主要特点**

1. TCP 是面向连接的；
2. 每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）；
3. TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达；
4. TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；
5. 面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。

#### IP头部字段，TCP头部字段

![29b0860e5a3e8c347dece1c60961fba8.jpeg](evernotecid://49AAD397-781F-4ADE-9BAE-38CAFFD93A9E/appyinxiangcom/22850103/ENResource/p76)
![3fc57834c9710827d8deb9fbb7b2c84a.png](evernotecid://49AAD397-781F-4ADE-9BAE-38CAFFD93A9E/appyinxiangcom/22850103/ENResource/p80)

#### 可靠传输

- 应用数据被分割成 TCP 认为最适合发送的数据块。
TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
- 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
- TCP 的接收端会丢弃重复的数据。
- 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
- 拥塞控制： 当网络拥塞时，减少数据的发送。
- 停止等待协议：它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段（**每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些**）。

#### 滑动窗口

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小（由此实现流量控制的功能），凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。
接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了

![1551083554944](http://windylee-blog.oss-cn-beijing.aliyuncs.com/interview4.png)

![1551083574272](http://windylee-blog.oss-cn-beijing.aliyuncs.com/interview5.png)

#### 拥塞控制

拥塞控制是为了降低整个网络的拥塞程度，而流量控制是为了让接收方能来得及接收。
TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。
![46e70389cb9716aa31b85237e5c74a25.png](evernotecid://49AAD397-781F-4ADE-9BAE-38CAFFD93A9E/appyinxiangcom/22850103/ENResource/p83)
**慢开始、拥塞避免**
发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...
注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。
**快重传、快恢复**
在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。
在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。
在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。
慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

#### HTTP常见状态码

- 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。
- 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。
- 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。
- 301 Moved Permanently ：永久性重定向
- 302 Found ：临时性重定向
- 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。
- 400 Bad Request ：请求报文中存在语法错误。
- 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
- 403 Forbidden ：请求被拒绝。

#### POST和GET的区别

- GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中
- 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码；POST 参考支持标准字符集
- GET方法是安全的（不会修改服务器状态）；POST不是安全的
- GET方法是幂等性的；POST方法不是

#### Restful协议

restful是一套编写接口的协议，协议规定如何编写以及如何设置返回值、状态码等信息。对于同一个url，根据不同的method做不同的处理，比如：post 创建数据、get获取数据、put和patch修改数据、delete删除数据。url尽量使用名词，所以也被称为"面向资源编程"。

> 面向资源符合HTTP的规范
>
> 无状态性
>
> 利用方法method属性描述对资源的操作，具有自解释性

#### HTTP1.1和HTTP1.0的区别

1. http1.0 需要 keep-alive 参数来告知服务器要建立一个长连接，而 http1.1 默认支持长连接
2. HTTP 1.1 支持只发送 header 信息(不带任何 body 信息)，如果服务器认为客户端有权限请求服务器，则返回 100，否则返回 401。客户端如果接受到 100，才开始把请求 body 发送到服务器。这样当服务器返回 401 的时候，客户端就可以不用发送请求 body 了，节约了带宽。
3. host 域 http1.0 没有 host 域，http1.1 才支持这个参数。
4. 带宽优化及网络连接的使用，HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range头域，允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

#### HTTP2.0和HTTP1.0的区别

1. 新的二进制格式（Binary Format），HTTP1.x 的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认 0和 1 的组合。基于这种考虑 HTTP2.0 的协议解析决定采用二进制格式，实现方便且健壮。
2. 多路复用（MultiPlexing），即连接共享，建立起一个连接请求后，可以在这个链接上一直发送，不要等待上一次发送完并且受到回复后才能发送下一个（http1.0 是这样），是可以同时发送多个请求，互相并不干扰。
3. header  压缩，如上文中所言，对前面提到过 HTTP1.x 的 header 带有大量信息，而且每次都要重复发送，HTTP2.0 利用 HPACK 对消息头进行压缩传输，客服端和服务器维护一个动态链表（当一个头部没有出现的时候，就插入，已经出现了就用表中的索引值进行替代），将既避免了重复 header 的传输，又减小了需要传输的大小。
4. 服务端推送（server push），就是客户端请求 html 的时候，服务器顺带把此 html 需要的 css,js也一起发送给客服端，而不像 http1.0 中需要请求一次 html，然后再请求一次 css，然后再请求一次 js。

#### Web 页面请求过程

##### 1. DHCP 配置主机信息

- 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
- 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
- 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。
- 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。
- 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
- 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
- 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。

##### 2. ARP 解析 MAC 地址

- 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。
- 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
- 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
- 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。
- DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。
- 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
- 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。

##### 3. DNS 解析域名

- 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。
- 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
- 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
- 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
- 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。

##### 4. HTTP 请求页面

- 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。
- 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
- HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
- 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。
- HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
- 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

### 设计模式
#### 常见设计模式

单例模式、工厂模式、抽象工厂模式（**抽象工厂模式创建的是对象家族，也就是很多对象而不是一个对象，并且这些对象是相关的，也就是说必须一起创建出来。而工厂方法模式只是用于创建一个对象**）、装饰器模式、适配器模式、生成器模式、责任链模式、命令模式、观察者模式、代理模式、策略模式

#### 设计原则

- 单一职责原则
- 里氏替换原则：在使用基类的的地方可以任意使用其子类
- 依赖倒置原则：高层模块不应该依赖底层模块，二者都该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象
- 接口隔离原则：类间的依赖关系应该建立在最小的接口上，建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少
- 迪米特法则：一个类对自己依赖的类知道的越少越好，高内聚、低耦合
- 开放封闭原则：对拓展开放，对修改封闭

#### 代理模式的优点

- 代理模式能够协调调用者和被调用者，在一定程度上降低了系 统的耦合度
- 可以不修改代码，增加类的功能（增加远程调用，参数校验，权限校验等）

### 数据库

#### ACID

- 原子性（Atomicity）指事务作为整体来执行，要么全部执行，要么全不执行。
- 一致性（Consistency）指事务应确保数据从一个一致的状态转变为另一个一致的状态。
- 隔离性（Isolation）指多个事务并发执行时，一个事务的执行不应影响其他事务的执行。
- 持久性（Durability）指已提交的事务修改数据会被持久保存。

#### MySQL索引结构

- B+ Tree索引

  可以指定多个列作为索引列，多个索引列共同组成键。适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为**聚簇索引**。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。**辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。**

- Hash索引

  能以O(1)的时间复杂度进行查找，但是失去了有序性，所以无法用于排序和分组，也无法用于部分查找和范围查找

- 全文索引

  MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。

索引可以减少需要扫描的数据行数，避免进行排序和分组，避免了临时表的创建，将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）

#### 最左前缀匹配原则

索引可以简单如一个列`(a)`，也可以复杂如多个列`(a, b, c, d)`，即**联合索引**。如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否**存在（相等）**，遇到范围查询`(>、<、between、like`左匹配)等就**不能进一步匹配**了，后续退化为线性查找。例子：

- 如有索引`(a, b, c, d)`，查询条件`a = 1 and b = 2 and c > 3 and d = 4`，则会在每个节点依次命中a、b、c，无法命中d。(很简单：索引命中只能是**相等**的情况，不能是范围匹配)

#### 慢查询优化思路

##### 使用Explain进行分析

Explain 用来分析 SELECT 查询语句，比较重要的字段有：

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

##### 优化数据访问

1. 减少请求的数据量
   - 只查询必要的列，避免使用`SELECT * FROM`
   - 只返回必要的行，使用`LIMIT`限制返回的数据
2. 使用索引减少扫描的行数

#### 重构查询方式

1. 切分大查询：一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。
2. 分解大连接查询：将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联
   - 分解之后，查询的数据粒度变细，可以提高缓存层的命中率，同时其它查询可能会重用缓存中的数据
   - 减少锁竞争

#### MySQL存储引擎

##### InnoDB

是 MySQL 默认的事务型存储引擎，实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ），主索引是聚簇索引，在索引中保存了数据。

内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

##### MyISAM

B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。

提供了大量的特性，包括压缩表、空间数据索引等。

不支持事务，不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。

##### 区别

- 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- 外键：InnoDB 支持外键。
- 备份：InnoDB 支持在线热备份。
- 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- 其它特性：MyISAM 支持压缩表和空间数据索引。

#### 事务隔离级别

- 读未提交：最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**
- 读已提交：允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**
- 可重复读(默认级别)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- 串行化： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。但是这将严重影响程序的性能。

#### 分库分表

##### 垂直拆分

可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

##### 水平拆分

常见的水平分表策略归纳起来，可以总结为随机分表和连续分表两种情况，例如，取模分表，时间维度分表，以及自定义 Hash 分表。连续分表可以快速定位到表进行高效查询，大多数情况下，可以有效避免跨表查询，但是可能存在数据热点问题。随机分表可能避免数据热点问题，但是拓展时需要进行数据迁移，需要进行跨表查询的概率增加。水平拆分之后，当需要同时操作切分后的多张表时，需要使用分布式事务解决一致性问题。单表查询变成了多表查询，需要在应用中对查询的数据进行聚合

#### MySQL中锁的实现

##### 多版本控制

多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。
MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号：

- 创建版本号：指示创建一个数据行的快照时的系统版本号；
- 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。

**版本号在查询时的作用：**

把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。

##### Record Lock 

锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

##### Gap Locks

当我们**用范围条件检索数据**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给**符合范围条件的已有数据记录的索引项加锁**；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”。InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。可以防止幻读

#### 数据库中的乐观锁和悲观锁

- 乐观锁：具体实现是，表中有一个版本字段，第一次读的时候，获取到这个字段。处理完业务逻辑开始更新的时候，需要再次查看该字段的值是否和第一次的一样。如果一样更新，反之拒绝。之所以叫乐观，因为这个模式没有从数据库加锁，等到更新的时候再判断是否可以更新。
- 悲观锁是数据库层面加锁，都会阻塞去等待锁。例如：`select * from xxx from update`，在select 语句后边加了 `for update`相当于加了排它锁(写锁)，加了写锁以后，其他的事务就不能对它修改了！需要等待当前事务修改完之后才可以修改.

#### MySQL优化方式

[MySQL数据库优化的八种方式](https://www.jianshu.com/p/dac715a88b44)

### 分布式

#### Memcached和Redis的区别

- memcached只支持字符串类型，Redis支持string，list，set，zset，hash五种不同类型
- Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。
- Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。Redis Cluster 实现了分布式的支持。
- Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。

#### Redis持久化方式

##### RDB持久化

将某个时间点的所有数据都存放到硬盘上，可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。如果系统发生故障，将会丢失最后一次创建快照之后的数据。如果数据量很大，保存快照的时间会很长。

##### AOF持久化

将写命令添加到 AOF 文件（Append Only File）的末尾，对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，目前支持三种磁盘同步策略：always（每个命令都同步）、everysec（每秒同步一次）和no（由操作系统决定同步时间）。随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

#### Redis数据结构

##### 哈希表

使用拉链法处理哈希冲突。内部使用两个哈希表，方便rehash操作。rehash 操作不是一次性完成，而是采用渐进方式，避免一次性执行过多的 rehash 操作给服务器带来过大的负担，在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。

##### 跳跃表

zset使用跳跃表实现，跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

![img](https://github.com/CyC2018/CS-Notes/raw/master/docs/notes/pics/beba612e-dc5b-4fc2-869d-0b23408ac90a.png)

在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。查找、删除、添加等操作的时间复杂度为$$O(log_n)$$

#### Redis数据淘汰机制

Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。

redis提供了定期删除和惰性删除两种数据过期机制，**定期删除**，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。定期删除可能导致很多key到期后没有被删除，这样在客户端下次查询过期数据的时候会进行删除操作，这叫做**惰性删除**。如果两种过期方式都没有生效导致redis内存耗尽，就需要走内存淘汰机制。redis提供了如下6中淘汰策略：

| 策略            | 描述                                                 |
| --------------- | ---------------------------------------------------- |
| volatile-lru    | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 |
| volatile-ttl    | 从已设置过期时间的数据集中挑选将要过期的数据淘汰     |
| volatile-random | 从已设置过期时间的数据集中任意选择数据淘汰           |
| allkeys-lru     | 从所有数据集中挑选最近最少使用的数据淘汰             |
| allkeys-random  | 从所有数据集中任意选择数据进行淘汰                   |
| noeviction      | 禁止驱逐数据                                         |

Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

#### Redis主从

当启动一个 slave node 的时候，它会发送一个 `PSYNC` 命令给 master node。

- 如果这是 slave node 初次连接到 master node，那么会触发一次 `full resynchronization` 全量复制。master会fork一个子进程生成RDB文件发送给slave，在生成RDB文件期间的写命令缓存在内存中。slave 会先**写入本地磁盘，然后再从本地磁盘加载到内存**中。接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。
- master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 `resynchronization`。

使用[哨兵机制](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-sentinel.md)实现主从的容灾处理

#### Dubbo

##### 工作原理

- 第一层：**service层**，接口层，给服务提供者和消费者来实现的
- 第二层：**config层**，配置层，主要是对dubbo进行各种配置的
- 第三层：**proxy层**，服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton
- 第四层：**registry层**，服务注册层，负责服务的注册与发现
- 第五层：**cluster层**，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
- 第六层：**monitor层**，监控层，对rpc接口的调用次数和调用时间进行监控
- 第七层：**protocol层**，远程调用层，封装rpc调用
- 第八层：**exchange层**，信息交换层，封装请求响应模式，同步转异步
- 第九层：**transport层**，网络传输层，抽象mina和netty为统一接口
- 第十层：**serialize层**，数据序列化层。网络传输需要。

因为刚开始初始化的时候，消费者会将提供者的地址等信息**拉取到本地缓存**，所以注册中心挂了可以继续通信。

##### 负载均衡策略

- random loadbalance。默认情况下，dubbo 是 random load balance **随机**调用实现负载均衡，
- roundrobin loadbalance。可以对 provider 不同实例**设置不同的权重**，会按照权重来负载均衡，权重越大分配流量越高
- leastactive loadbalance
- consistanthash loadbalance。一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大

##### 集群容错策略

- failover cluster 模式。失败自动切换，自动重试其他机器，默认

- failfast cluster模式。一次调用失败就立即失败

- failsafe cluster 模式。出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。

- failback cluster 模式。失败了后台自动记录请求，然后定时重发

- forking cluster 模式。**并行调用**多个 provider，只要一个成功就立即返回。

- broadcacst cluster。逐个调用所有的 provider。

#### 分布式事务协议

##### 两阶段提交协议

在两阶段提交协议中，引入了协调者的角色，负责决定这个分布式事务是提交还是回滚

- 投票阶段

  协调者向所有参与者询问是否可以执行提交操作，并等待各参与者的响应。参与者执行的本地事务，将undo信息和redo信息写入日志。如果本地事务执行成功，将"同意"信息相应给协调者，否则将向协调者发送"终止"信息

- 提交执行阶段

  1. 当协调者获取到所有参与者的"同意"相应后，向所有参与者发送"正式提交"的请求。参与者获取到请求后正式完成操作，释放整个事务期间占用的资源，向协调者发送"完成"信息。协调者获取到所有协调者的完成信息后，标志分布式事务完成。
  2. 若任意参与者的响应信息为"终止"信息或超时未收到参与者相应，协调者向所有参与者发送"回滚操作"请求，参与者利用之前的redo日志进行回滚操作，释放占用的资源，向协调者发送"回滚完成"的信息。协调者收到所有参与者的信息后，取消分布式事务。

**缺点**：各参与者在事务执行完成前，需要一直占用本地资源；协调者需要给每个参与者执行超时时间，防止事务被阻塞；协调者存在单点故障问题；

**问题**：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，无法知道事务是否已经被提交。

##### 三阶段提交协议

- CanCommit阶段

  协调者向参与者发送CanCommit请求，询问是否可以执行事务提交操作。参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No

- PreCommit阶段

  1. 如所有相应为YES，协调者向参与者发送PreCommit请求，并进入Prepared阶段。参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。
  2. 如果任意参与者响应为NO或响应超时，协调者向所有参与者发送abort请求，参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。

- DoCommit阶段

  1. 协调接收到所有参与者发送的ACK响应，从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。参与者接收到doCommit请求之后，执行正式的事务提交并释放占用的资源，向协调者发送ACK相应。协调者接收到所有参与者的ack响应之后，完成事务。
  2. 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），协调者向所有参与者发送abort请求。参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并释放资源，向协调者发送ACK消息。协调者接收到参与者反馈的ACK消息之后，执行事务的中断。

#### CAP原理

- **一致性（Consistence）**
  分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）

  > **强一致性**
  >
  >当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。但是这种实现对性能影响较大。
  > **弱一致性**
  >
  >系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别（比如秒级别）之后，可以让数据达到一致性状态。
  > **最终一致性**
  >
  >弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。

- **可用性（Availability）**
  集群出现故障节点后，是否还能响应客户端的读写请求。（对数据更新具备高可用性）

- **分区容忍性（Partition tolerance）**
  保证数据可持久存储，在各种情况下都不会出现数据丢失的问题。为了实现数据的持久性，不但需要在写入的时候保证数据能够持久存储，还需要能够将数据备份一个或多个副本，存放在不同的物理设备上，防止某个存储设备发生故障时，数据不会丢失。

#### Kafka顺序性、重复性、丢失性

- Kafka保证在同一个partition中的消息是有序的，所以生产者在向消息队列写消息时可以指定一个key，保证需要顺序消费的信息都发送到一个partition中
- 一般消费者在消费kafka中的消息时，是不会丢失数据的。但是当kafka的offset是自动提交时，如果消费者没有处理完消息就出现了宕机的情况，恢复之后就消费不到offset前的数据了。可以设置offset成不自动提交，消费者处理完消息之后手动提交
- 生产者将消息发送到kafka，如果leader还没来得及将消息同步到follower就出现了宕机，就会导致还没有同步的数据丢失。
  1. 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
  2. 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队
  3. 在 producer 端设置 `acks=all`：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**
  4. 在 producer 端设置 `retries=MAX`（很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**
- Kafka消息的重复性没有办法得到保证，目前只提供了at-least-once和at-most-once语义，需要在消费端进行幂等性处理

### 算法

#### B树、B+树

- **B树**

1. 根节点的儿子树为[2, M]，除根结点之外的非叶子节点的儿子数为[M/2, M]，关键字个数为[M/2-1, M-1]，儿子结点数 = 关键字个数 + 1
2. 节点内的关键字是从左到右递增排序的
3. 所有叶子节点位于同一层

- **B+树**

1. **非叶子**节点不保存关键字记录的指针，只进行数据索引
2. **叶子**节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到
3. 非叶子节点的子节点数=关键字数

- **两者的区别**

1. B+**树的层级更少**：相较于B树B+每个**非叶子**节点存储的关键字数更多，树的层级更少所以查询数据更快；
2. B+**树查询速度更稳定**：B+所有关键字数据地址都存在**叶子**节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;
3. B+**树天然具备排序功能：**B+树所有的**叶子**节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。
4. B+**树全节点遍历更快：**B+树遍历整棵树只需要遍历所有的**叶子**节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。
5. B树**相对于**B+树**的优点是，如果经常访问的数据离根节点很近，而**B树**的**非叶子**节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比**B+树**快。

#### 红黑树

红黑树是一种含有红黑节点并能够自平衡的二叉查找树，其具有如下性质：

1. 每个节点要么是黑色，要么是红色。
2. 根节点是黑色的，每个叶子结点（Nil）也是黑色的
3. 每个红色节点的两个子节点是黑色的
4. 任意一个节点到每个叶子结点的路径中黑色节点的个数是相等的

红黑树通过左旋、右旋和变色三种方式实现自平衡：

**左旋**：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。如图3。

 **右旋**：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。如图4。

 **变色**：结点的颜色由红变黑或由黑变红。

执行插入操作时共分为如下几种情况：

![](http://windylee-blog.oss-cn-beijing.aliyuncs.com/2392382-fa2b78271263d2c8.png)

需要进行旋转的情况：**插入节点的父节点为红色，且其叔叔节点不存在或者为黑色**。

二叉树删除结点找替代结点有3种情情景：

- 情景1：若删除结点无子结点，直接删除
- 情景2：若删除结点只有一个子结点，用子结点替换删除结点
- 情景3：若删除结点有两个子结点，用后继结点（大于删除结点的最小结点）替换删除结点

**删除结点被替代后，在不考虑结点的键值的情况下，对于树来说，可以认为删除的是替代结点！**所以情景2和3都可以转换为情景1，因此我们只需要考虑删除树末节点的情景。

执行删除操作时共分为如下几种情况：

![](http://windylee-blog.oss-cn-beijing.aliyuncs.com/2392382-edaf96e55f08c198.png)

#### 堆

- 堆是一颗完全二叉树
- 堆中某个节点的值总是不大于或不小于其孩子节点的值
- 堆中每个节点的子树都是堆

#### 一致性哈希

一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1。将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。当需要访问服务器的时候，将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。

- 如果某台服务器出现宕机，那么本应该落到该服务器的请求都会落到顺时针方向的下一个服务器，而其他服务器不会受到影响；
- 如果增加一台服务器，则本应该落到上一台服务器的部分数据就会访问到该服务器

一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜(即某台服务器承担了过多的数据请求)。引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点(一台服务器可以被映射到hash环上的多个位置)。同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，这样就解决了服务节点少时数据倾斜的问题

### Web

#### Spring-AOP

Spring AOP使用了动态代理的设计模式，所谓的动态代理就是说AOP框架不回去修改字节码，而是在内存中临时的为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。

Spring AOP的动态代理主要有两种方式，JDK动态代理的CGLIB动态代理，JDK动态代理通过反射来接受被代理的类，并且要求被代理的类必须实现一个接口。如果目标类没有实现接口，会选择使用CGLIB来动态代理目标类，CGLIB是一个代码生成的类库，可以在运行时动态的生成某个类的子类，因此目标类需要能够被继承，并且代理的方法需要能够被重写。

组成元素

- 通知Advice：定义类需要处理的任务，以及何时完成--before/after/around/afterthrow等
- 连接点joinPoint：程序代码里面可以插入切面的点
- 切点PointCut：定义类需要通知的位置，会去连接点里面找对应的切面
- 切面Aspect：组合Adivce和PointCut
- 织入Weaving：编译时就把Advice织入到对应切点上，速度更快

#### ApplicationContext和BeanFactory的区别

- BeanFactory不支持国际化功能，因为BeanFactory没有拓展Spring中MessageResource接口，不具有消息处理能力(i18n)
- ApplicationContext具有强大的事件机制，主要是通过ApplicationEvent和ApplicationListener这两个接口提供，当ApplicationContext发布一个事件时，所有拓展了ApplicationListener的Bean都将会接受到这个事件
- ApplicationContext拓展了ResourceLoader接口，从而可以用来加载多个Resource
- BeanFactory采用的是延迟加载形式来注入Bean，即只有在使用到某个Bean时，才对该Bean进行加载实例化；ApplicationContext在容器启动时，一次性创建了所有的Bean

#### Spring Bean生命周期

1. 实例化一个 Bean－－也就是我们常说的 new；
2. 按照 Spring 上下文对实例化的 Bean 进行配置－－也就是 IOC 注入；
3. 如果这个 Bean 已经实现了 BeanNameAware 接口，会调用它实现的 setBeanName(String)方法，此处传递的就是 Spring 配置文件中 Bean 的 id 值
4. 如果这个 Bean 已经实现了 BeanFactoryAware 接口，会调用它实现的 setBeanFactory(setBeanFactory(BeanFactory)传递的是 Spring 工厂自身（可以用这个方式来获取其它 Bean，只需在 Spring 配置文件中配置一个普通的 Bean 就可以）
5. 如果这个 Bean 已经实现了 ApplicationContextAware 接口，会调用 setApplicationContext(ApplicationContext)方法，传入 Spring 上下文（同样这个方式也可以实现步骤 4 的内容，但比 4 更好，因为 ApplicationContext 是 BeanFactory 的子接口，有更多的实现方法）；
6. 如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor 经常被用作是 Bean内容的更改，并且由于这个是在 Bean 初始化结束时调用那个的方法，也可以被应用于内存或缓存技术；
7. 如果 Bean 在 Spring 配置文件中配置了 init-method 属性会自动调用其配置的初始化方法。
8. 如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postProcessAfterIn
   itialization(Object obj, String s)方法。注：以上工作完成以后就可以应用这个 Bean 了，那这个 Bean 是一个 Singleton 的，所以一般情况下我们调用同一个 id 的 Bean 会是在内容地址相同的实例，当然在 Spring
   配置文件中也可以配置非 Singleton，这里我们不做赘述。
9. 当 Bean 不再需要时，会经过清理阶段，如果 Bean 实现了 DisposableBean 这个接口，会调用那个其实现的 destroy()方法；
10. 最后，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调
    用其配置的销毁方法。

#### Spring MVC执行流程

1. 用户发送请求至前端控制器 DispatcherServlet
2. DispatcherServlet 收到请求调用 HandlerMapping 处理器映射器。
3. 处理器映射器根据请求 url 找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给 DispatcherServlet。
4. DispatcherServlet 通过 HandlerAdapter 处理器适配器调用处理器
5. 执行处理器(Controller，也叫后端控制器)。
6. Controller 执行完成返回 ModelAndView
7. HandlerAdapter 将 controller 执行结果 ModelAndView 返回给 DispatcherServlet
8. DispatcherServlet 将 ModelAndView 传给 ViewReslover 视图解析器
9. ViewReslover 解析后返回具体 View
10. DispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中）。
11. DispatcherServlet 响应用

#### MyBatis架构

- 读取XML文件或注解解析用户的Mapper配置，生成Config单例对象
- 根据Config对象生成Mapper的动态代理类，代理Mapper接口的所有方法，每个接口方法对应一个SQL语句，根据SQL语句生成类似于PrepareStatement的对象（创建该对象的session是初始化MyBatis的时候使用MyBatis的时候使用SessionFactory创建的）
- SQL语句的输入值的设置，是根据Config去获取到实体的属性与数据库表字段的映射关系，然后set到prepareStatement，然后放到数据库引擎中执行，输出值根据Config构造的实体关系属性与数据库表字段的映射关系，通过反射机制设置到实体对象，然后返回。

#### 过滤器Filter和拦截器Interceptor的区别

- 拦截器是基于Java反射机制的，过滤器是基于函数回调的
- 拦截器是基于方法的，粒度更细（可以进行事务管理，日志记录，权限检查），过滤器依赖于servlet容器（一般进行更为通用的处理，比如编解码，非法输入拦截，跨域请求等）
- 拦截器只能对Action请求起作用，过滤器可以对几乎所有请求HTTP、SIP器作用
- 拦截器可以访问Action上下文，值栈里的对象，过滤器不能
- 在Action的生命周期中，拦截器可以多次调用；过滤器只能在容器初始化时构建好

#### Web安全性考虑

1. 参数校验：客户端做初始校验，服务端做最后检验
2. 用户权限拦截校验
3. SQL注入：PrepareStatement预编译成模板解决、正则表达式校验、在后端加入拦截器对输入参数进行过滤校验
4. 跨站脚本攻击（XSS）：客户端信任服务器，所以黑客一旦在服务端返回的页面中插入一段JS代码，前端渲染出来，便为用户设下了陷阱，用户提交的数据就有可能被传输到黑客的服务器上，可以采用输出编码比如htmlencoder在输出到页面中，也可以对用户提交的内容进行特殊字符的过滤
5. cookie泄露：尽可能避免在cookie中存放隐私数据，实在不行利用MD5等Hash算法多次散列之后存放
6. 中间人攻击：客户端请求的公钥并非来自合法服务器，而是中间人自己的服务器生成的公钥，造成了信息泄露。可以采用HTTPS替换HTTP在传输层上保证安全性，服务端要设置证书，客户端会验证证书的有效期、颁发机构等
7. MD5加盐
8. 跨站请求伪造CSRF：token放header中不会被记录到浏览器、验证HTTP Referer中的IP地址
9. 证书：客户端持有CA根证书和CA公钥，服务端把证书下发给客户端，客户端先去验证服务端证书的合法性（域名、过期时间），通过后再用CA公钥解密证书里的数字摘要，看与自己的CA根证书是否匹配，若是则信任它发请求，不是则不允许发送。
